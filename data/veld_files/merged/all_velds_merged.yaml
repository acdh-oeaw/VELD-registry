veld_data__akp_ner_linkedcat___linkedcat___veld.yaml:
  url: https://github.com/veldhub/veld_data__akp_ner_linkedcat/blob/main/linkedcat/veld.yaml
  content:
    x-veld:
      data:
        file_type: csv
        description: "Prefered dataset is not this one, but linkedcat2! This dataset\
          \ was created by applying a custom trained SpaCy NER model an APIS / \xD6\
          BL data, on data set 'linkedcat2' at our solr index. The csv file is split\
          \ into id column, character start index of recognized entity, character\
          \ end index of entity, label of entity type, and a small context window."
        topics:
        - NLP
        - Named Entity Recognition
        contents:
        - NER data
        - inferenced NLP data
veld_data__akp_ner_linkedcat___linkedcat2___veld.yaml:
  url: https://github.com/veldhub/veld_data__akp_ner_linkedcat/blob/main/linkedcat2/veld.yaml
  content:
    x-veld:
      data:
        file_type: csv
        description: "Prefered dataset is this one, not linkedcat! This dataset was\
          \ created by applying a custom trained SpaCy NER model an APIS / \xD6BL\
          \ data, on data set 'linkedcat2' at our solr index. The csv file is split\
          \ into id column, character start index of recognized entity, character\
          \ end index of entity, label of entity type, and a small context window."
        topics:
        - NLP
        - Named Entity Recognition
        contents:
        - NER data
        - inferenced NLP data
veld_data__demo_inference_input_ts-vienna-2024___veld.yaml:
  url: https://github.com/veldhub/veld_data__demo_inference_input_ts-vienna-2024/blob/main/veld.yaml
  content:
    x-veld:
      data:
        file_type: txt
        description: A single txt file, used as inference input to a self-trained
          updipe model as a demonstration
        topics:
        - NLP
        - universal dependencies
        contents:
        - raw text
veld_data__demo_train_data_ts-vienna-2024___veld.yaml:
  url: https://github.com/veldhub/veld_data__demo_train_data_ts-vienna-2024/blob/main/veld.yaml
  content:
    x-veld:
      data:
        file_type: conllu
        description: A single conllu file, used to train a updipe model as a demonstration
        topics:
        - NLP
        - universal dependencies
        contents:
        - linguistically enriched text
        - tokenized text
        - lemmatized text
veld_data__eltec_original_selection___veld.yaml:
  url: https://github.com/veldhub/veld_data__eltec_original_selection/blob/main/veld.yaml
  content:
    x-veld:
      data:
        description: parent git repo that integrates various ELTeC corpora as submodules
          for downstream processing.
        file_type: xml
        contents:
        - TEI
        - annotated literature
veld_data__wordembeddings_evaluation___evaluation_gold_data___capitalized___veld.yaml:
  url: https://github.com/veldhub/veld_data__wordembeddings_evaluation/blob/main/evaluation_gold_data/capitalized/veld.yaml
  content:
    x-veld:
      data:
        description: custom evaluation data for evaluating word embeddings models.
          Words are capitalized.
        topics:
        - NLP
        - word embeddings
        file_type: yaml
        contents:
        - evaluation data
        - NLP gold data
veld_data__wordembeddings_evaluation___evaluation_gold_data___lowercase___veld.yaml:
  url: https://github.com/veldhub/veld_data__wordembeddings_evaluation/blob/main/evaluation_gold_data/lowercase/veld.yaml
  content:
    x-veld:
      data:
        description: custom evaluation data for evaluating word embeddings models.
          Words are all lowercase.
        topics:
        - NLP
        - word embeddings
        file_type: yaml
        contents:
        - evaluation data
        - NLP gold data
veld_code__analyse_conllu___veld.yaml:
  url: https://github.com/veldhub/veld_code__analyse_conllu/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: ''
        topics:
        - NLP
        - Machine learning
        - tokenization
        - lemmatization
        - part of speech
        - dependency parsing
        - universal dependencies
        - grammatical annotation
        inputs:
        - volume: /veld/input/
          file_type: conllu
        outputs:
        - volume: /veld/output/
          file_type: json
          contents:
          - statistics
          - NLP statistics
    services:
      veld:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        working_dir: /veld/code/
        volumes:
        - ./src:/veld/code/
veld_code__apis_ner_evaluate_old_models___veld_evaluate.yaml:
  url: https://github.com/veldhub/veld_code__apis_ner_evaluate_old_models/blob/main/veld_evaluate.yaml
  content:
    x-veld:
      code:
        description: hard-coded evaluation of several spaCy2.2.4 models.
        topics:
        - NLP
        - Machine learning
        - Named entity recognition
        inputs:
        - volume: /veld/input/
          description: This input is hard-wired to the apis spacy-ner repo and not
            made for generic usage.
          file_type:
          - pickle
          - txt
          - json
          - spacy model
          contents:
          - NER gold data
          - Machine learning model
          - NLP model
        outputs:
        - volume: /veld/output/
          environment: out_eval_result
          description: evaluation report of the models from the apis spacy-ner repo.
          file_type: md
          contents: evaluation report
    services:
      veld_evaluate:
        build: .
        command: python /veld/code/reevaluate_all_models.py
        volumes:
        - ./src/:/veld/code/
        environment:
          out_eval_result_file: null
veld_code__apis_ner_transform_to_gold___veld.yaml:
  url: https://github.com/veldhub/veld_code__apis_ner_transform_to_gold/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: hard-coded conversion of apis ner models to custom json format.
        topics:
        - ETL
        - data cleaning
        inputs:
        - volume: /veld/input/
          description: This input is hard-wired to the apis spacy-ner repo and not
            made for generic usage.
          file_type:
          - pickle
          - txt
          - json
          contents: NER gold data
        outputs:
        - volume: /veld/output/cleaned/
          environment: out_json_cleaned_file
          description: raw uncleaned, as it was originally. Now just transformed to
            json.
          file_type: json
          contents: NER gold data
        - volume: /veld/output/uncleaned/
          environment: out_json_uncleaned_file
          description: removed empty entity annotations and fixed border issues.
          file_type: json
          contents: NER gold data
        - volume: /veld/output/cleaned_simplified/
          environment: out_json_cleaned_simplified_file
          description: additionally to cleaning, this data is slimmed down from superfluous
            entity ids in favor of simplified entity classes.
          file_type: json
          contents: NER gold data
        - volume: /veld/output/log/
          environment: out_log_file
          file_type: txt
    services:
      veld:
        build: .
        command: python /veld/code/extract_and_clean.py
        volumes:
        - ./src/:/veld/code/
        environment:
          out_json_uncleaned_file: null
          out_json_cleaned_file: null
          out_json_cleaned_simplified_file: null
          out_log_file: null
veld_code__bert_embeddings___veld_infer_and_create_index.yaml:
  url: https://github.com/veldhub/veld_code__bert_embeddings/blob/main/veld_infer_and_create_index.yaml
  content:
    x-veld:
      code: null
    services:
      infer_and_create_index:
        build: .
        command: python /veld/code/infer_and_create_index.py
        volumes:
        - ./src/:/veld/code/
veld_code__downloader___veld.yaml:
  url: https://github.com/veldhub/veld_code__downloader/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: A very simple curl call. Since many veld chains need to download
          data, it makes sense to encapsulate the download functionality into a dedicated
          downloader veld code
        topics: ETL
        outputs:
        - volume: /veld/output/
          environment: out_file
          description: environment var is optional. If unset, this script will fetch
            the file name from the resource.
        settings:
        - environment: url
          env_type: str
          description: The url where some resource is located and should be downloaded
            from.
    services:
      veld_downloader:
        build: .
        command: sh /veld/code/downloader.sh
        volumes:
        - ./downloader.sh:/veld/code/downloader.sh
        environment:
          url: null
          out_file: null
veld_code__fasttext___veld_jupyter_notebook.yaml:
  url: https://github.com/veldhub/veld_code__fasttext/blob/main/veld_jupyter_notebook.yaml
  content:
    x-veld:
      code:
        description: a fasttext training and inference jupyter notebook.
        topics:
        - NLP
        - Machine Learning
        - word embeddings
    services:
      veld_jupyter_notebook:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/jupyter_notebook/:/veld/code/:z
        - ./data/:/veld/storage/:z
veld_code__fasttext___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__fasttext/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: a fasttext training and inference jupyter notebook.
        topics:
        - NLP
        - Machine Learning
        - word embeddings
        inputs:
        - volume: /veld/input/
          file_type: txt
          environment: in_train_data_file
          description: training data must be expressed as one sentence per line.
          contents: raw text
        outputs:
        - volume: /veld/output/
          file_type:
          - bin
          - fasttext model
          environment: out_model_file
          contents:
          - fasttext model
          - word embeddings
        settings:
        - environment: vector_size
          description: 'hyperparameter: the dimension of the vectors to be trained.'
          env_type: int
          default: 200
        - environment: epochs
          description: 'hyperparameter: the number of epochs of the training.'
          env_type: int
          default: 50
        - environment: window_size
          description: 'hyperparameter: the size of the context window of each token.'
          env_type: int
          default: 5
    services:
      veld_train:
        build: .
        command: /veld/code/train.sh
        volumes:
        - ./src/train/:/veld/code/:z
        - ./data/training_data/:/veld/input/:z
        - ./data/models/:/veld/output/:z
        environment:
          in_train_data_file: null
          out_model_file: null
          model_description: null
          vector_size: 200
          epochs: 50
          window_size: 5
veld_code__glove___veld_jupyter_notebook.yaml:
  url: https://github.com/veldhub/veld_code__glove/blob/main/veld_jupyter_notebook.yaml
  content:
    x-veld:
      code:
        description: A jupyter notebook that loads GloVe vectors and provides some
          convenient functions to use them.
        topics:
        - NLP
        - Machine learning
        - word embeddings
    services:
      veld_jupyter_notebook:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/main/jupyter_notebook/:/veld/code/:z
        - ./data/:/veld/storage/:z
veld_code__glove___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__glove/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: This code repo encapsulates the original code from https://github.com/stanfordnlp/GloVe/tree/master
        topics:
        - NLP
        - Machine learning
        - word embeddings
        inputs:
        - volume: /veld/input/
          environment: in_corpus_file
          description: In the txt file, each line must be one sentence
          file_type: txt
          contents: natural text
        outputs:
        - volume: /veld/output/
          environment: out_vocab_file
          file_type: bin
          contents:
          - GloVe global word cooccurrence matrix
          - GloVe vectors
        - volume: /veld/output/
          environment: out_cooccurrence_file
          file_type: bin
          contents:
          - GloVe global word cooccurrence matrix
          - GloVe vectors
        - volume: /veld/output/
          environment: out_cooccurrence_shuf_file
          file_type: bin
          contents:
          - GloVe global word cooccurrence matrix
          - GloVe vectors
        - volume: /veld/output/
          environment: out_vector_file
          file_type: bin
          contents:
          - GloVe global word cooccurrence matrix
          - GloVe vectors
        settings:
        - environment: verbose
          env_type: int
          default: 2
        - environment: memory
          env_type: float
          default: 4.0
        - environment: vocab_min_count
          env_type: int
          default: 5
        - environment: vector_size
          env_type: int
          default: 50
        - environment: max_iter
          env_type: int
          default: 15
        - environment: window_size
          env_type: int
          default: 15
        - environment: binary
          env_type: int
          default: 2
        - environment: num_threads
          env_type: int
          default: 8
        - environment: x_max
          env_type: int
          default: 10
    services:
      veld_train:
        build: .
        volumes:
        - ./src/main/train/:/veld/code/:z
        - ./data/training_data/:/veld/input/:z
        - ./data/models/:/veld/output/:z
        command: /veld/code/train.sh
        environment:
          in_corpus_file: null
          out_vocab_file: null
          out_cooccurrence_file: null
          out_cooccurrence_shuf_file: null
          out_vector_file: null
          model_id: null
          model_description: null
          verbose: 2
          memory: 4.0
          vocab_min_count: 5
          vector_size: 50
          max_iter: 15
          window_size: 15
          binary: 2
          num_threads: 8
          x_max: 10
veld_code__jupyter_notebook_base___veld.yaml:
  url: https://github.com/veldhub/veld_code__jupyter_notebook_base/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: template veld code repo for a juptyer notebook
    services:
      veld:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        working_dir: /veld/code/
        volumes:
        - ./src:/veld/code/
        - ./volumes/input/:/veld/input/
        - ./volumes/output/:/veld/output/
veld_code__simple_docker_test___veld.yaml:
  url: https://github.com/veldhub/veld_code__simple_docker_test/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: prints information about the python intepreter within the docker
          container.
        topics: testing
    services:
      veld:
        build: .
        command: python /veld/code/test.py
        volumes:
        - ./test.py:/veld/code/test.py
veld_code__spacy___veld_convert.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_convert.yaml
  content:
    x-veld:
      code:
        description: prepare data for spacy NER training, since spacy expects the
          entity annotation indices to be precisely at the beginning and end of the
          words, and also no overlapping entity annotations. Then it converts the
          data to spaCy docbin, and prepares it for training by splitting it into
          train, dev, eval subsets, and shuffling them randomly.
        topics:
        - ETL
        - NLP
        - Machine learning
        inputs:
        - volume: /veld/input/
          file_type: json
          description: name of the csv file, containing NER gold data
          environment: in_json_file
          contents: NER gold data
        outputs:
        - volume: /veld/output/docbin/
          description: path to folder where spacy docbin files will be stored with
            file names `train.spacy, dev.spacy, eval.spacy`
          file_type: spacy docbin
          contents: NER gold data
        - volume: /veld/output/log/
          environment: out_log_file
          description: log file of conversion
          file_type: spacy docbin
          contents: NER gold data
        settings:
        - environment: model_base
          description: spacy model to be used for conversion.
          env_type: str
        - environment: percentage_train
          description: percentage of data allocated to training set
          env_type: int
          default: 80
        - environment: percentage_dev
          description: percentage of data allocated to dev set
          env_type: int
          default: 10
        - environment: percentage_eval
          description: percentage of data allocated to eval set
          env_type: int
          default: 10
        - environment: seed
          description: seed for initial random shuffling of training data
          env_type: int
          default: 42
    services:
      veld_convert:
        build: .
        command: python /veld/code/convert.py
        volumes:
        - ./src/:/veld/code/
        - ./data/models_base_cache/:/tmp/models_base_cache/
        - ./data/training_data_json/:/veld/input/
        - ./data/docbin/:/veld/output/docbin/
        - ./:/veld/output/log/
        environment:
          in_json_file: null
          out_log_file: null
          model_base: null
          percentage_train: 80
          percentage_dev: 10
          percentage_eval: 10
          seed: 42
veld_code__spacy___veld_create_config.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_create_config.yaml
  content:
    x-veld:
      code:
        description: 'Creating a spacy config by encapsulating `init config` ( https://spacy.io/api/cli#init-config
          ) and `init fill-config` ( https://spacy.io/api/cli#init-fill-config ) .
          The output is ai config file used for training; see more here: https://spacy.io/usage/training/#config'
        topics:
        - NLP
        - Machine learning
        outputs:
        - volume: /veld/output/
          file_type: cfg
          environment: out_spacy_config
          contents: spacy training config
          description: See https://spacy.io/usage/training/#config
        settings:
        - environment: lang
          description: See https://spacy.io/api/cli#init-config
          env_type: str
        - environment: tagger
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: parser
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: ner
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: entity_linker
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: entity_ruler
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: textcat
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: textcat_multilabel
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: lemmatizer
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: trainable_lemmatizer
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: morphologizer
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: attribute_ruler
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: senter
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: sentencizer
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: tok2vec
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: transformer
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: optimize_efficiency
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: optimize_accuracy
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: gpu
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
        - environment: pretraining
          description: See https://spacy.io/api/cli#init-config
          env_type: bool
          default: false
          optional: true
    services:
      veld_create_config:
        build: .
        working_dir: /veld/code/
        command: /veld/code/create_config.sh
        volumes:
        - ./src/:/veld/code/
        - ./data/configs/:/veld/output/
        environment:
          out_config_file: null
          lang: de
          tagger: false
          parser: false
          ner: false
          entity_linker: false
          entity_ruler: false
          textcat: false
          textcat_multilabel: false
          lemmatizer: false
          trainable_lemmatizer: false
          morphologizer: false
          attribute_ruler: false
          senter: false
          sentencizer: false
          tok2vec: false
          transformer: false
          optimize_efficiency: null
          optimize_accuracy: null
          gpu: false
          pretraining: false
veld_code__spacy___veld_publish_to_hf.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_publish_to_hf.yaml
  content:
    x-veld:
      code:
        description: 'simple service to push spacy models to huggingface. IMPORTANT:
          Only works from spacy v3.* onwards!'
        topics:
        - NLP
        - ETL
        inputs:
        - volume: /veld/input/
          file_type: spacy model
          contents: NLP model
        settings:
        - environment: model_name
          description: 'name of the model, to be used for huggingface metadata. IMPORTANT:
            do not put double underscores into the model name, as this crashes spacy
            while publishing.'
          env_type: str
          optional: true
        - environment: version
          description: 'version of the model, to be used for huggingface metadata.
            IMPORTANT: spacy crashes when the version tag contains the character `v`
            in front of numeric+dot version identifiers: E.g. `v1.1` crashes, while
            `1.1` works.'
          env_type: str
          optional: true
        - environment: hf_token
          description: 'huggingface authentication token. IMPORTANT: It is advised
            to not hardcode that directly into the yaml file but rather define the
            environment variable yourself, before calling this docker compose service.
            On linux and mac, this can be done with `export hf_token=<TOKEN>` before
            launching a docker compose service, or persist it in a `.env` (with the
            content simply being `hf_token=<TOKEN>`) file next to the chain veld yaml
            file, where docker compose would load it from (take care to not commit
            that to git! Best to add the `.env` to `.gitignore`).'
          env_type: str
    services:
      veld_publish_to_hf:
        build: .
        command: bash /veld/code/publish_to_hf.sh
        volumes:
        - ./src/:/veld/code/
        environment:
          model_name: null
          version: null
          hf_token: $hf_token
veld_code__spacy___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: A spacy trainig setup, utilizing spacy v3's config system.
        topics:
        - NLP
        - Machine learning
        inputs:
        - volume: /veld/input/docbin/
          file_type: spacy docbin
          environment: in_train_docbin_file
          contents:
          - NLP gold data
          - ML gold data
          - gold data
        - volume: /veld/input/docbin/
          file_type: spacy docbin
          environment: in_dev_docbin_file
          contents:
          - NLP gold data
          - ML gold data
          - gold data
        - volume: /veld/input/docbin/
          file_type: spacy docbin
          environment: in_eval_docbin_file
          contents:
          - NLP gold data
          - ML gold data
          - gold data
        - volume: /veld/input/config/
          file_type: cfg
          environment: in_spacy_config
          contents: spacy training config
          description: See https://spacy.io/usage/training/#config
        outputs:
        - volume: /veld/output/
          file_type: spacy model
          contents:
          - NLP model
          - spacy model
        - volume: /veld/output/
          file_type: txt
          environment: out_train_log_file
          description: path to the train log file
          contents: logs
        - volume: /veld/output/
          file_type: txt
          environment: out_eval_log_file
          description: path to the eval log file
          contents: logs
        settings:
        - environment: model_base
          description: spacy model to be used for downstream training.
          env_type: str
    services:
      veld_train:
        build: .
        working_dir: /veld/code/
        command: /veld/code/train.sh
        volumes:
        - ./src/:/veld/code/
        - ./data/models_base_cache/:/tmp/models_base_cache/
        - ./data/docbin/:/veld/input/docbin/
        - ./data/config/:/veld/input/config/
        - ./data/model/:/veld/output/
        environment:
          in_train_docbin_file: null
          in_dev_docbin_file: null
          in_eval_docbin_file: null
          model_base: null
          out_train_log_file: null
          out_eval_log_file: null
veld_code__teitok-tools___veld_parseudpipe.yaml:
  url: https://github.com/veldhub/veld_code__teitok-tools/blob/main/veld_parseudpipe.yaml
  content:
    x-veld:
      code:
        description: 'This code veld encapsulates and veldifies the parseudpipe script.
          All its settings here are passed down to the script. For more information
          on its usage and settings, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#parseudpipe'
        topics:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
        inputs:
        - volume: /veld/input/
          file_type: xml
          environment: in_xml_file
        outputs:
        - volume: /veld/output/
          file_type: xml
          environment: out_xml_file
        settings:
        - environment: model
          description: which UDPIPE model to use
          env_type: str
          optional: true
        - environment: lang
          description: language of the texts (if no model is provided)
          env_type: str
          optional: true
        - environment: token
          description: token node
          env_type: str
          optional: true
        - environment: tokxp
          description: token XPath
          env_type: str
          optional: true
        - environment: sent
          description: sentence node
          env_type: str
          optional: true
        - environment: sentxp
          description: sentence XPath
          env_type: str
          optional: true
        - environment: atts
          description: attributes to use for the word form
          env_type: str
          optional: true
    services:
      veld_parseudpipe:
        build: .
        volumes:
        - ./:/veld/code/
        command: ./veld_parseudpipe.sh
        environment:
          in_xml_file: null
          out_xml_file: null
          model: null
          lang: null
          token: null
          tokxp: null
          sent: null
          sentxp: null
          atts: null
veld_code__teitok-tools___veld_udpipe2teitok.yaml:
  url: https://github.com/veldhub/veld_code__teitok-tools/blob/main/veld_udpipe2teitok.yaml
  content:
    x-veld:
      code:
        description: 'This code veld encapsulates and veldifies the udpipe2teitok
          script. All its settings here are passed down to the script. For more information
          on its usage and settings, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#udpipe2teitok'
        topics:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
        inputs:
        - volume: /veld/input/
          file_type: txt
        outputs:
        - volume: /veld/output/
          file_type: xml
        settings:
        - environment: model
          description: the UDPIPE model to be used (which has to be available in the
            REST API)
          env_type: str
          optional: true
        - environment: lang
          description: An indication of the language (either an ISO code or a name)
            in case no model is provided.
          env_type: str
          optional: true
        - environment: mixed
          description: mixed language corpus - use CWALI to detect the language of
            each file.
          env_type: bool
          default: false
          optional: true
    services:
      veld_udpipe2teitok:
        build: .
        volumes:
        - ./:/veld/code/
        command: ./veld_udpipe2teitok.sh
        environment:
          lang: null
          model: null
          mixed: false
veld_code__teitok-tools___veld_xmltokenize.yaml:
  url: https://github.com/veldhub/veld_code__teitok-tools/blob/main/veld_xmltokenize.yaml
  content:
    x-veld:
      code:
        description: 'This code veld encapsulates and veldifies the xmltokenize script.
          All its settings here are passed down to the script. For more information
          on its usage and settings, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#xmltokenize'
        topics:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
        inputs:
        - volume: /veld/input/
          file_type: xml
          environment: in_xml_file
          description: The xml file to be tokenized
        outputs:
        - volume: /veld/output/
          file_type: xml
          environment: out_xml_file
          description: The output tokenized xml
        settings:
        - environment: textnode
          description: what to use as the text body to tokenize
          env_type: str
        - environment: exclude
          description: elements not to tokenize
          env_type: str
          optional: true
        - environment: enumerate
          description: provide a unique ID to each token
          env_type: bool
          default: false
          optional: true
        - environment: segment
          description: split into sentences (1=yes, 2=only) - only for TEI files
          env_type: int
          optional: true
    services:
      veld_xmltokenize:
        build: .
        volumes:
        - ./:/veld/code/
        command: ./veld_xmltokenize.sh
        environment:
          in_xml_file: null
          out_xml_file: null
          textnode: null
          tok: null
          exclude: null
          enumerate: false
          segment: null
veld_code__udpipe___veld_infer.yaml:
  url: https://github.com/veldhub/veld_code__udpipe/blob/main/veld_infer.yaml
  content:
    x-veld:
      code:
        description: udpipe inference setup
        topics:
        - NLP
        - Machine learning
        - tokenization
        - lemmatization
        - part of speech
        - dependency parsing
        - universal dependencies
        - grammatical annotation
        inputs:
        - volume: /veld/input/txt/
          environment: in_txt_file
          description: txt files to be inferenced on. Note that the environment var
            `in_txt_file` is optional, and if it is not present, the entire input
            folder will be processed recursively
          file_type: txt
          contents: raw text
        - volume: /veld/input/model/
          environment: in_model_file
          file_type: udpipe model
          contents:
          - NLP model
          - tokenizer
          - lemmatizer
        outputs:
        - volume: /veld/output/
          description: The file name of the output conllu is created by the corresponding
            input txt file, since recursive processing requires such automatic logic
          file_type:
          - conllu
          - tsv
          contents:
          - inferenced NLP data
          - tokenized text
          - lemmatized text
          - part of speech of text
          - universal dependencies of text
          - grammatically annotated text
          - linguistic data
        settings:
        - environment: tokenizer
          description: if tokenizer config should be read or not
          env_type: boolean
          optional: true
          default: true
        - environment: tokenizer_normalized_spaces
          description: 'by default, UDPipe uses custom MISC fields to exactly encode
            spaces in the original document (as described below). If true, only the
            standard CoNLL-U v2 markup (SpaceAfter=No and # newpar) is used.'
          env_type: boolean
          optional: true
          default: false
        - environment: tokenizer_presegmented
          description: the input file is assumed to be already segmented, with each
            sentence on a separate line, and is only tokenized (respecting sentence
            breaks)
          env_type: boolean
          optional: true
          default: false
        - environment: tokenizer_ranges
          description: for each token, a range in the original document is stored
            in the format described below.
          env_type: boolean
          optional: true
          default: false
        - environment: tokenizer_joint_with_parsing
          description: "an experimental mode performing sentence segmentation jointly\
            \ using the tokenizer and the parser (see Milan Straka and Jana Strakov\xE1\
            : Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe\
            \ paper for details)."
          env_type: boolean
          optional: true
          default: false
        - environment: tokenizer_joint_change_boundary_logprob
          description: for every sentence boundary not returned by the tokenizer (i.e.,
            either 0, 1 or 2 times). The joint sentence segmentation chooses such
            a segmentation, where every sentence has length at most joint_max_sentence_len
            and the sum of logprobs of all sentences is as large as possible.
          env_type: boolean
          optional: true
          default: false
        - environment: tagger
          description: if tagger config should be read or not
          env_type: boolean
          optional: true
          default: true
        - environment: parser
          description: if parser config should be read or not
          env_type: boolean
          optional: true
          default: true
    services:
      veld_infer:
        build: .
        command: /veld/code/infer.sh
        volumes:
        - ./data/inference/input/txt/:/veld/input/txt/
        - ./data/inference/input/model/:/veld/input/model/
        - ./data/inference/output/:/veld/output/
        - ./src/main/:/veld/code/
        environment:
          in_txt_file: null
          in_model_file: null
          tokenizer: true
          tokenizer_normalized_spaces: false
          tokenizer_presegmented: false
          tokenizer_ranges: false
          tokenizer_joint_with_parsing: false
          tokenizer_joint_change_boundary_logprob: false
          tagger: true
          parser: true
veld_code__udpipe___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__udpipe/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: udpipe training setup
        topics:
        - NLP
        - Machine learning
        - tokenization
        - lemmatization
        - part of speech
        - dependency parsing
        - universal dependencies
        - grammatical annotation
        inputs:
        - volume: /veld/input/
          environment: train_data_path
          file_type: conllu
          contents:
          - tokenized text
          - enriched text
          - linguistic data
        outputs:
        - volume: /veld/output/
          environment: model_path
          file_type: udpipe model
          contents:
          - NLP model
          - tokenizer
          - lemmatizer
        settings:
        - environment: tokenizer
          description: if tokenizer config should be read or not
          env_type: boolean
          optional: true
          default: true
        - environment: tokenizer_tokenize_url
          description: tokenize URLs and emails using a manually implemented recognizer
          env_type: boolean
          optional: true
          default: true
        - environment: tokenizer_allow_spaces
          description: allow tokens to contain spaces
          env_type: boolean
          optional: true
          default: true
        - environment: tokenizer_dimension
          description: dimension of character embeddings and of the per-character
            bidirectional GRU. Note that inference time is quadratic in this parameter.
            Supported values are only 16, 24 and 64, with 64 needed for languages
            with complicated tokenization like Japanese, Chinese or Vietnamese or
            complicated segmentation.
          env_type: int
          optional: true
          default: 24
        - environment: tokenizer_segment_size
          description: length of character segment used to predict token and sentence
            breaks. Larger values like 200 are needed for languges with complicated
            segmentation
          env_type: int
          optional: true
          default: 50
        - environment: tokenizer_epochs
          description: the number of epochs to train the tokenizer for
          env_type: int
          optional: true
          default: 100
        - environment: tokenizer_batch_size
          description: batch size (number of segments) used during tokenizer training
          env_type: int
          optional: true
          default: 50
        - environment: tokenizer_learning_rate
          description: the learning rate used during tokenizer training
          env_type: float
          optional: true
          default: 0.005
        - environment: tokenizer_learning_rate_final
          description: if not zero, use exponential learning rate decay so that last
            epoch uses this learning rate
          env_type: float
          optional: true
          default: 0
        - environment: tokenizer_dropout
          description: dropout used during tokenizer training
          env_type: float
          optional: true
          default: 0.1
        - environment: tokenizer_early_stopping
          description: perform early stopping, choosing training iteration maximizing
            sentences F1 score plus tokens F1 score on heldout data
          env_type: boolean
          optional: true
          default: 1
        - environment: tagger
          description: if tagger config should be read or not
          env_type: boolean
          optional: true
          default: true
        - environment: tagger_use_lemma
          description: use the lemma field internally to perform disambiguation; the
            lemma may be not outputted
          env_type: boolean
          optional: true
          default: true
        - environment: tagger_provide_lemma
          description: produce the disambiguated lemma on output
          env_type: boolean
          optional: true
          default: true
        - environment: tagger_use_xpostag
          description: use the XPOS tags internally to perform disambiguation; it
            may not be outputted
          env_type: boolean
          optional: true
          default: true
        - environment: tagger_provide_xpostag
          description: produce the disambiguated XPOS tag on output
          env_type: boolean
          optional: true
          default: true
        - environment: tagger_use_feats
          description: use the Feats internally to perform disambiguation; it may
            not be outputted
          env_type: boolean
          optional: true
          default: true
        - environment: tagger_provide_feats
          description: produce the disambiguated Feats field on output
          env_type: boolean
          optional: true
          default: true
        - environment: tagger_dictionary_max_form_analyses
          description: the maximum number of (most frequent) form analyses from UD
            training data that are to be kept in the morphological dictionary
          env_type: int
          optional: true
          default: 0
        - environment: tagger_dictionary_file
          description: use a given custom morphological dictionary, where each line
            contains 5 tab-separated fields FORM, LEMMA, UPOSTAG, XPOSTAG and FEATS.
            Note that this dictionary data is appended to the dictionary created from
            the UD training data, not replacing it.
          env_type: file
          optional: true
          default: null
        - environment: tagger_guesser_suffix_rules
          description: number of rules generated for every suffix
          env_type: int
          optional: true
          default: 8
        - environment: tagger_guesser_prefixes_max
          description: maximum number of form-generating prefixes to use in the guesser
          env_type: int
          optional: true
          default: 4
        - environment: tagger_guesser_prefix_min_count
          description: minimum number of occurrences of form-generating prefix to
            consider using it in the guesser
          env_type: int
          optional: true
          default: 10
        - environment: tagger_guesser_enrich_dictionary
          description: number of rules generated for forms present in training data
            (assuming that the analyses from the training data may not be all)
          env_type: int
          optional: true
          default: 6
        - environment: tagger_iterations
          description: number of training iterations to perform
          env_type: int
          optional: true
          default: 20
        - environment: tagger_early_stopping
          description: perform early stopping, choosing training iteration maximizing
            tagging accuracy on the heldout data
          env_type: boolean
          optional: true
          default: 0
        - environment: tagger_templates
          description: MorphoDiTa feature templates to use, either lemmatizer which
            focuses more on lemmas, or tagger which focuses more on UPOS/XPOS/FEATS
          env_type: file
          optional: true
          default: null
        - environment: parser
          description: if parser config should be read or not
          env_type: boolean
          optional: true
          default: true
        - environment: parser_use_gold_tags
          description: if false and a tagger exists, the Lemmas/UPOS/XPOS/FEATS for
            both the training and heldout data are generated by the tagger, otherwise
            they are taken from the gold data
          env_type: boolean
          optional: true
          default: false
        - environment: parser_embedding_upostag
          description: the dimension of the UPos embedding used in the parser
          env_type: int
          optional: true
          default: 20
        - environment: parser_embedding_feats
          description: the dimension of the Feats embedding used in the parser
          env_type: int
          optional: true
          default: 20
        - environment: parser_embedding_xpostag
          description: the dimension of the XPos embedding used in the parser
          env_type: int
          optional: true
          default: 0
        - environment: parser_embedding_form
          description: the dimension of the Form embedding used in the parser
          env_type: int
          optional: true
          default: 50
        - environment: parser_embedding_lemma
          description: the dimension of the Lemma embedding used in the parser
          env_type: int
          optional: true
          default: 0
        - environment: parser_embedding_deprel
          description: the dimension of the Deprel embedding used in the parser
          env_type: int
          optional: true
          default: 20
        - environment: parser_embedding_form_mincount
          description: for forms not present in the pre-trained embeddings, generate
            random embeddings if the form appears at least this number of times in
            the trainig data (forms not present in the pre-trained embeddings and
            appearing less number of times are considered OOV)
          env_type: int
          optional: true
          default: 2
        - environment: parser_embedding_lemma_mincount
          description: for lemmas not present in the pre-trained embeddings, generate
            random embeddings if the lemma appears at least this number of times in
            the trainig data (lemmas not present in the pre-trained embeddings and
            appearing less number of times are considered OOV)
          env_type: int
          optional: true
          default: 2
        - environment: parser_iterations
          description: number of training iterations to use
          env_type: int
          optional: true
          default: 10
        - environment: parser_hidden_layer
          description: the size of the hidden layer
          env_type: int
          optional: true
          default: 200
        - environment: parser_batch_size
          description: batch size used during neural-network training
          env_type: int
          optional: true
          default: 10
        - environment: parser_learning_rate
          description: the learning rate used during neural-network training
          env_type: float
          optional: true
          default: 0.02
        - environment: parser_learning_rate_final
          description: the final learning rate used during neural-network training
          env_type: float
          optional: true
          default: 0.001
        - environment: parser_l2
          description: the L2 regularization used during neural-network training
          env_type: float
          optional: true
          default: 0.5
        - environment: parser_early_stopping
          description: perform early stopping, choosing training iteration maximizing
            LAS on heldout data
          env_type: boolean
          optional: true
          default: false
    services:
      veld_train:
        build: .
        command: /veld/code/train.sh
        volumes:
        - ./data/training/input/:/veld/input/
        - ./data/training/output/:/veld/output/
        - ./src/main/:/veld/code/
        environment:
          train_data_path: null
          model_path: null
          tokenizer: true
          tokenizer_tokenize_url: true
          tokenizer_allow_spaces: null
          tokenizer_dimension: 24
          tokenizer_segment_size: 50
          tokenizer_epochs: 100
          tokenizer_batch_size: 50
          tokenizer_learning_rate: 0.005
          tokenizer_learning_rate_final: 0
          tokenizer_dropout: 0.1
          tokenizer_early_stopping: 1
          tagger: true
          tagger_use_lemma: true
          tagger_provide_lemma: null
          tagger_use_xpostag: null
          tagger_provide_xpostag: null
          tagger_use_feats: null
          tagger_provide_feats: null
          tagger_dictionary_max_form_analyses: 0
          tagger_dictionary_file: null
          tagger_guesser_suffix_rules: 8
          tagger_guesser_prefixes_max: 4
          tagger_guesser_prefix_min_count: 10
          tagger_guesser_enrich_dictionary: 6
          tagger_iterations: 20
          tagger_early_stopping: 0
          tagger_templates: null
          parser: true
          parser_use_gold_tags: null
          parser_embedding_upostag: 20
          parser_embedding_feats: 20
          parser_embedding_xpostag: 0
          parser_embedding_form: 50
          parser_embedding_lemma: 0
          parser_embedding_deprel: 20
          parser_embedding_form_mincount: 2
          parser_embedding_lemma_mincount: 2
          parser_iterations: 10
          parser_hidden_layer: 200
          parser_batch_size: 10
          parser_learning_rate: 0.02
          parser_learning_rate_final: 0.001
          parser_l2: 0.5
          parser_early_stopping: null
veld_code__wikipedia_nlp_preprocessing___veld_download_and_extract.yaml:
  url: https://github.com/veldhub/veld_code__wikipedia_nlp_preprocessing/blob/main/veld_download_and_extract.yaml
  content:
    x-veld:
      code:
        description: downloading wikipedia archive and extracting each article to
          a json file.
        topics:
        - NLP
        - Machine Learning
        - ETL
        outputs:
        - volume: /veld/output/
          description: a folder containing json files, where each file contains the
            contents of a wikipedia article
          file_type: json
          contents:
          - NLP training data
          - raw text
        settings:
        - environment: wikipedia_dump_url
          description: url to a wikipdedia dump download, from https://dumps.wikimedia.org/
          env_type: url
        - environment: out_data_description
          description: short human description for the data and its purpose, will
            be persisted in a data veld yaml
          env_type: string
          optional: true
    services:
      veld_download_and_extract:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        - ./data/wikipedia_json/:/veld/output/:z
        command: /veld/code/download_and_extract.sh
        environment:
          wikipedia_dump_url: null
          out_data_description: null
veld_code__wikipedia_nlp_preprocessing___veld_transform_wiki_json_to_txt.yaml:
  url: https://github.com/veldhub/veld_code__wikipedia_nlp_preprocessing/blob/main/veld_transform_wiki_json_to_txt.yaml
  content:
    x-veld:
      code:
        description: transforming wikipedia raw jsons to a single txt file.
        topics:
        - NLP
        - Machine Learning
        - ETL
        inputs:
        - volume: /veld/input/
          description: a folder containing json files, where each file contains the
            contents of a wikipedia article
          file_type: json
          contents:
          - NLP training data
          - raw text
        outputs:
        - volume: /veld/output/
          description: single txt file, containing only raw content of wikipedia pagaes,
            split into sentences or per article with a newline each, possibly being
            only a sampled subset for testing.
          environment: out_txt_file
          file_type: txt
          contents:
          - NLP training data
          - word embeddings training data
          - raw text
        settings:
        - environment: out_data_description
          description: short human description for the data and its purpose, will
            be persisted in a data veld yaml
          env_type: string
          optional: true
        - environment: cpu_count
          description: number of cpu cores to be used for parallel processing
          env_type: int
          optional: true
          default: maximum number of available cpu cores
        - environment: set_split_sentences
          description: Should the resulting txt be split by newlines at each sentence
            boundary? If not, then newlines will be set at the end of each article.
          env_type: boolean
          optional: true
          default: false
        - environment: sample_size_percentage
          description: As percentage, can be used to transform only a sample of the
            data, for testing purpose most likely. The sample is randomly picked,
            and a random seed can also be set with `sample_random_seed`
          env_type: float
          optional: true
          default: 100
        - environment: sample_random_seed
          description: a random seed in case a random sample is drawn and its randomness
            should be fixed.
          env_type: str
          optional: true
          default: null
        - environment: buffer_segments
          description: The interval at which progress should be printed. E.g. 100
            means to print hundred times during processing.
          env_type: int
          optional: true
          default: 100
    services:
      veld_transform_wiki_json_to_txt:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        - ./data/wikipedia_json/:/veld/input/
        - ./data/wikipedia_txt/:/veld/output/
        command: python /veld/code/transform_wiki_json_to_txt.py
        environment:
          out_txt_file: null
          out_data_description: null
          cpu_count: null
          set_split_sentences: false
          sample_size_percentage: 100
          sample_random_seed: null
          buffer_segments: 100
veld_code__word2vec___veld_jupyter_notebook.yaml:
  url: https://github.com/veldhub/veld_code__word2vec/blob/main/veld_jupyter_notebook.yaml
  content:
    x-veld:
      code:
        description: a word2vec jupyter notebook, for quick experiments
        topics:
        - NLP
        - Machine Learning
        - word embeddings
        inputs:
        - volume: /veld/input/
          description: arbitrary storage for word2vec experiments
          file_type:
          - word2vec model
          - training data
          - NLP training data
          - raw text
          contents:
          - NLP model
          - word embeddings model
          - model metadata
          - NLP training data
          - word embeddings training data
          - raw text
        outputs:
        - volume: /veld/output/
          description: arbitrary storage for word2vec experiments
    services:
      veld_jupyter_notebook:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/jupyter_notebook/:/veld/code/:z
        - ./data/input/:/veld/input/:z
        - ./data/output/:/veld/output/:z
veld_code__word2vec___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__word2vec/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: word2vec training setup
        topics:
        - NLP
        - Machine Learning
        - word embeddings
        inputs:
        - volume: /veld/input/
          environment: in_train_data_file
          description: training data. Must be one single txt file, one sentence per
            line.
          file_type: txt
          contents:
          - NLP training data
          - word embeddings training data
          - raw text
        outputs:
        - volume: /veld/output/
          environment: out_model_file
          description: self trained word embeddings word2vec model
          file_type: word2vec model
          contents:
          - NLP model
          - word embeddings model
        settings:
        - environment: train_data_description
          description: short human description for the kind of training data
          env_type: string
          optional: true
        - environment: model_description
          description: short human description for the overall model and its purpose
          env_type: string
          optional: true
        - environment: epochs
          description: 'word2vec hyperparameter: number of training epochs'
          env_type: int
          optional: true
          default: 50
        - environment: vector_size
          description: 'word2vec hyperparameter: number of dimensions of the word
            vectors'
          env_type: int
          default: 200
        - environment: window
          description: 'word2vec hyperparameter: number of surrounding context words
            to be used for training.'
          env_type: int
          default: 3
        - environment: min_count
          description: 'word2vec hyperparameter: minimal number of occurrence for
            each word to be used for training.'
          env_type: int
          default: 5
    services:
      veld_train:
        build: .
        command: python /veld/code/train.py
        volumes:
        - ./src/train/:/veld/code/:z
        - ./data/training_data/:/veld/input/:z
        - ./data/models/:/veld/output/:z
        environment:
          in_train_data_file: null
          out_model_file: null
          model_description: null
          epochs: 50
          vector_size: 200
          window: 3
          min_count: 5
veld_code__wordembeddings_evaluation___veld_analyse_evaluation.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_analyse_evaluation.yaml
  content:
    x-veld:
      code:
        description: data visualization of all evaluation data. In a jupyter notebook.
        topics:
        - NLP
        - word embeddings
        - data visualization
        inputs:
        - volume: /veld/
          environment: in_evaluation_summary_file
          description: summary of the custom evaluation logic on word embeddings
          file_type: yaml
          contents: evaluation data
        outputs:
        - volume: /veld/output/
          environment: out_visualization_html_file
          description: data visualization of all evaluation data, expressed as interactive
            html
          file_type: html
          contents: data visualization
        - volume: /veld/output/
          environment: out_visualization_png_file
          description: data visualization of all evaluation data, expressed as png
          file_type: png
          contents: data visualization
    services:
      veld_analyse_evaluation:
        build:
          context: .
          dockerfile: ./build_analyse.dockerfile
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/analyse/:/veld/code/:z
        environment:
          in_evaluation_summary_file: null
          out_visualization_html_file: null
          out_visualization_png_file: null
veld_code__wordembeddings_evaluation___veld_analyse_evaluation_non_interactive.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_analyse_evaluation_non_interactive.yaml
  content:
    x-veld:
      code:
        description: data visualization of all evaluation data. non-interactive version
          of the juypter code.
        topics:
        - NLP
        - word embeddings
        - data visualization
        inputs:
        - volume: /veld/
          environment: in_evaluation_summary_file
          description: summary of the custom evaluation logic on word embeddings
          file_type: yaml
          contents: evaluation data
        outputs:
        - volume: /veld/output/
          environment: out_visualization_html_file
          description: data visualization of all evaluation data, expressed as interactive
            html
          file_type: html
          contents: data visualization
        - volume: /veld/output/
          environment: out_visualization_png_file
          description: data visualization of all evaluation data, expressed as png
          file_type: png
          contents: data visualization
    services:
      veld_analyse_evaluation:
        build:
          context: .
          dockerfile: ./build_analyse.dockerfile
        command: ./analyse.sh
        volumes:
        - ./src/analyse/:/veld/code/:z
        environment:
          in_evaluation_summary_file: null
          out_visualization_html_file: null
          out_visualization_png_file: null
veld_code__wordembeddings_evaluation___veld_eval_fasttext.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_eval_fasttext.yaml
  content:
    x-veld:
      code:
        description: custom evaluation logic on fasttext word embeddings.
        topics:
        - NLP
        - Machine learning
        - evaluation
        inputs:
        - volume: /veld/input/model/
          environment: in_model_file
          file_type: fasttext model
          contents:
          - NLP model
          - word embeddings model
        - volume: /veld/input/model/
          environment: in_model_metadata_file
          file_type: yaml
          contents: metadata
        - volume: /veld/input/eval_data/
          environment: in_eval_gold_data_file
          file_type: yaml
          contents: NLP gold data
        outputs:
        - volume: /veld/output/summary/
          environment: out_eval_summary_file
          file_type: yaml
          description: ''
          contents: ''
        - volume: /veld/output/log/
          environment: out_eval_log_file
          file_type: txt
          contents: logs
    services:
      veld_eval_fasttext:
        build:
          context: .
          dockerfile: ./build_fasttext.dockerfile
        command: python eval_fasttext.py
        volumes:
        - ./src/:/veld/code/:z
        environment:
          in_model_file: null
          in_model_metadata_file: null
          in_2_eval_gold_data_file: null
          out_1_eval_summary_file: null
          out_2_eval_log_file: null
veld_code__wordembeddings_evaluation___veld_eval_glove.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_eval_glove.yaml
  content:
    x-veld:
      code:
        description: custom evaluation logic on GloVe word embeddings.
        topics:
        - NLP
        - Machine learning
        - evaluation
        inputs:
        - volume: /veld/input/model/
          environment: in_vector_file
          file_type: GloVe vector model
          contents:
          - NLP model
          - word embeddings model
        - volume: /veld/input/model/
          environment: in_model_metadata_file
          file_type: yaml
          contents: metadata
        - volume: /veld/input/eval_data/
          environment: in_eval_gold_data_file
          file_type: yaml
          contents: NLP gold data
        outputs:
        - volume: /veld/output/summary/
          environment: out_eval_summary_file
          file_type: yaml
          description: ''
          contents: ''
        - volume: /veld/output/log/
          environment: out_eval_log_file
          file_type: txt
          contents: logs
        settings:
        - environment: model_id
          description: id of the model
          env_type: str
    services:
      veld_eval_glove:
        build:
          context: .
          dockerfile: ./build_glove.dockerfile
        command: python3 eval_glove.py
        volumes:
        - ./src/:/veld/code/:z
        environment:
          in_1_vector_file: null
          model_id: null
          in_1_model_metadata_file: null
          in_2_eval_gold_data_file: null
          out_1_eval_summary_file: null
          out_2_eval_log_file: null
veld_code__wordembeddings_evaluation___veld_eval_word2vec.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_eval_word2vec.yaml
  content:
    x-veld:
      code:
        description: custom evaluation logic on word2vec word embeddings.
        topics:
        - NLP
        - Machine learning
        - evaluation
        inputs:
        - volume: /veld/input/model/
          environment: in_model_file
          description: word2vec model file to be evaluated
          file_type: word2vec model
          contents:
          - NLP model
          - word embeddings model
        - volume: /veld/input/model/
          environment: in_model_metadata_file
          description: word2vec model metadata
          file_type: yaml
          contents: metadata
        - volume: /veld/input/eval_data/
          environment: in_eval_gold_data_file
          file_type: yaml
          contents: NLP gold data
        outputs:
        - volume: /veld/output/summary/
          environment: out_eval_summary_file
          file_type: yaml
          description: ''
          contents: ''
        - volume: /veld/output/log/
          environment: out_eval_log_file
          file_type: txt
          contents: logs
    services:
      veld_eval_word2vec:
        build:
          context: .
          dockerfile: ./build_word2vec.dockerfile
        command: python eval_word2vec.py
        volumes:
        - ./src/:/veld/code/:z
        - ./data/models/:/veld/input/1/:z
        - ./data/evaluation_gold_data/:/veld/input/2/:z
        - ./data/evaluation_results/summary/:/veld/output/1/:z
        - ./data/evaluation_results/logs/:/veld/output/2/:z
        environment:
          in_1_model_file: null
          in_1_model_metadata_file: null
          in_2_eval_gold_data_file: null
          out_1_eval_summary_file: null
          out_2_eval_log_file: null
veld_code__wordembeddings_preprocessing___veld_preprocess_clean.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_clean.yaml
  content:
    x-veld:
      code:
        description: Removes lines that don't reach a threshold regarding the ratio
          of textual content to non-textual (numbers, special characters) content.
          Splits output into clean and dirty file.
        topics:
        - NLP
        - preprocessing
        - ETL
        inputs:
        - volume: /veld/input/
          environment: in_file
          file_type: txt
          contents: raw text
        outputs:
        - volume: /veld/output/
          environment: out_file_clean
          description: clean lines, where each line's ratio is above the configured
            threshold
          file_type: txt
          contents: raw text
        - volume: /veld/output/
          environment: out_file_dirty
          description: dirty lines, where each line's ratio is below the configured
            threshold
          file_type: txt
          contents: raw text
        settings:
        - environment: min_percentage_char
          description: threshold above which a line is considered clean. E.g. 80 means
            80% of character of a line must be textual
          env_type: int
        - environment: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          env_type: str
        - environment: cpu_count
          description: number of cpu cores allocated to this processing. Defaults
            to maximum number of available cores
          env_type: int
        - environment: buffer_segments
          description: percentage of segments where processing results are persisted
            in between. So that processing could continue should it have crashed
          env_type: int
          default: 100
        - environment: sleep_duration
          description: number of seceonds between each multiprocess invokation, since
            with big data, a memory race condition can occurr. To work-around this,
            a small waiting period in between can be set with this variable.
          env_type: int
          default: 10
    services:
      veld_preprocess_clean:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 /veld/code/preprocess_clean.py
        environment:
          in_file: null
          out_file_clean: null
          out_file_dirty: null
          out_data_veld_yaml: null
          min_percentage_char: null
          out_data_description: null
          cpu_count: null
          buffer_segments: 100
          sleep_duration: 10
veld_code__wordembeddings_preprocessing___veld_preprocess_lowercase.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_lowercase.yaml
  content:
    x-veld:
      code:
        description: makes entire text lowercase
        topics:
        - NLP
        - preprocessing
        - ETL
        inputs:
        - volume: /veld/input/
          environment: in_txt_file
          file_type: txt
          contents: raw text
        outputs:
        - volume: /veld/output/
          environment: out_txt_file
          file_type: txt
          contents: raw text
        settings:
        - environment: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          env_type: str
    services:
      veld_preprocess_lowercase:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 /veld/code/preprocess_lowercase.py
        environment:
          in_txt_file: null
          out_txt_file: null
          out_data_description: null
veld_code__wordembeddings_preprocessing___veld_preprocess_remove_punctuation.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_remove_punctuation.yaml
  content:
    x-veld:
      code:
        description: removes punctuation from text with spaCy pretrained models
        topics:
        - NLP
        - preprocessing
        - ETL
        inputs:
        - volume: /veld/input/
          environment: in_txt_file
          file_type: txt
          contents: raw text
        outputs:
        - volume: /veld/output/txt/
          environment: out_txt_file
          file_type: txt
          contents: raw text
        - volume: /veld/output/tmp/
          file_type: txt
          contents: raw text
        settings:
        - environment: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          env_type: str
        - environment: cpu_count
          description: number of cpu cores allocated to this processing. Defaults
            to maximum number of available cores
          env_type: int
        - environment: buffer_segments
          description: percentage of segments where processing results are persisted
            in between. So that processing could continue should it have crashed
          env_type: int
          default: 100
        - environment: sleep_duration
          description: number of seceonds between each multiprocess invokation, since
            with big data, a memory race condition can occurr. To work-around this,
            a small waiting period in between can be set with this variable.
          env_type: int
          default: 10
    services:
      veld_preprocess_remove_punctuation:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 -u /veld/code/preprocess_remove_punctuation.py
        environment:
          in_txt_file: null
          out_txt_file: null
          cpu_count: null
          buffer_segments: 100
          out_data_description: null
          sleep_duration: 10
veld_code__wordembeddings_preprocessing___veld_preprocess_sample.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_sample.yaml
  content:
    x-veld:
      code:
        description: takes a random sample of lines from a txt file. Randomness can
          be set with a seed too
        topics:
        - NLP
        - preprocessing
        - ETL
        inputs:
        - volume: /veld/input/
          environment: in_txt_file
          file_type: txt
          contents: raw text
        outputs:
        - volume: /veld/output/
          environment: out_txt_file
          file_type: txt
          contents: raw text
        settings:
        - environment: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          env_type: str
        - environment: percentage_sample
          description: percentage of lines to be randomly sampled
          env_type: int
        - environment: sample_random_seed
          description: seed to make randomness stable and reproducible
          env_type: str
        - environment: buffer_segments
          description: percentage of segments where processing results are persisted
            in between. So that processing could continue should it have crashed
          env_type: int
          default: 100
    services:
      veld_preprocess_sample:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 /veld/code/preprocess_sample.py
        environment:
          in_file: null
          out_file: null
          out_data_description: null
          percentage_sample: null
          sample_random_seed: null
          buffer_segments: 100
veld_code__wordembeddings_preprocessing___veld_preprocess_strip.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_strip.yaml
  content:
    x-veld:
      code:
        description: removes all lines before and after given line numbers
        topics:
        - NLP
        - preprocessing
        - ETL
        inputs:
        - volume: /veld/input/
          environment: in_file
          file_type: txt
          contents: raw text
        outputs:
        - volume: /veld/output/
          environment: out_file
          file_type: txt
          contents: raw text
        settings:
        - environment: line_start
          description: line number before which lines will be stripped away. E.g.
            line_start=50 removes lines from 1-49
          env_type: int
        - environment: line_end
          description: line number after which lines will be stripped away. E.g. line_end=100
            removes lines from 101-end
          env_type: int
    services:
      veld_preprocess_strip:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: /veld/code/preprocess_strip.sh
        environment:
          in_file: null
          out_file: null
          line_start: null
          line_end: null
veld_code__xmlanntools___veld_ann2standoff.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_ann2standoff.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the ann2standoff script. For more
          documentation, see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#ann2standoff'
        topics:
        - NLP
        - ETL
        inputs:
        - volume: /veld/input/data/
          environment: in_conllu_file
          file_type:
          - conllu
          - tsv
        - volume: /veld/input/data/
          environment: in_txt_file
          file_type: txt
        - volume: /veld/input/config/
          environment: in_ann2standoff_ini_file
          file_type: ini
        outputs:
        - volume: /veld/output/
          environment: out_json_file
          file_type: json
        settings:
        - environment: profile_name
          env_type: str
          default: DEFAULT
          optional: true
    services:
      veld_ann2standoff:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/ann2standoff/in/data/:/veld/input/data/
        - ./data/ann2standoff/in/config/:/veld/input/config/
        - ./data/ann2standoff/out/:/veld/output/
        command: ./veld_ann2standoff.sh
        environment:
          in_conllu_file: null
          in_txt_file: null
          in_ann2standoff_ini_file: null
          out_json_file: null
          profile_name: DEFAULT
veld_code__xmlanntools___veld_standoff2xml.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_standoff2xml.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the standoff2xml script. For more
          documentation, see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#standoff2xml'
        topics:
        - NLP
        - ETL
        inputs:
        - volume: /veld/input/
          environment: in_txt_file
          file_type: txt
        - volume: /veld/input/
          environment: in_json_file
          file_type: json
        - volume: /veld/input/
          environment: in_ann_json_file
          file_type: json
        outputs:
        - volume: /veld/output/
          environment: out_ann_xml_file
          file_type: xml
        settings:
        - environment: token_annotation
          env_type: bool
          default: false
          optional: true
        - environment: warn_breaking
          env_type: str
          optional: true
        - environment: keep_between_sentences
          env_type: bool
          default: false
          optional: true
    services:
      veld_standoff2xml:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/standoff2xml/in/:/veld/input/
        - ./data/standoff2xml/out/:/veld/output/
        command: ./veld_standoff2xml.sh
        environment:
          in_txt_file: null
          in_json_file: null
          in_ann_json_file: null
          out_ann_xml_file: null
          token_annotation: false
          warn_breaking: null
          keep_between_sentences: false
veld_code__xmlanntools___veld_tag_ud.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_tag_ud.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the tag_ud script. For more documentation,
          see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#tag_ud'
        topics:
        - NLP
        - ETL
        inputs:
        - volume: /veld/input/
          environment: in_txt_file
          file_type: txt
        outputs:
        - volume: /veld/output/
          environment: out_conllu_file
          file_type:
          - tsv
          - conllu
        settings:
        - environment: model
          env_type: str
        - environment: batch
          env_type: int
          default: 1000
          optional: true
        - environment: verbose
          env_type: bool
          default: false
          optional: true
    services:
      veld_tag_ud:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/tag_ud/in/:/veld/input/
        - ./data/tag_ud/out/:/veld/output/
        command: ./veld_tag_ud.sh
        environment:
          in_txt_file: null
          out_conllu_file: null
          model: null
          batch: 1000
          verbose: false
veld_code__xmlanntools___veld_xml2standoff.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_xml2standoff.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the xml2standoff script. For more
          documentation, see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#xml2standoff'
        topics:
        - NLP
        - ETL
        inputs:
        - volume: /veld/input/
          environment: in_xml_file
          file_type: xml
        outputs:
        - volume: /veld/output/
          environment: out_txt_file
          file_type: txt
        - volume: /veld/output/
          environment: out_json_file
          file_type: json
        settings:
        - environment: text_elements
          env_type: str
          optional: true
        - environment: exclude_elements
          env_type: str
          optional: true
        - environment: keep_linebreaks
          env_type: bool
          default: false
          optional: true
    services:
      veld_xml2standoff:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/xml2standoff/in/:/veld/input/
        - ./data/xml2standoff/out/:/veld/output/
        command: ./veld_xml2standoff.sh
        environment:
          in_xml_file: null
          out_txt_file: null
          out_json_file: null
          text_elements: null
          exclude_elements: null
          keep_linebreaks: false
veld_code__xmlanntools___veld_xml2vrt.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_xml2vrt.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the xml2vrt script. For more documentation,
          see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#xml2vrt'
        topics:
        - NLP
        - ETL
        inputs:
        - volume: /veld/input/data/
          environment: in_ann_xml_file
          file_type: xml
        - volume: /veld/input/config/
          environment: in_ann2standoff_ini_file
          file_type: ini
        outputs:
        - volume: /veld/output/
          environment: out_conlluish_xml_file
          file_type: xml
        settings:
        - environment: attributes
          env_type: str
          optional: true
        - environment: token_element
          env_type: str
          optional: true
        - environment: include_elements
          env_type: str
          optional: true
        - environment: exclude_elements
          env_type: str
          optional: true
        - environment: keep_token_tags
          env_type: bool
          default: false
          optional: true
        - environment: keep_empty
          env_type: bool
          default: false
          optional: true
        - environment: discard_freetext
          env_type: bool
          default: false
          optional: true
        - environment: no_glue
          env_type: bool
          default: false
          optional: true
        - environment: glue
          env_type: str
          optional: true
        - environment: fragment
          env_type: bool
          default: false
          optional: true
        - environment: no_flattening
          env_type: bool
          default: false
          optional: true
    services:
      veld_xml2vrt:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/xml2vrt/in/data/:/veld/input/data/
        - ./data/xml2vrt/in/config/:/veld/input/config/
        - ./data/xml2vrt/out/:/veld/output/
        command: ./veld_xml2vrt.sh
        environment:
          in_ann_xml_file: null
          in_ann2standoff_ini_file: null
          out_conlluish_xml_file: null
          attributes: null
          token_element: null
          include_elements: null
          exclude_elements: null
          keep_token_tags: false
          keep_empty: false
          discard_freetext: false
          no_glue: false
          glue: null
          fragment: false
          no_flattening: false
veld_chain__akp_ner_inference___veld_infer.yaml:
  url: https://github.com/veldhub/veld_chain__akp_ner_inference/blob/main/veld_infer.yaml
  content:
    x-veld:
      chain:
        description: This repo uses self-trained spaCy NER models on the linkedcat
          dataset to extract entities, which are stored in csv files.
        topics:
        - NLP
        - Machine learning
        - Named entity recognition
    services:
      veld_infer:
        extends:
          file: ./code/veld_code__akp_ner_inference/veld_infer.yaml
          service: veld_infer
        volumes:
        - ./data/veld_data__apis_spacy_ner_models/m1/model-best/:/veld/input/
        - ./data/veld_data__akp_ner_linkedcat/linkedcat2/:/veld/output/
        environment:
          solr_core_url: http://linkedcat-solr.acdh-cluster-2.arz.oeaw.ac.at/solr/linkedcat2
          out_csv_file: linkedcat2.csv
veld_chain__apis_ner_evaluate_old_models___veld_evaluate.yaml:
  url: https://github.com/veldhub/veld_chain__apis_ner_evaluate_old_models/blob/main/veld_evaluate.yaml
  content:
    x-veld:
      chain:
        description: hard-coded evaluation of several spaCy 2.2.4 models.
        topics:
        - NLP
        - Machine learning
        - Named entity recognition
    services:
      veld_evaluate:
        extends:
          file: ./code/veld_code__apis_ner_evaluate_old_models/veld_evaluate.yaml
          service: veld_evaluate
        volumes:
        - ./data/spacy-ner/:/veld/input/
        - ./data/spacy-ner/:/veld/output/
        environment:
          out_eval_result_file: reevaluations_all.md
veld_chain__apis_ner_transform_to_gold___veld.yaml:
  url: https://github.com/veldhub/veld_chain__apis_ner_transform_to_gold/blob/main/veld.yaml
  content:
    x-veld:
      chain:
        description: Conversion of apis ner model data to harmonized custom json format.
        topics:
        - ETL
        - data cleaning
    services:
      veld:
        extends:
          file: ./code/veld_code__apis_ner_transform_to_gold/veld.yaml
          service: veld
        volumes:
        - ./data/veld_data__apis_spacy_ner_legacy/:/veld/input/
        - ./data/veld_data__apis_oebl__ner_gold/data_uncleaned:/veld/output/uncleaned/
        - ./data/veld_data__apis_oebl__ner_gold/data_cleaned:/veld/output/cleaned/
        - ./data/veld_data__apis_oebl__ner_gold/data_cleaned_simplified:/veld/output/cleaned_simplified/
        - ./:/veld/output/log/
        environment:
          out_json_uncleaned_file: uncleaned.json
          out_json_cleaned_file: cleaned.json
          out_json_cleaned_simplified_file: cleaned_simplified.json
          out_log_file: extract_and_clean.log
veld_chain__demo_teitok-tools___veld_parseudpipe.yaml:
  url: https://github.com/veldhub/veld_chain__demo_teitok-tools/blob/main/veld_parseudpipe.yaml
  content:
    x-veld:
      chain:
        description: 'This chain veld exemplifies usage of the respective code veld.
          For more information on the underlying tool and its usage, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#parseudpipe'
        topics:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
    services:
      veld_parseudpipe:
        extends:
          file: ./code/veld_code__teitok-tools/veld_parseudpipe.yaml
          service: veld_parseudpipe
        volumes:
        - ./data/parseudpipe/in/:/veld/input/
        - ./data/parseudpipe/out/:/veld/output/
        environment:
          in_xml_file: DEU001_tokenized.xml
          out_xml_file: DEU001.xml
          model: german-hdt-ud-2.6-200830
          sent: p
veld_chain__demo_teitok-tools___veld_udpipe2teitok.yaml:
  url: https://github.com/veldhub/veld_chain__demo_teitok-tools/blob/main/veld_udpipe2teitok.yaml
  content:
    x-veld:
      chain:
        description: 'This chain veld exemplifies usage of the respective code veld.
          For more information on the underlying tool and its usage, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#udpipe2teitok'
        topics:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
    services:
      veld_udpipe2teitok:
        extends:
          file: ./code/veld_code__teitok-tools/veld_udpipe2teitok.yaml
          service: veld_udpipe2teitok
        volumes:
        - ./data/udpipe2teitok/in/:/veld/input/
        - ./data/udpipe2teitok/out/:/veld/output/
        environment:
          lang: de
          model: german-hdt-ud-2.6-200830
          mixed: true
veld_chain__demo_teitok-tools___veld_xmltokenize.yaml:
  url: https://github.com/veldhub/veld_chain__demo_teitok-tools/blob/main/veld_xmltokenize.yaml
  content:
    x-veld:
      chain:
        description: 'This chain veld exemplifies usage of the respective code veld.
          For more information on the underlying tool and its usage, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#xmltokenize'
        topics:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
    services:
      veld_xmltokenize:
        extends:
          file: ./code/veld_code__teitok-tools/veld_xmltokenize.yaml
          service: veld_xmltokenize
        volumes:
        - ./data/xmltokenize/in/:/veld/input/
        - ./data/xmltokenize/out/:/veld/output/
        environment:
          in_xml_file: DEU001.xml
          out_xml_file: DEU001.xml
          textnode: body
          tok: xyz
          enumerate: true
veld_chain__demo_udipe_ts-vienna-2024___veld_infer.yaml:
  url: https://github.com/veldhub/veld_chain__demo_udipe_ts-vienna-2024/blob/main/veld_infer.yaml
  content:
    x-veld:
      chain:
        description: A demonstration of a VELD chain inferencing on a txt with a self-trained
          udpipe model
        topics:
        - NLP
        - universal dependencies
    services:
      veld_infer:
        extends:
          file: ./code/veld_code__udpipe/veld_infer.yaml
          service: veld_infer
        volumes:
        - ./data/veld_data__demo_inference_input_ts-vienna-2024/:/veld/input/txt/
        - ./data/veld_data__demo_updipe_models_ts-vienna-2024/:/veld/input/model/
        - ./data/veld_data__demo_inference_output_ts-vienna-2024/:/veld/output/
        environment:
          in_txt_file: rumpelstiltskin.txt
          in_model_file: en_ewt-ud.udpipe
veld_chain__demo_udipe_ts-vienna-2024___veld_train.yaml:
  url: https://github.com/veldhub/veld_chain__demo_udipe_ts-vienna-2024/blob/main/veld_train.yaml
  content:
    x-veld:
      chain:
        description: A demonstration of a VELD chain training a udpipe model from
          scratch
        topics:
        - NLP
        - universal dependencies
    services:
      veld_train:
        extends:
          file: ./code/veld_code__udpipe/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/veld_data__demo_train_data_ts-vienna-2024/:/veld/input/
        - ./data/veld_data__demo_updipe_models_ts-vienna-2024/:/veld/output/
        environment:
          train_data_path: en_ewt-ud.conllu
          model_path: en_ewt-ud.udpipe
          tokenizer_epochs: 2
          tagger_iterations: 2
          parser_iterations: 2
veld_chain__demo_wordembeddings_multiarch___veld_jupyter_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_jupyter_word2vec.yaml
  content:
    x-veld:
      chain:
        description: demo word2vec jupyter notebook
        topics:
        - NLP
        - Machine Learning
        - word embeddings
    services:
      veld_jupyter_notebook:
        extends:
          file: ./code/veld_code__word2vec/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/models/word2vec/:/veld/input/:z
veld_chain__demo_wordembeddings_multiarch___veld_preprocess.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_preprocess.yaml
  content:
    x-veld:
      chain:
        description: Download and preprocessing of the bible
        topics:
        - ETL
        - NLP
        - bible studies
    services:
      veld_downloader:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/training_data/:/veld/output/
        environment:
          url: https://raw.githubusercontent.com/mxw/grmr/master/src/finaltests/bible.txt
          out_file: bible.txt
      veld_bible_preprocess:
        build: ./code/bible_preprocess/
        command: python /veld/code/bible_preprocess.py
        volumes:
        - ./code/bible_preprocess/bible_preprocess.py:/veld/code/bible_preprocess.py
        - ./data/training_data/:/veld/input/
        - ./data/training_data/:/veld/output/
        environment:
          in_file: bible.txt
          out_file: bible.txt
        depends_on:
          veld_downloader:
            condition: service_completed_successfully
veld_chain__demo_wordembeddings_multiarch___veld_train_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_train_word2vec.yaml
  content:
    x-veld:
      chain:
        description: demo word2vec training on the bible
        topics:
        - NLP
        - Machine Learning
        - word embeddings
    services:
      veld_train:
        extends:
          file: ./code/veld_code__word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/:/veld/input/
        - ./data/models/word2vec/m1/:/veld/output/
        environment:
          in_train_data_file: bible.txt
          out_model_file: m1.bin
          model_description: trained on bible with simple hyperparams
          epochs: 20
          vector_size: 200
          window: 5
          min_count: 5
veld_chain__eltec_udpipe_inference___veld_analyse.yaml:
  url: https://github.com/veldhub/veld_chain__eltec_udpipe_inference/blob/main/veld_analyse.yaml
  content:
    x-veld:
      chain:
        description: chain to analyse the conllu data which was inferenced by udpipe
          on several ELTeC corpora.
        topics:
        - NLP
        - Machine learning
        - tokenization
        - lemmatization
        - part of speech
        - dependency parsing
        - universal dependencies
        - grammatical annotation
    services:
      veld_analyse:
        extends:
          file: ./code/veld_code__analyse_conllu/veld.yaml
          service: veld
        volumes:
        - ./data/data_tmp_conllu_inferenced/:/veld/input/
        - ./data/veld_data__eltec_conllu_stats/data/:/veld/output/
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_analyse_evaluation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_analyse_evaluation.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_analyse_evaluation:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_analyse_evaluation.yaml
          service: veld_analyse_evaluation
        volumes:
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/input/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/:z
        environment:
          in_evaluation_summary_file: summary.yaml
          out_visualization_html_file: summary_visualized.html
          out_visualization_png_file: summary_visualized.png
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_analyse_evaluation_non_interactive.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_analyse_evaluation_non_interactive.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_analyse_evaluation_non_interactive:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_analyse_evaluation_non_interactive.yaml
          service: veld_analyse_evaluation
        volumes:
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/input/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/:z
        environment:
          in_evaluation_summary_file: summary.yaml
          out_visualization_html_file: summary_visualized.html
          out_visualization_png_file: summary_visualized.png
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_eval_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_eval_glove.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_eval_glove:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_glove.yaml
          service: veld_eval_glove
        volumes:
        - ./data/veld_data__glove_models/data/m3/:/veld/input/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/glove/:/veld/output/2/:z
        environment:
          in_1_vector_file: m3_vector.txt
          model_id: m3
          in_1_model_metadata_file: veld.yaml
          in_2_eval_gold_data_file: eval_data_lowercase.yaml
          out_1_eval_summary_file: summary.yaml
          out_2_eval_log_file: m3.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_eval_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_eval_word2vec.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_eval_word2vec:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_word2vec.yaml
          service: veld_eval_word2vec
        volumes:
        - ./data/veld_data__word2vec_models/m9/:/veld/input/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/word2vec/:/veld/output/2:z
        environment:
          in_1_model_file: m9.bin
          in_1_model_metadata_file: veld.yaml
          in_2_eval_gold_data_file: eval_data_lowercase.yaml
          out_1_eval_summary_file: summary.yaml
          out_2_eval_log_file: m9.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_clean.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_clean.yaml
  content:
    x-veld:
      code: null
    services:
      veld_preprocess_clean:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_clean.yaml
          service: veld_preprocess_clean
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed/:/veld/input/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/:/veld/output/1/:z
        - ./tmp_clean/:/veld/output/2/clean/:z
        - ./tmp_dirty/:/veld/output/2/dirty/:z
        environment:
          in_file: data.txt
          out_file_clean: data.txt
          out_file_dirty: data_dirty.txt
          min_percentage_char: 80
          out_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
            sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          cpu_count: 15
          buffer_segments: 100
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_lowercase.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_lowercase.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_preprocess_lowercase:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled/:/veld/input/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased/:/veld/output/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
            sampled, lowercased.'
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_remove_punctuation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_remove_punctuation.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_preprocess_remove_punctuation:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased/:/veld/input/:z
        - ./tmp/:/veld/output/2/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed/:/veld/output/1/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: 'AMC data: stripped from non-alphanumeric lines, lowercased,
            punctuation removed.'
          cpu_count: 14
          buffer_segments: 1000
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_sample.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_sample.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_preprocess_sample:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_sample.yaml
          service: veld_preprocess_sample
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped/:/veld/input/:z
        - ./exp_bert_tmp/:/veld/output/:z
        environment:
          in_file: data.txt
          out_file: data.txt
          out_data_description: 10% of AMC
          percentage_sample: 0.01
          sample_random_seed: 42
          buffer_segments: 100
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_strip.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_strip.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_preprocess_strip:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_strip.yaml
          service: veld_preprocess_strip
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq/:/veld/input/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped/:/veld/output/:z
        environment:
          in_file: data.txt
          out_file: data.txt
          line_start: 54993
          line_end: 521781020
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_train_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_train_fasttext.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_train_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_train.yaml
          service: veld_train
        volumes:
        - ./veld_data_amc_we_training_data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/:/veld/input/:z
        - ./veld_data_fasttext_models/m9/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m9.bin
          model_description: 100% AMC model
          vector_size: 300
          epochs: 10
          window_size: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_train_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_train_glove.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_train_glove:
        extends:
          file: ./code/veld_code__glove/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed__cleaned/:/veld/input/:z
        - ./data/veld_data__glove_models/data/m4/:/veld/output/:z
        environment:
          in_corpus_file: data.txt
          out_vocab_file: m4_vocab.txt
          out_cooccurrence_file: m4_cooccurrence.bin
          out_cooccurrence_shuf_file: m4_cooccurrence_shuf.bin
          out_vector_file: m4_vector
          model_id: m4
          model_description: 10% AMC model
          verbose: 2
          memory: 4.0
          vocab_min_count: 5
          vector_size: 200
          max_iter: 10
          window_size: 15
          binary: 2
          num_threads: 14
          x_max: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_train_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_train_word2vec.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_train_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/:/veld/input/:z
        - ./data/veld_data__word2vec_models/m8/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m8.bin
          model_description: 100% AMC model
          epochs: 10
          vector_size: 300
          window: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_playground_jupyter_notebook_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_playground_jupyter_notebook_fasttext.yaml
  content:
    x-veld:
      chain:
        description: jupyter notebook for playing with fasttext models
        topics: NLP
    services:
      veld_jupyter_notebook_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/training_data/:/veld/storage/training_data/:z
        - ./data/models/fasttext/:/veld/storage/models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_playground_jupyter_notebook_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_playground_jupyter_notebook_glove.yaml
  content:
    x-veld:
      chain:
        description: jupyter notebook for playing with glove models
        topics: NLP
    services:
      veld_jupyter_notebook_glove:
        extends:
          file: ./code/veld_code__glove/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/training_data/:/veld/storage/training_data/:z
        - ./data/models/glove/:/veld/storage/models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_playground_jupyter_notebook_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_playground_jupyter_notebook_word2vec.yaml
  content:
    x-veld:
      chain:
        description: jupyter notebook for playing with word2vec models
        topics: NLP
    services:
      veld_jupyter_notebook_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/training_data/:/veld/storage/training_data/:z
        - ./data/models/word2vec/:/veld/storage/models/:z
? veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_01_preprocess_download_and_extract.yaml
: url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_01_preprocess_download_and_extract.yaml
  content:
    x-veld:
      chain:
        description: downloading wikipedia archive and extracting each article to
          a json file.
        topics:
        - NLP
        - Machine Learning
        - ETL
    services:
      veld_preprocess_download_and_extract:
        extends:
          file: ./code/veld_code__wikipedia_nlp_preprocessing/veld_download_and_extract.yaml
          service: veld_download_and_extract
        volumes:
        - ./data/training_data/extracted/:/veld/output/:z
        environment:
          wikipedia_dump_url: https://dumps.wikimedia.org/dewiki/latest/dewiki-latest-pages-articles.xml.bz2
? veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_02_preprocess_transform_wiki_json_to_txt.yaml
: url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_02_preprocess_transform_wiki_json_to_txt.yaml
  content:
    x-veld:
      chain:
        description: transforming wikipedia jsons to a single txt file.
        topics:
        - NLP
        - Machine Learning
        - ETL
    services:
      veld_preprocess_transform_wiki_json_to_txt_articles:
        extends:
          file: ./code/veld_code__wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data/training_data/extracted/data/:/veld/input/:z
        - ./data/training_data/extracted__txt_article_per_line/:/veld/output/:z
        environment:
          out_txt_file: data.txt
          out_data_description: 10% german wikipedia, transformed from json files
            into one txt file, each json file's content persisted with each each article
            in a single line.
          set_split_sentences: false
          sample_size_percentage: 10
          cpu_count: 14
          buffer_segments: 10
      veld_preprocess_transform_wiki_json_to_txt_sentences:
        extends:
          file: ./code/veld_code__wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data/training_data/extracted/data/:/veld/input/:z
        - ./data/training_data/extracted__txt_sentence_per_line/:/veld/output/:z
        environment:
          out_txt_file: data.txt
          out_data_description: 10% german wikipedia, transformed from json files
            into one txt file, each json file's content persisted with each sentence
            in a single line.
          set_split_sentences: true
          sample_size_percentage: 10
          cpu_count: 14
          buffer_segments: 10
        depends_on:
          veld_preprocess_transform_wiki_json_to_txt_articles:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_03_preprocess_lowercase.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_03_preprocess_lowercase.yaml
  content:
    x-veld:
      chain:
        description: preprocessing by making the entire text lowercase.
        topics: NLP
    services:
      veld_preprocess_lowercase_articles:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data/training_data/extracted__txt_article_per_line/:/veld/input/:z
        - ./data/training_data/extracted__txt_article_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased
      veld_preprocess_lowercase_sentences:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line/:/veld/input/:z
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased
        depends_on:
          veld_preprocess_lowercase_articles:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_04_preprocess_remove_punctuation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_04_preprocess_remove_punctuation.yaml
  content:
    x-veld:
      chain:
        description: preprocessing by removing punctuation of the entire text.
        topics: NLP
    services:
      veld_preprocess_remove_punctuation_articles:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data/training_data/extracted__txt_article_per_line__lowercased/:/veld/input/:z
        - ./data/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/output/txt/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased, punctuation removed
          cpu_count: 14
          buffer_segments: 100
      veld_preprocess_remove_punctuation_sentences:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/input/:z
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/output/txt/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased, punctuation removed
          cpu_count: 14
          buffer_segments: 100
        depends_on:
          veld_preprocess_remove_punctuation_articles:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_05_train_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_05_train_fasttext.yaml
  content:
    x-veld:
      chain:
        description: training a fasttext model on wikipediaa
        topics: NLP
    services:
      veld_train_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data/models/fasttext/m1/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m1.bin
          model_description: 10% wikipedia test model
          vector_size: 200
          epochs: 5
          window_size: 5
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_06_train_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_06_train_word2vec.yaml
  content:
    x-veld:
      chain:
        description: training a word2vec model on wikipediaa
        topics: NLP
    services:
      veld_train_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data/models/word2vec/m1/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m1.bin
          model_description: 10% wikipedia test model
          epochs: 5
          vector_size: 200
          window: 5
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_07_train_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_07_train_glove.yaml
  content:
    x-veld:
      chain:
        description: training a glove model on wikipediaa
        topics: NLP
    services:
      veld_train_glove:
        extends:
          file: ./code/veld_code__glove/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data/models/glove/m1/:/veld/output/:z
        environment:
          in_corpus_file: data.txt
          out_vocab_file: m1_vocab.txt
          out_cooccurrence_file: m1_cooccurrence.bin
          out_cooccurrence_shuf_file: m1_cooccurrence_shuf.bin
          out_vector_file: m1_vector
          model_id: m1
          model_description: 10% wikipedia test model
          verbose: 2
          memory: 1.0
          vocab_min_count: 5
          vector_size: 200
          max_iter: 5
          window_size: 5
          binary: 2
          num_threads: 11
          x_max: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_08_eval_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_08_eval_fasttext.yaml
  content:
    x-veld:
      chain:
        description: evaluate fasttext model against evaluation gold data
        topics: NLP
    services:
      veld_eval_fasttext:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_fasttext.yaml
          service: veld_eval_fasttext
        volumes:
        - ./data/models/fasttext/m1/:/veld/input/model/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/eval_data/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/summary/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/fasttext/:/veld/output/log/:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_09_eval_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_09_eval_word2vec.yaml
  content:
    x-veld:
      chain:
        description: evaluate word2vec model against evaluation gold data
        topics: NLP
    services:
      veld_eval_word2vec:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_word2vec.yaml
          service: veld_eval_word2vec
        volumes:
        - ./data/models/word2vec/m1/:/veld/input/model/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/eval_data/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/summary/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/word2vec/:/veld/output/log/:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_10_eval_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_10_eval_glove.yaml
  content:
    x-veld:
      chain:
        description: evaluate glove model against evaluation gold data
        topics: NLP
    services:
      veld_eval_glove:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_glove.yaml
          service: veld_eval_glove
        volumes:
        - ./data/models/glove/m1/:/veld/input/model/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/eval_data/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/summary/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/glove/:/veld/output/log/:z
        environment:
          in_vector_file: m1_vector.txt
          model_id: m1
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_11_analyse_evaluation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_11_analyse_evaluation.yaml
  content:
    x-veld:
      chain:
        description: chain of analysing and evaluating models trained on wikipedia
        topics: NLP
    services:
      veld_analyse_evaluation:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_analyse_evaluation.yaml
          service: veld_analyse_evaluation
        volumes:
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/input/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/:z
        environment:
          in_evaluation_summary_file: summary.yaml
          out_visualization_html_file: summary_visualized.html
          out_visualization_png_file: summary_visualized.png
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_all_multi_chain.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_all_multi_chain.yaml
  content:
    x-veld:
      chain:
        description: An entire multi chain, going through everything (fetching, preprocessing,
          training, evaluation in one service. This chain is composed of the other
          chains and is rather meant as a demonstration of the entire setup
        topics: NLP
    services:
      veld_preprocess_transform_wiki_json_to_txt_fasttext-word2vec:
        extends:
          file: ./veld_code_20_wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data_local/training_data/extracted/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_sentence_per_line/:/veld/output/:z
        environment:
          in_json_folder: data
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, transformed from json files into
            one txt file, each json file's content is split into sentences and persisted
            per line. Best for fastText and word2vec.
          sample_size_percentage: 10
          set_split_sentences: true
          cpu_count: 14
          sample_random_seed: 42
          info_interval: 100
      veld_preprocess_transform_wiki_json_to_txt_glove:
        extends:
          file: ./veld_code_20_wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data_local/training_data/extracted/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_article_per_line/:/veld/output/:z
        environment:
          in_json_folder: data
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, transformed from json files into
            one txt file, each json file's content is persisted per line. Best for
            GloVe.
          sample_size_percentage: 10
          set_split_sentences: false
          cpu_count: 14
          sample_random_seed: 42
          info_interval: 100
        depends_on:
          veld_preprocess_transform_wiki_json_to_txt_fasttext-word2vec:
            condition: service_completed_successfully
      veld_preprocess_lowercase_fasttext-word2vec:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one sentence per line,
            lowercased,
        depends_on:
          veld_preprocess_transform_wiki_json_to_txt_glove:
            condition: service_completed_successfully
      veld_preprocess_lowercase_glove:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data_local/training_data/extracted__txt_article_per_line/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one article per line,
            lowercased
        depends_on:
          veld_preprocess_lowercase_fasttext-word2vec:
            condition: service_completed_successfully
      veld_preprocess_remove_punctuation_fasttext-word2vec:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one sentence per line,
            lowercased, removed punctuation
          cpu_count: 14
          info_interval: 100
        depends_on:
          veld_preprocess_lowercase_glove:
            condition: service_completed_successfully
      veld_preprocess_remove_punctuation_glove:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one article per line,
            lowercased, removed punctuation
          cpu_count: 14
          info_interval: 100
        depends_on:
          veld_preprocess_remove_punctuation_fasttext-word2vec:
            condition: service_completed_successfully
      veld_train_fasttext:
        extends:
          file: ./veld_code_12_fasttext/veld_train.yaml
          service: veld_train
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data_local/models/fasttext/m1/:/veld/output/:z
        environment:
          in_train_data_file: de_wiki_sample.txt
          model_id: m1
          model_description: fasttext test model
          vector_size: 200
          epochs: 10
        depends_on:
          veld_preprocess_remove_punctuation_glove:
            condition: service_completed_successfully
      veld_train_word2vec:
        extends:
          file: ./veld_code_13_word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data_local/models/word2vec/m1/:/veld/output/:z
        environment:
          in_train_data_file: de_wiki_sample.txt
          model_id: m1
          model_description: word2vec test model
          epochs: 10
          vector_size: 200
          window: 5
          min_count: 5
        depends_on:
          veld_train_fasttext:
            condition: service_completed_successfully
      veld_train_glove:
        extends:
          file: ./veld_code_17_glove/veld_train.yaml
          service: veld_train
        volumes:
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data_local/models/glove/m1/:/veld/output/:z
        environment:
          in_corpus_file: de_wiki_sample.txt
          out_vocab_file: m1_vocab.txt
          out_cooccurrence_file: m1_cooccurrence.bin
          out_cooccurrence_shuf_file: m1_cooccurrence_shuf.bin
          out_vector_file: m1_vector
          model_id: m1
          model_description: glove test model
          verbose: 2
          memory: 4.0
          vocab_min_count: 5
          vector_size: 200
          max_iter: 10
          window_size: 15
          binary: 2
          num_threads: 14
          x_max: 10
        depends_on:
          veld_train_word2vec:
            condition: service_completed_successfully
      veld_eval_fasttext:
        extends:
          file: ./veld_code_14_we_evaluation/veld_eval_fasttext.yaml
          service: veld_eval_fasttext
        volumes:
        - ./data_local/models/fasttext/m1/:/veld/input/1/:z
        - ./veld_data_10_we_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./veld_data_10_we_evaluation/evaluation_results/:/veld/output/1/:z
        - ./veld_data_10_we_evaluation/evaluation_results/logs/fasttext/:/veld/output/2:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
        depends_on:
          veld_train_glove:
            condition: service_completed_successfully
      veld_eval_word2vec:
        extends:
          file: ./veld_code_14_we_evaluation/veld_eval_word2vec.yaml
          service: veld_eval_word2vec
        volumes:
        - ./data_local/models/word2vec/m1/:/veld/input/1/:z
        - ./veld_data_10_we_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./veld_data_10_we_evaluation/evaluation_results/:/veld/output/1/:z
        - ./veld_data_10_we_evaluation/evaluation_results/logs/word2vec/:/veld/output/2:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
        depends_on:
          veld_eval_fasttext:
            condition: service_completed_successfully
      veld_eval_glove:
        extends:
          file: ./veld_code_14_we_evaluation/veld_eval_glove.yaml
          service: veld_eval_glove
        volumes:
        - ./data_local/models/glove/m1/:/veld/input/1/:z
        - ./veld_data_10_we_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./veld_data_10_we_evaluation/evaluation_results/:/veld/output/1/:z
        - ./veld_data_10_we_evaluation/evaluation_results/logs/glove/:/veld/output/2/:z
        environment:
          in_vector_file: m1_vector.txt
          model_id: m1
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
        depends_on:
          veld_eval_word2vec:
            condition: service_completed_successfully
veld_chain__train_spacy_apis_ner___veld_analysis.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_analysis.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_analysis:
        extends:
          file: ./code/analysis/compose.yaml
          service: veld_analysis
        volumes:
        - ./data/:/veld/input/
veld_chain__train_spacy_apis_ner___veld_convert.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_convert.yaml
  content:
    x-veld:
      chain:
        description: cleaning and converting json into spaCy docbin
        topics:
        - ETL
        - NLP
        - Machine learning
    services:
      veld_convert:
        extends:
          file: ./code/veld_code__spacy/veld_convert.yaml
          service: veld_convert
        volumes:
        - ./data/veld_data__apis_oebl__ner_gold/data_cleaned_simplified/:/veld/input/
        - ./data/docbin/:/veld/output/docbin/
        - ./:/veld/output/log/
        environment:
          in_json_file: cleaned_simplified.json
          out_log_file: veld_convert.log
          model_base: de_core_news_lg
veld_chain__train_spacy_apis_ner___veld_create_config.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_create_config.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_create_config:
        extends:
          file: ./code/veld_code__spacy/veld_create_config.yaml
          service: veld_create_config
        volumes:
        - ./data/configs/:/veld/output/
        environment:
          out_config_file: config_1.cfg
          lang: de
          ner: true
          optimize_accuracy: true
          pretraining: true
veld_chain__train_spacy_apis_ner___veld_publish_to_hf.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_publish_to_hf.yaml
  content:
    x-veld:
      chain:
        description: pushing spacy model to huggingface.
        topics: NLP
    services:
      veld_publish_to_hf:
        extends:
          file: ./code/veld_code__spacy/veld_publish_to_hf.yaml
          service: veld_publish_to_hf
        volumes:
        - ./data/veld_data__apis_spacy_ner_models/m1/model-best/:/veld/input/
        environment:
          model_name: m1
          version: '1.0'
veld_chain__train_spacy_apis_ner___veld_train.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_train.yaml
  content:
    x-veld:
      chain:
        description: A NER trainig setup, utilizing spaCy 3's config system.
        topics:
        - NLP
        - Machine learning
        - Named entity recognition
    services:
      veld_train:
        extends:
          file: ./code/veld_code__spacy/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/docbin/:/veld/input/docbin/
        - ./data/configs/:/veld/input/config/
        - ./data/veld_data__apis_spacy_ner_models/m2/:/veld/output/
        environment:
          in_train_docbin_file: train.spacy
          in_dev_docbin_file: dev.spacy
          in_eval_docbin_file: eval.spacy
          in_spacy_config: config_2.cfg
          model_base: de_core_news_lg
          out_train_log_file: train.log
          out_eval_log_file: eval.log
