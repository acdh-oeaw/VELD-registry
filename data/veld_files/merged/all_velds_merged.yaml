veld_data__akp_ner_linkedcat___linkedcat___veld.yaml:
  url: https://github.com/veldhub/veld_data__akp_ner_linkedcat/blob/main/linkedcat/veld.yaml
  content:
    x-veld:
      data:
        file_type: csv
        description: "Prefered dataset is not this one, but linkedcat2! This dataset\
          \ was created by applying a custom trained SpaCy NER model an APIS / \xD6\
          BL data, on data set 'linkedcat2' at our solr index. The csv file is split\
          \ into id column, character start index of recognized entity, character\
          \ end index of entity, label of entity type, and a small context window."
        topic:
        - NLP
        - Named Entity Recognition
        content:
        - NER data
        - inferenced NLP data
veld_data__akp_ner_linkedcat___linkedcat2___veld.yaml:
  url: https://github.com/veldhub/veld_data__akp_ner_linkedcat/blob/main/linkedcat2/veld.yaml
  content:
    x-veld:
      data:
        file_type: csv
        description: "Prefered dataset is this one, not linkedcat! This dataset was\
          \ created by applying a custom trained SpaCy NER model an APIS / \xD6BL\
          \ data, on data set 'linkedcat2' at our solr index. The csv file is split\
          \ into id column, character start index of recognized entity, character\
          \ end index of entity, label of entity type, and a small context window."
        topic:
        - NLP
        - Named Entity Recognition
        content:
        - NER data
        - inferenced NLP data
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: no metadata, only text, one sentence per line; Created
          by Hannes Pirker.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 63G
          number of lines: 652802789
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: no metadata, only text, one sentence per line, each
          sentence made unique by ordering AMC sentences alphabetically and removing
          dupcliates; Created by Hannes Pirker.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 58G
          number of lines: 521785159
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: unique sentence data, cleaned from non-alphanumeric
          junk before ''A'' (anything before line number 54,993) and after ''Z'' (anything
          after line number 521,781,020)'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 58G
          number of lines: 521726028
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
          lines, lowercased.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 58G
          number of lines: 521726064
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
          lines, lowercased, punctuation removed.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 56G
          number of lines: 521726064
? veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned___veld.yaml
: url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/veld.yaml
  content:
    x-veld:
      data:
        description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
          lines, lowercased, punctuation removed, removed sentences with too many
          non-alphanumeric characters.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        path: data.txt
        additional:
          data size: 54G
          number of lines: 485820330
          min_percentage_char: 80
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__sampled___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled/veld.yaml
  content:
    x-veld:
      data:
        description: '10% AMC: stripped from non-alphanumeric lines, 10% sampled.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 5.8G
          number of lines: 52172602
          percentage_sample: 10.0
          sample_random_seed: '42'
veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased___veld.yaml:
  url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased/veld.yaml
  content:
    x-veld:
      data:
        description: '10% AMC: stripped from non-alphanumeric lines, 10% sampled,
          lowercased.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 5.8G
          number of lines: 52172602
? veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed___veld.yaml
: url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed/veld.yaml
  content:
    x-veld:
      data:
        description: '10% AMC: stripped from non-alphanumeric lines, 10% sampled,
          lowercased, punctuation removed.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        additional:
          data size: 5.6G
          number of lines: 52172610
? veld_data__amc_we_training_data___203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed__cleaned___veld.yaml
: url: https://github.com/veldhub/veld_data__amc_we_training_data/blob/main/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed__cleaned/veld.yaml
  content:
    x-veld:
      data:
        description: '10% AMC: stripped from non-alphanumeric lines, 10% sampled,
          lowercased, punctuation removed, removed sentences with too many non-alphanumeric
          characters.'
        file_type: txt
        content:
        - raw text
        - newspaper texts
        topic: NLP
        path: data.txt
        additional:
          data size: 5.4G
          number of clean lines: 48582220
          number of dirty removed lines: 3590390
          minimum number of characters in percentage of each line: 80.0
veld_data__apis_oebl__ner_gold___data_cleaned___veld.yaml:
  url: https://github.com/veldhub/veld_data__apis_oebl__ner_gold/blob/main/data_cleaned/veld.yaml
  content:
    x-veld:
      data:
        file_type: json
        description: Overlapping entities are removed, index offsets corrected, and
          duplicates removed. Also texts without any entities are removed too, since
          it's not known if they don't contain any entities (which often is not true;
          quite a few of them contain entities) or if the annotators simply didn't
          go through them (which is more likely, hence they were removed). In the
          original uncleaned data, some entity types are suffixed with numbers (e.g.
          `PER-1337`). These were used for identifying entities in a project context,
          but are probably of less use for NER NLP training. This dataset keeps the
          identifiers.
        content:
        - gold data
        - NER gold data
        - NLP gold data
        topic:
        - NLP
        - Named entity recognition
        additional:
          total count of entities: 26364
          individual count of entities:
            ORG: 5256
            ORG-5398: 847
            PER: 3637
            PER-5421: 146
            PER-5420: 2120
            PER-5422: 21
            LOC: 5224
            LOC-5388: 1808
            PER-5424: 144
            PER-5418: 1077
            ORG-5611: 592
            LOC-5391: 925
            PER-5715: 35
            LOC-5399: 325
            ORG-5622: 585
            ORG-5642: 670
            ORG-5630: 28
            PER-5412: 589
            PER-5414: 127
            PER-5413: 214
            ORG-5682: 10
            PER-5432: 324
            LOC-5390: 333
            ORG-5686: 43
            ORG-5689: 58
            ORG-5657: 52
            ORG-5791: 3
            ORG-5697: 70
            ORG-5612: 75
            PER-5775: 109
            ORG-5634: 67
            ORG-5648: 16
            ORG-5395: 1
            ORG-5683: 61
            PER-5411: 80
            ORG-5776: 12
            ORG-5675: 13
            PER-5781: 57
            ORG-5658: 69
            ORG-5643: 5
            ORG-5616: 17
            ORG-5679: 6
            ORG-5396: 31
            PER-5428: 34
            PER-5769: 2
            PER-5415: 58
            ORG-5667: 7
            PER-5801: 6
            PER-5800: 16
            ORG-5812: 1
            PER-5417: 97
            ORG-5660: 3
            PER-5423: 7
            ORG-5806: 8
            ORG-5677: 54
            ORG-5760: 7
            ORG-5688: 7
            ORG-5662: 22
            PER-5783: 8
            ORG-5690: 10
            ORG-5652: 1
            ORG-5646: 20
            ORG-5691: 3
            ORG-5613: 3
            ORG-5792: 8
            LOC-5787: 3
            ORG-5645: 9
            LOC-5403: 1
            ORG-5659: 6
            LOC-5400: 2
            ORG-5610: 5
            ORG-5651: 1
            ORG-5777: 2
            ORG-5617: 2
            ORG-5618: 2
            ORG-5778: 4
            PER-5785: 5
            ORG-5631: 7
            ORG-5701: 1
            ORG-5656: 2
            PER-5759: 1
            ORG-5624: 3
            PER-5430: 5
            ORG-5621: 1
            ORG-5640: 6
            LOC-5401: 2
            ORG-5676: 3
            ORG-5639: 4
            ORG-5674: 3
            PER-5416: 1
            LOC-5392: 1
            LOC-5402: 2
            ORG-5654: 4
            ORG-5620: 1
            ORG-5672: 5
            ORG-5879: 1
            PER-5425: 3
            ORG-5698: 2
veld_data__apis_oebl__ner_gold___data_cleaned_simplified___veld.yaml:
  url: https://github.com/veldhub/veld_data__apis_oebl__ner_gold/blob/main/data_cleaned_simplified/veld.yaml
  content:
    x-veld:
      data:
        file_type: json
        description: Same as the cleaned data, but with simplified entities (e.g.
          `PER` instead of `PER-1337`). Probably it's best to use this data set for
          NER training.
        content:
        - gold data
        - NER gold data
        - NLP gold data
        topic:
        - NLP
        - Named entity recognition
        additional:
          total count of entities: 14313
          individual count of entities:
            ORG: 5356
            PER: 3698
            LOC: 5259
veld_data__apis_oebl__ner_gold___data_uncleaned___veld.yaml:
  url: https://github.com/veldhub/veld_data__apis_oebl__ner_gold/blob/main/data_uncleaned/veld.yaml
  content:
    x-veld:
      data:
        file_type: json
        description: "The original, but united, data coming from APIS / \xD6BL."
        content:
        - gold data
        - NER gold data
        - NLP gold data
        topic:
        - NLP
        - Named entity recognition
        additional:
          total count of entities: 27729
          individual count of entities:
            ORG: 5620
            ORG-5398: 848
            PER: 3637
            PER-5421: 146
            PER-5420: 2120
            PER-5422: 21
            LOC: 6224
            LOC-5388: 1808
            PER-5424: 144
            PER-5418: 1077
            ORG-5611: 592
            LOC-5391: 925
            PER-5715: 35
            LOC-5399: 325
            ORG-5622: 585
            ORG-5642: 670
            ORG-5630: 28
            PER-5412: 589
            PER-5414: 127
            PER-5413: 214
            ORG-5682: 10
            PER-5432: 324
            LOC-5390: 333
            ORG-5686: 43
            ORG-5689: 58
            ORG-5657: 52
            ORG-5791: 3
            ORG-5697: 70
            ORG-5612: 75
            PER-5775: 109
            ORG-5634: 67
            ORG-5648: 16
            ORG-5395: 1
            ORG-5683: 61
            PER-5411: 80
            ORG-5776: 12
            ORG-5675: 13
            PER-5781: 57
            ORG-5658: 69
            ORG-5643: 5
            ORG-5616: 17
            ORG-5679: 6
            ORG-5396: 31
            PER-5428: 34
            PER-5769: 2
            PER-5415: 58
            ORG-5667: 7
            PER-5801: 6
            PER-5800: 16
            ORG-5812: 1
            PER-5417: 97
            ORG-5660: 3
            PER-5423: 7
            ORG-5806: 8
            ORG-5677: 54
            ORG-5760: 7
            ORG-5688: 7
            ORG-5662: 22
            PER-5783: 8
            ORG-5690: 10
            ORG-5652: 1
            ORG-5646: 20
            ORG-5691: 3
            ORG-5613: 3
            ORG-5792: 8
            LOC-5787: 3
            ORG-5645: 9
            LOC-5403: 1
            ORG-5659: 6
            LOC-5400: 2
            ORG-5610: 5
            ORG-5651: 1
            ORG-5777: 2
            ORG-5617: 2
            ORG-5618: 2
            ORG-5778: 4
            PER-5785: 5
            ORG-5631: 7
            ORG-5701: 1
            ORG-5656: 2
            PER-5759: 1
            ORG-5624: 3
            PER-5430: 5
            ORG-5621: 1
            ORG-5640: 6
            LOC-5401: 2
            ORG-5676: 3
            ORG-5639: 4
            ORG-5674: 3
            PER-5416: 1
            LOC-5392: 1
            LOC-5402: 2
            ORG-5654: 4
            ORG-5620: 1
            ORG-5672: 5
            ORG-5879: 1
            PER-5425: 3
            ORG-5698: 2
veld_data__apis_spacy_ner_models___m1___model-best___veld.yaml:
  url: https://github.com/veldhub/veld_data__apis_spacy_ner_models/blob/main/m1/model-best/veld.yaml
  content:
    x-veld:
      data:
        file_type: spacy model
        content:
        - spacy model
        - NLP model
        additional:
          performance:
            ents_f: 0.7800650054
            ents_p: 0.7831762146
            ents_r: 0.7769784173
            ents_per_type:
              LOC:
                p: 0.8150943396
                r: 0.8105065666
                f: 0.8127939793
              ORG:
                p: 0.7168674699
                r: 0.698630137
                f: 0.7076313181
              PER:
                p: 0.8290598291
                r: 0.8410404624
                f: 0.8350071736
            tok2vec_loss: 102.1628509774
            ner_loss: 3583.9829101562
veld_data__apis_spacy_ner_models___m2___model-best___veld.yaml:
  url: https://github.com/veldhub/veld_data__apis_spacy_ner_models/blob/main/m2/model-best/veld.yaml
  content:
    x-veld:
      data:
        file_type: spacy model
        content:
        - spacy model
        - NLP model
        additional:
          performance:
            ents_f: 0.7813646368
            ents_p: 0.7971556886
            ents_r: 0.7661870504
            ents_per_type:
              LOC:
                p: 0.8352713178
                r: 0.808630394
                f: 0.8217349857
              ORG:
                p: 0.7250996016
                r: 0.7123287671
                f: 0.7186574531
              PER:
                p: 0.8490566038
                r: 0.7803468208
                f: 0.813253012
            tok2vec_loss: 120.6995862189
            ner_loss: 3537.5532226562
veld_data__demo_inference_input_ts-vienna-2024___veld.yaml:
  url: https://github.com/veldhub/veld_data__demo_inference_input_ts-vienna-2024/blob/main/veld.yaml
  content:
    x-veld:
      data:
        file_type: txt
        description: A single txt file, used as inference input to a self-trained
          updipe model as a demonstration
        topic:
        - NLP
        - universal dependencies
        content:
        - raw text
veld_data__demo_train_data_ts-vienna-2024___veld.yaml:
  url: https://github.com/veldhub/veld_data__demo_train_data_ts-vienna-2024/blob/main/veld.yaml
  content:
    x-veld:
      data:
        file_type: conllu
        description: A single conllu file, used to train a updipe model as a demonstration
        topic:
        - NLP
        - universal dependencies
        content:
        - linguistically enriched text
        - tokenized text
        - lemmatized text
veld_data__eltec_original_selection___veld.yaml:
  url: https://github.com/veldhub/veld_data__eltec_original_selection/blob/main/veld.yaml
  content:
    x-veld:
      data:
        description: parent git repo that integrates various ELTeC corpora as submodules
          for downstream processing.
        file_type: xml
        content:
        - TEI
        - annotated literature
veld_data__fasttext_models___m1___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m1/veld.yaml
  content:
    x-veld:
      data:
        description: test training
        file_type: bin
        content:
        - word embeddings model
        - fasttext model
        additional:
          model_id: m1
          train_data_description: sample wikipedia, single txt, one sentence per line,
            lowercased, removed punctuation
          training_architecture: fasttext
          train_data_size: 686M
          train_data_md5_hash: 05e9002eeaab646a6d82af02eaf86a13
          training_epochs: 10
          training_vector_size: 200
          training_window_size: 5
          training_duration (minutes): 37.4
          model_data_size: 4.0G
veld_data__fasttext_models___m3___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m3/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: bin
        content:
        - word embeddings model
        - fasttext model
        additional:
          model_id: m3
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          training_architecture: fasttext
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_epochs: 10
          training_vector_size: 200
          training_window_size: 5
          training_duration (minutes): 317.3
          model_data_size: 3.9G
veld_data__fasttext_models___m4___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m4/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: bin
        content:
        - word embeddings model
        - fasttext model
        additional:
          model_id: m4
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          training_architecture: fasttext
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_epochs: 50
          training_vector_size: 200
          training_window_size: 5
          training_duration (minutes): 1585
          model_data_size: 3.9G
veld_data__fasttext_models___m5___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m5/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: bin
        content:
        - word embeddings model
        - fasttext model
        additional:
          model_id: m5
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          training_architecture: fasttext
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_epochs: 10
          training_vector_size: 300
          training_window_size: 5
          training_duration (minutes): 393.1
          model_data_size: 5.8G
veld_data__fasttext_models___m6___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m6/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: bin
        content:
        - word embeddings model
        - fasttext model
        additional:
          model_id: m6
          train_data_description: null
          training_architecture: fasttext
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_epochs: 10
          training_vector_size: 300
          training_window_size: 5
          training_duration (minutes): 4731
          model_data_size: 18G
veld_data__fasttext_models___m7___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m7/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: bin
        content:
        - word embeddings model
        - fasttext model
        additional:
          model_id: m7
          train_data_description: null
          training_architecture: fasttext
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_epochs: 10
          training_vector_size: 200
          training_window_size: 5
          training_duration (minutes): 3380
          model_data_size: 12G
veld_data__fasttext_models___m8___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m8/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: bin
        content:
        - word embeddings model
        - fasttext model
        additional:
          model_id: m8
          train_data_description: null
          training_architecture: fasttext
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_epochs: 10
          training_vector_size: 200
          training_window_size: 10
          training_duration (minutes): 4923
          model_data_size: 12G
veld_data__fasttext_models___m9___veld.yaml:
  url: https://github.com/veldhub/veld_data__fasttext_models/blob/main/m9/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: bin
        content:
        - word embeddings model
        - fasttext model
        additional:
          model_id: m9
          train_data_description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
            lines, lowercased, punctuation removed, removed sentences with too many
            non-alphanumeric characters.'
          training_architecture: fasttext
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_epochs: 10
          training_vector_size: 300
          training_window_size: 10
          training_duration (minutes): 6513
          model_data_size: 18G
veld_data__glove_models___m1___veld.yaml:
  url: https://github.com/veldhub/veld_data__glove_models/blob/main/m1/veld.yaml
  content:
    x-veld:
      data:
        description: glove test model
        file_type:
        - bin
        - txt
        content:
        - word embeddings model
        - glove model
        additional:
          model_id: m1
          train_data_description: sample wikipedia, single txt, one article per line,
            lowercased, removed punctuation
          training_architecture: glove
          train_data_size: 681M
          train_data_md5_hash: ba86437d073c0cf19e0f54c8dbc52547
          verbose: '2'
          memory: '4.0'
          vocab_min_count: '5'
          vector_size: '200'
          max_iter: '10'
          window_size: '15'
          binary: '2'
          num_threads: '14'
          x_max: '10'
          training_duration (minutes): 44.11
          model_data_size: 16G
veld_data__glove_models___m3___veld.yaml:
  url: https://github.com/veldhub/veld_data__glove_models/blob/main/m3/veld.yaml
  content:
    x-veld:
      data:
        description: 1% AMC model
        file_type:
        - bin
        - txt
        content:
        - word embeddings model
        - glove model
        additional:
          model_id: m3
          train_data_description: 1% of AMC
          training_architecture: glove
          train_data_size: 552M
          train_data_md5_hash: 05514cc05c6d61fcb3b20076372e2b8a
          verbose: '2'
          memory: '4.0'
          vocab_min_count: '5'
          vector_size: '200'
          max_iter: '10'
          window_size: '15'
          binary: '2'
          num_threads: '14'
          x_max: '10'
          training_duration (minutes): 24.8
          model_data_size: 9.1G
veld_data__word2vec_models___m3___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m3/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: bin
        topic:
        - NLP
        - word embeddings
        content:
        - word embeddings model
        - word2vec model
        additional:
          model_id: m3
          training_architecture: word2vec
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_vector_size: 200
          training_epochs: 10
          window: 5
          min_count: 5
          training_duration (minutes): 165.3
          model_data_size: 2.4G
veld_data__word2vec_models___m4___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m4/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: bin
        topic:
        - NLP
        - word embeddings
        content:
        - word embeddings model
        - word2vec model
        additional:
          model_id: m4
          training_architecture: word2vec
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_vector_size: 200
          training_epochs: 50
          window: 5
          min_count: 5
          training_duration (minutes): 786.8
          model_data_size: 2.4G
veld_data__word2vec_models___m5___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m5/veld.yaml
  content:
    x-veld:
      data:
        description: 10% AMC model
        file_type: bin
        topic:
        - NLP
        - word embeddings
        content:
        - word embeddings model
        - word2vec model
        additional:
          model_id: m5
          training_architecture: word2vec
          train_data_description: 'AMC data: stripped from non-alphanumeric lines,
            10% sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          train_data_size: 5.4G
          train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
          training_vector_size: 300
          training_epochs: 10
          window: 5
          min_count: 5
          training_duration (minutes): 188.4
          model_data_size: 3.6G
veld_data__word2vec_models___m6___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m6/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: bin
        topic:
        - NLP
        - word embeddings
        content:
        - word embeddings model
        - word2vec model
        additional:
          model_id: m6
          training_architecture: word2vec
          train_data_description: null
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_vector_size: 300
          training_epochs: 10
          window: 5
          min_count: 5
          training_duration (minutes): 4573
          model_data_size: 17G
veld_data__word2vec_models___m7___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m7/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: bin
        topic:
        - NLP
        - word embeddings
        content:
        - word embeddings model
        - word2vec model
        additional:
          model_id: m7
          training_architecture: word2vec
          train_data_description: null
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_vector_size: 200
          training_epochs: 10
          window: 5
          min_count: 5
          training_duration (minutes): 1915
          model_data_size: 11G
veld_data__word2vec_models___m8___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m8/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: bin
        topic:
        - NLP
        - word embeddings
        content:
        - word embeddings model
        - word2vec model
        additional:
          model_id: m8
          training_architecture: word2vec
          train_data_description: null
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_vector_size: 300
          training_epochs: 10
          window: 10
          min_count: 5
          training_duration (minutes): 10128
          model_data_size: 17G
veld_data__word2vec_models___m9___veld.yaml:
  url: https://github.com/veldhub/veld_data__word2vec_models/blob/main/m9/veld.yaml
  content:
    x-veld:
      data:
        description: 100% AMC model
        file_type: bin
        topic:
        - NLP
        - word embeddings
        content:
        - word embeddings model
        - word2vec model
        additional:
          model_id: m9
          training_architecture: word2vec
          train_data_description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
            lines, lowercased, punctuation removed, removed sentences with too many
            non-alphanumeric characters.'
          train_data_size: 54G
          train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
          training_vector_size: 200
          training_epochs: 10
          window: 10
          min_count: 5
          training_duration (minutes): 1847
          model_data_size: 261M
veld_data__wordembeddings_evaluation___evaluation_gold_data___capitalized___veld.yaml:
  url: https://github.com/veldhub/veld_data__wordembeddings_evaluation/blob/main/evaluation_gold_data/capitalized/veld.yaml
  content:
    x-veld:
      data:
        description: custom evaluation data for evaluating word embeddings models.
          Words are capitalized.
        topic:
        - NLP
        - word embeddings
        file_type: yaml
        content:
        - evaluation data
        - NLP gold data
veld_data__wordembeddings_evaluation___evaluation_gold_data___lowercase___veld.yaml:
  url: https://github.com/veldhub/veld_data__wordembeddings_evaluation/blob/main/evaluation_gold_data/lowercase/veld.yaml
  content:
    x-veld:
      data:
        description: custom evaluation data for evaluating word embeddings models.
          Words are all lowercase.
        topic:
        - NLP
        - word embeddings
        file_type: yaml
        content:
        - evaluation data
        - NLP gold data
veld_code__analyse_conllu___veld.yaml:
  url: https://github.com/veldhub/veld_code__analyse_conllu/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: ''
        topic:
        - NLP
        - Machine learning
        - tokenization
        - lemmatization
        - part of speech
        - dependency parsing
        - universal dependencies
        - grammatical annotation
        input:
        - volume: /veld/input/
          file_type: conllu
        output:
        - volume: /veld/output/
          file_type: json
          content:
          - statistics
          - NLP statistics
    services:
      veld:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        working_dir: /veld/code/
        volumes:
        - ./src:/veld/code/
veld_code__apis_ner_evaluate_old_models___veld_evaluate.yaml:
  url: https://github.com/veldhub/veld_code__apis_ner_evaluate_old_models/blob/main/veld_evaluate.yaml
  content:
    x-veld:
      code:
        description: hard-coded evaluation of several spaCy2.2.4 models.
        topic:
        - NLP
        - Machine learning
        - Named entity recognition
        input:
        - volume: /veld/input/
          description: This input is hard-wired to the apis spacy-ner repo and not
            made for generic usage.
          file_type:
          - pickle
          - txt
          - json
          - spacy model
          content:
          - NER gold data
          - Machine learning model
          - NLP model
        output:
        - volume: /veld/output/
          environment_var: out_eval_result
          description: evaluation report of the models from the apis spacy-ner repo.
          file_type: md
          content: evaluation report
    services:
      veld_evaluate:
        build: .
        command: python /veld/code/reevaluate_all_models.py
        volumes:
        - ./src/:/veld/code/
        environment:
          out_eval_result_file: null
veld_code__apis_ner_transform_to_gold___veld.yaml:
  url: https://github.com/veldhub/veld_code__apis_ner_transform_to_gold/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: hard-coded conversion of apis ner models to custom json format.
        topic:
        - ETL
        - data cleaning
        input:
        - volume: /veld/input/
          description: This input is hard-wired to the apis spacy-ner repo and not
            made for generic usage.
          file_type:
          - pickle
          - txt
          - json
          content: NER gold data
        output:
        - volume: /veld/output/cleaned/
          environment_var: out_json_cleaned_file
          description: raw uncleaned, as it was originally. Now just transformed to
            json.
          file_type: json
          content: NER gold data
        - volume: /veld/output/uncleaned/
          environment_var: out_json_uncleaned_file
          description: removed empty entity annotations and fixed border issues.
          file_type: json
          content: NER gold data
        - volume: /veld/output/cleaned_simplified/
          environment_var: out_json_cleaned_simplified_file
          description: additionally to cleaning, this data is slimmed down from superfluous
            entity ids in favor of simplified entity classes.
          file_type: json
          content: NER gold data
        - volume: /veld/output/log/
          environment_var: out_log_file
          file_type: txt
    services:
      veld:
        build: .
        command: python /veld/code/extract_and_clean.py
        volumes:
        - ./src/:/veld/code/
        environment:
          out_json_uncleaned_file: null
          out_json_cleaned_file: null
          out_json_cleaned_simplified_file: null
          out_log_file: null
veld_code__bert_embeddings___veld_infer_and_create_index.yaml:
  url: https://github.com/veldhub/veld_code__bert_embeddings/blob/main/veld_infer_and_create_index.yaml
  content:
    x-veld:
      code: null
    services:
      infer_and_create_index:
        build: .
        command: python /veld/code/infer_and_create_index.py
        volumes:
        - ./src/:/veld/code/
veld_code__downloader___veld.yaml:
  url: https://github.com/veldhub/veld_code__downloader/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: A very simple curl call. Since many veld chains need to download
          data, it makes sense to encapsulate the download functionality into a dedicated
          downloader veld code
        topic: ETL
        output:
        - volume: /veld/output/
          environment_var: out_file
          description: optional. If unset, this script will fetch the file name from
            the resource.
          optional: true
        config:
          environment_var: url
          var_type: str
          description: The url where some resource is located and should be downloaded
            from.
    services:
      veld_downloader:
        build: .
        command: sh /veld/code/downloader.sh
        volumes:
        - ./downloader.sh:/veld/code/downloader.sh
        environment:
          url: null
          out_file: null
veld_code__fasttext___veld_jupyter_notebook.yaml:
  url: https://github.com/veldhub/veld_code__fasttext/blob/main/veld_jupyter_notebook.yaml
  content:
    x-veld:
      code:
        description: a fasttext training and inference jupyter notebook.
        topic:
        - NLP
        - Machine Learning
        - word embeddings
    services:
      veld_jupyter_notebook:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/jupyter_notebook/:/veld/code/:z
        - ./data/:/veld/storage/:z
veld_code__fasttext___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__fasttext/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: a fasttext training and inference jupyter notebook.
        topic:
        - NLP
        - Machine Learning
        - word embeddings
        input:
        - volume: /veld/input/
          file_type: txt
          environment_var: in_train_data_file
          description: training data must be expressed as one sentence per line.
          content: raw text
        output:
        - volume: /veld/output/
          file_type:
          - bin
          - fasttext model
          environment_var: out_model_file
          content:
          - fasttext model
          - word embeddings
        config:
        - environment_var: vector_size
          description: 'hyperparameter: the dimension of the vectors to be trained.'
          var_type: int
          default: 200
        - environment_var: epochs
          description: 'hyperparameter: the number of epochs of the training.'
          var_type: int
          default: 50
        - environment_var: window_size
          description: 'hyperparameter: the size of the context window of each token.'
          var_type: int
          default: 5
    services:
      veld_train:
        build: .
        command: /veld/code/train.sh
        volumes:
        - ./src/train/:/veld/code/:z
        - ./data/training_data/:/veld/input/:z
        - ./data/models/:/veld/output/:z
        environment:
          in_train_data_file: null
          out_model_file: null
          model_description: null
          vector_size: 200
          epochs: 50
          window_size: 5
veld_code__glove___veld_jupyter_notebook.yaml:
  url: https://github.com/veldhub/veld_code__glove/blob/main/veld_jupyter_notebook.yaml
  content:
    x-veld:
      code:
        description: A jupyter notebook that loads GloVe vectors and provides some
          convenient functions to use them.
        topic:
        - NLP
        - Machine learning
        - word embeddings
    services:
      veld_jupyter_notebook:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/main/jupyter_notebook/:/veld/code/:z
        - ./data/:/veld/storage/:z
veld_code__glove___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__glove/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: This code repo encapsulates the original code from https://github.com/stanfordnlp/GloVe/tree/master
        topic:
        - NLP
        - Machine learning
        - word embeddings
        input:
        - volume: /veld/input/
          environment_var: in_corpus_file
          description: In the txt file, each line must be one sentence
          file_type: txt
          content: natural text
        output:
        - volume: /veld/output/
          environment_var: out_vocab_file
          file_type: bin
          content:
          - GloVe global word cooccurrence matrix
          - GloVe vectors
        - volume: /veld/output/
          environment_var: out_cooccurrence_file
          file_type: bin
          content:
          - GloVe global word cooccurrence matrix
          - GloVe vectors
        - volume: /veld/output/
          environment_var: out_cooccurrence_shuf_file
          file_type: bin
          content:
          - GloVe global word cooccurrence matrix
          - GloVe vectors
        - volume: /veld/output/
          environment_var: out_vector_file
          file_type: bin
          content:
          - GloVe global word cooccurrence matrix
          - GloVe vectors
        config:
        - environment_var: verbose
          var_type: int
          default: 2
        - environment_var: memory
          var_type: float
          default: 4.0
        - environment_var: vocab_min_count
          var_type: int
          default: 5
        - environment_var: vector_size
          var_type: int
          default: 50
        - environment_var: max_iter
          var_type: int
          default: 15
        - environment_var: window_size
          var_type: int
          default: 15
        - environment_var: binary
          var_type: int
          default: 2
        - environment_var: num_threads
          var_type: int
          default: 8
        - environment_var: x_max
          var_type: int
          default: 10
    services:
      veld_train:
        build: .
        volumes:
        - ./src/main/train/:/veld/code/:z
        - ./data/training_data/:/veld/input/:z
        - ./data/models/:/veld/output/:z
        command: /veld/code/train.sh
        environment:
          in_corpus_file: null
          out_vocab_file: null
          out_cooccurrence_file: null
          out_cooccurrence_shuf_file: null
          out_vector_file: null
          model_id: null
          model_description: null
          verbose: 2
          memory: 4.0
          vocab_min_count: 5
          vector_size: 50
          max_iter: 15
          window_size: 15
          binary: 2
          num_threads: 8
          x_max: 10
veld_code__jupyter_notebook_base___veld.yaml:
  url: https://github.com/veldhub/veld_code__jupyter_notebook_base/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: template veld code repo for a juptyer notebook
    services:
      veld:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        working_dir: /veld/code/
        volumes:
        - ./src:/veld/code/
        - ./volumes/input/:/veld/input/
        - ./volumes/output/:/veld/output/
veld_code__simple_docker_test___veld.yaml:
  url: https://github.com/veldhub/veld_code__simple_docker_test/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: prints information about the python intepreter within the docker
          container.
        topic: testing
    services:
      veld:
        build: .
        command: python /veld/code/test.py
        volumes:
        - ./test.py:/veld/code/test.py
veld_code__spacy___veld_convert.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_convert.yaml
  content:
    x-veld:
      code:
        description: prepare data for spacy NER training, since spacy expects the
          entity annotation indices to be precisely at the beginning and end of the
          words, and also no overlapping entity annotations. Then it converts the
          data to spaCy docbin, and prepares it for training by splitting it into
          train, dev, eval subsets, and shuffling them randomly.
        topic:
        - ETL
        - NLP
        - Machine learning
        input:
        - volume: /veld/input/
          file_type: json
          description: name of the csv file, containing NER gold data
          environment_var: in_json_file
          content: NER gold data
        output:
        - volume: /veld/output/docbin/
          description: path to folder where spacy docbin files will be stored with
            file names `train.spacy, dev.spacy, eval.spacy`
          file_type: spacy docbin
          content: NER gold data
        - volume: /veld/output/log/
          environment_var: out_log_file
          description: log file of conversion
          file_type: spacy docbin
          content: NER gold data
        config:
        - environment_var: model_base
          description: spacy model to be used for conversion.
          var_type: str
        - environment_var: percentage_train
          description: percentage of data allocated to training set
          var_type: int
          default: 80
        - environment_var: percentage_dev
          description: percentage of data allocated to dev set
          var_type: int
          default: 10
        - environment_var: percentage_eval
          description: percentage of data allocated to eval set
          var_type: int
          default: 10
        - environment_var: seed
          description: seed for initial random shuffling of training data
          var_type: int
          default: 42
    services:
      veld_convert:
        build: .
        command: python /veld/code/convert.py
        volumes:
        - ./src/:/veld/code/
        - ./data/models_base_cache/:/tmp/models_base_cache/
        - ./data/training_data_json/:/veld/input/
        - ./data/docbin/:/veld/output/docbin/
        - ./:/veld/output/log/
        environment:
          in_json_file: null
          out_log_file: null
          model_base: null
          percentage_train: 80
          percentage_dev: 10
          percentage_eval: 10
          seed: 42
veld_code__spacy___veld_create_config.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_create_config.yaml
  content:
    x-veld:
      code:
        description: 'Creating a spacy config by encapsulating `init config` ( https://spacy.io/api/cli#init-config
          ) and `init fill-config` ( https://spacy.io/api/cli#init-fill-config ) .
          The output is ai config file used for training; see more here: https://spacy.io/usage/training/#config'
        topic:
        - NLP
        - Machine learning
        output:
        - volume: /veld/output/
          file_type: cfg
          environment_var: out_spacy_config
          content: spacy training config
          description: See https://spacy.io/usage/training/#config
        config:
        - environment_var: lang
          description: See https://spacy.io/api/cli#init-config
          var_type: str
        - environment_var: tagger
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: parser
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: ner
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: entity_linker
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: entity_ruler
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: textcat
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: textcat_multilabel
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: lemmatizer
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: trainable_lemmatizer
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: morphologizer
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: attribute_ruler
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: senter
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: sentencizer
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: tok2vec
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: transformer
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: optimize_efficiency
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: optimize_accuracy
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: gpu
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
        - environment_var: pretraining
          description: See https://spacy.io/api/cli#init-config
          var_type: bool
          default: false
          optional: true
    services:
      veld_create_config:
        build: .
        working_dir: /veld/code/
        command: /veld/code/create_config.sh
        volumes:
        - ./src/:/veld/code/
        - ./data/configs/:/veld/output/
        environment:
          out_config_file: null
          lang: de
          tagger: false
          parser: false
          ner: false
          entity_linker: false
          entity_ruler: false
          textcat: false
          textcat_multilabel: false
          lemmatizer: false
          trainable_lemmatizer: false
          morphologizer: false
          attribute_ruler: false
          senter: false
          sentencizer: false
          tok2vec: false
          transformer: false
          optimize_efficiency: null
          optimize_accuracy: null
          gpu: false
          pretraining: false
veld_code__spacy___veld_publish_to_hf.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_publish_to_hf.yaml
  content:
    x-veld:
      code:
        description: 'simple service to push spacy models to huggingface. IMPORTANT:
          Only works from spacy v3.* onwards!'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/
          file_type: spacy model
          content: NLP model
        config:
        - environment_var: model_name
          description: 'name of the model, to be used for huggingface metadata. IMPORTANT:
            do not put double underscores into the model name, as this crashes spacy
            while publishing.'
          var_type: str
          optional: true
        - environment_var: version
          description: 'version of the model, to be used for huggingface metadata.
            IMPORTANT: spacy crashes when the version tag contains the character `v`
            in front of numeric+dot version identifiers: E.g. `v1.1` crashes, while
            `1.1` works.'
          var_type: str
          optional: true
        - environment_var: hf_token
          description: 'huggingface authentication token. IMPORTANT: It is advised
            to not hardcode that directly into the yaml file but rather define the
            environment variable yourself, before calling this docker compose service.
            On linux and mac, this can be done with `export hf_token=<TOKEN>` before
            launching a docker compose service, or persist it in a `.env` (with the
            content simply being `hf_token=<TOKEN>`) file next to the chain veld yaml
            file, where docker compose would load it from (take care to not commit
            that to git! Best to add the `.env` to `.gitignore`).'
          var_type: str
    services:
      veld_publish_to_hf:
        build: .
        command: bash /veld/code/publish_to_hf.sh
        volumes:
        - ./src/:/veld/code/
        environment:
          model_name: null
          version: null
          hf_token: $hf_token
veld_code__spacy___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__spacy/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: A spacy trainig setup, utilizing spacy v3's config system.
        topic:
        - NLP
        - Machine learning
        input:
        - volume: /veld/input/docbin/
          file_type: spacy docbin
          environment_var: in_train_docbin_file
          content:
          - NLP gold data
          - ML gold data
          - gold data
        - volume: /veld/input/docbin/
          file_type: spacy docbin
          environment_var: in_dev_docbin_file
          content:
          - NLP gold data
          - ML gold data
          - gold data
        - volume: /veld/input/docbin/
          file_type: spacy docbin
          environment_var: in_eval_docbin_file
          content:
          - NLP gold data
          - ML gold data
          - gold data
        - volume: /veld/input/config/
          file_type: cfg
          environment_var: in_spacy_config
          content: spacy training config
          description: See https://spacy.io/usage/training/#config
        output:
        - volume: /veld/output/
          file_type: spacy model
          content:
          - NLP model
          - spacy model
        - volume: /veld/output/
          file_type: txt
          environment_var: out_train_log_file
          description: path to the train log file
          content: logs
        - volume: /veld/output/
          file_type: txt
          environment_var: out_eval_log_file
          description: path to the eval log file
          content: logs
        config:
        - environment_var: model_base
          description: spacy model to be used for downstream training.
          var_type: str
    services:
      veld_train:
        build: .
        working_dir: /veld/code/
        command: /veld/code/train.sh
        volumes:
        - ./src/:/veld/code/
        - ./data/models_base_cache/:/tmp/models_base_cache/
        - ./data/docbin/:/veld/input/docbin/
        - ./data/config/:/veld/input/config/
        - ./data/model/:/veld/output/
        environment:
          in_train_docbin_file: null
          in_dev_docbin_file: null
          in_eval_docbin_file: null
          model_base: null
          out_train_log_file: null
          out_eval_log_file: null
veld_code__teitok-tools___veld_parseudpipe.yaml:
  url: https://github.com/veldhub/veld_code__teitok-tools/blob/main/veld_parseudpipe.yaml
  content:
    x-veld:
      code:
        description: 'This code veld encapsulates and veldifies the parseudpipe script.
          All its config here are passed down to the script. For more information
          on its usage and config, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#parseudpipe'
        topic:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
        input:
        - volume: /veld/input/
          file_type: xml
          environment_var: in_xml_file
        output:
        - volume: /veld/output/
          file_type: xml
          environment_var: out_xml_file
        config:
        - environment_var: model
          description: which UDPIPE model to use
          var_type: str
          optional: true
        - environment_var: lang
          description: language of the texts (if no model is provided)
          var_type: str
          optional: true
        - environment_var: token
          description: token node
          var_type: str
          optional: true
        - environment_var: tokxp
          description: token XPath
          var_type: str
          optional: true
        - environment_var: sent
          description: sentence node
          var_type: str
          optional: true
        - environment_var: sentxp
          description: sentence XPath
          var_type: str
          optional: true
        - environment_var: atts
          description: attributes to use for the word form
          var_type: str
          optional: true
    services:
      veld_parseudpipe:
        build: .
        volumes:
        - ./:/veld/code/
        command: ./veld_parseudpipe.sh
        environment:
          in_xml_file: null
          out_xml_file: null
          model: null
          lang: null
          token: null
          tokxp: null
          sent: null
          sentxp: null
          atts: null
veld_code__teitok-tools___veld_udpipe2teitok.yaml:
  url: https://github.com/veldhub/veld_code__teitok-tools/blob/main/veld_udpipe2teitok.yaml
  content:
    x-veld:
      code:
        description: 'This code veld encapsulates and veldifies the udpipe2teitok
          script. All its config here are passed down to the script. For more information
          on its usage and config, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#udpipe2teitok'
        topic:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
        input:
        - volume: /veld/input/
          file_type: txt
        output:
        - volume: /veld/output/
          file_type: xml
        config:
        - environment_var: model
          description: the UDPIPE model to be used (which has to be available in the
            REST API)
          var_type: str
          optional: true
        - environment_var: lang
          description: An indication of the language (either an ISO code or a name)
            in case no model is provided.
          var_type: str
          optional: true
        - environment_var: mixed
          description: mixed language corpus - use CWALI to detect the language of
            each file.
          var_type: bool
          default: false
          optional: true
    services:
      veld_udpipe2teitok:
        build: .
        volumes:
        - ./:/veld/code/
        command: ./veld_udpipe2teitok.sh
        environment:
          lang: null
          model: null
          mixed: false
veld_code__teitok-tools___veld_xmltokenize.yaml:
  url: https://github.com/veldhub/veld_code__teitok-tools/blob/main/veld_xmltokenize.yaml
  content:
    x-veld:
      code:
        description: 'This code veld encapsulates and veldifies the xmltokenize script.
          All its config here are passed down to the script. For more information
          on its usage and config, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#xmltokenize'
        topic:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
        input:
        - volume: /veld/input/
          file_type: xml
          environment_var: in_xml_file
          description: The xml file to be tokenized
        output:
        - volume: /veld/output/
          file_type: xml
          environment_var: out_xml_file
          description: The output tokenized xml
        config:
        - environment_var: textnode
          description: what to use as the text body to tokenize
          var_type: str
        - environment_var: exclude
          description: elements not to tokenize
          var_type: str
          optional: true
        - environment_var: enumerate
          description: provide a unique ID to each token
          var_type: bool
          default: false
          optional: true
        - environment_var: segment
          description: split into sentences (1=yes, 2=only) - only for TEI files
          var_type: int
          optional: true
    services:
      veld_xmltokenize:
        build: .
        volumes:
        - ./:/veld/code/
        command: ./veld_xmltokenize.sh
        environment:
          in_xml_file: null
          out_xml_file: null
          textnode: null
          tok: null
          exclude: null
          enumerate: false
          segment: null
veld_code__udpipe___veld_infer.yaml:
  url: https://github.com/veldhub/veld_code__udpipe/blob/main/veld_infer.yaml
  content:
    x-veld:
      code:
        description: udpipe inference setup
        topic:
        - NLP
        - Machine learning
        - tokenization
        - lemmatization
        - part of speech
        - dependency parsing
        - universal dependencies
        - grammatical annotation
        input:
        - volume: /veld/input/txt/
          environment_var: in_txt_file
          description: txt files to be inferenced on. Note that the environment var
            `in_txt_file` is optional, and if it is not present, the entire input
            folder will be processed recursively
          optional: true
          file_type: txt
          content: raw text
        - volume: /veld/input/model/
          environment_var: in_model_file
          file_type: udpipe model
          content:
          - NLP model
          - tokenizer
          - lemmatizer
        output:
        - volume: /veld/output/
          description: The file name of the output conllu is created by the corresponding
            input txt file, since recursive processing requires such automatic logic
          file_type:
          - conllu
          - tsv
          content:
          - inferenced NLP data
          - tokenized text
          - lemmatized text
          - part of speech of text
          - universal dependencies of text
          - grammatically annotated text
          - linguistic data
        config:
        - environment_var: tokenizer
          description: if tokenizer config should be read or not
          var_type: bool
          optional: true
          default: true
        - environment_var: tokenizer_normalized_spaces
          description: 'by default, UDPipe uses custom MISC fields to exactly encode
            spaces in the original document (as described below). If true, only the
            standard CoNLL-U v2 markup (SpaceAfter=No and # newpar) is used.'
          var_type: bool
          optional: true
          default: false
        - environment_var: tokenizer_presegmented
          description: the input file is assumed to be already segmented, with each
            sentence on a separate line, and is only tokenized (respecting sentence
            breaks)
          var_type: bool
          optional: true
          default: false
        - environment_var: tokenizer_ranges
          description: for each token, a range in the original document is stored
            in the format described below.
          var_type: bool
          optional: true
          default: false
        - environment_var: tokenizer_joint_with_parsing
          description: "an experimental mode performing sentence segmentation jointly\
            \ using the tokenizer and the parser (see Milan Straka and Jana Strakov\xE1\
            : Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe\
            \ paper for details)."
          var_type: bool
          optional: true
          default: false
        - environment_var: tokenizer_joint_change_boundary_logprob
          description: for every sentence boundary not returned by the tokenizer (i.e.,
            either 0, 1 or 2 times). The joint sentence segmentation chooses such
            a segmentation, where every sentence has length at most joint_max_sentence_len
            and the sum of logprobs of all sentences is as large as possible.
          var_type: bool
          optional: true
          default: false
        - environment_var: tagger
          description: if tagger config should be read or not
          var_type: bool
          optional: true
          default: true
        - environment_var: parser
          description: if parser config should be read or not
          var_type: bool
          optional: true
          default: true
    services:
      veld_infer:
        build: .
        command: /veld/code/infer.sh
        volumes:
        - ./data/inference/input/txt/:/veld/input/txt/
        - ./data/inference/input/model/:/veld/input/model/
        - ./data/inference/output/:/veld/output/
        - ./src/main/:/veld/code/
        environment:
          in_txt_file: null
          in_model_file: null
          tokenizer: true
          tokenizer_normalized_spaces: false
          tokenizer_presegmented: false
          tokenizer_ranges: false
          tokenizer_joint_with_parsing: false
          tokenizer_joint_change_boundary_logprob: false
          tagger: true
          parser: true
veld_code__udpipe___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__udpipe/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: udpipe training setup
        topic:
        - NLP
        - Machine learning
        - tokenization
        - lemmatization
        - part of speech
        - dependency parsing
        - universal dependencies
        - grammatical annotation
        input:
        - volume: /veld/input/
          environment_var: train_data_path
          file_type: conllu
          content:
          - tokenized text
          - enriched text
          - linguistic data
        output:
        - volume: /veld/output/
          environment_var: model_path
          file_type: udpipe model
          content:
          - NLP model
          - tokenizer
          - lemmatizer
        config:
        - environment_var: tokenizer
          description: if tokenizer config should be read or not
          var_type: bool
          optional: true
          default: true
        - environment_var: tokenizer_tokenize_url
          description: tokenize URLs and emails using a manually implemented recognizer
          var_type: bool
          optional: true
          default: true
        - environment_var: tokenizer_allow_spaces
          description: allow tokens to contain spaces
          var_type: bool
          optional: true
          default: true
        - environment_var: tokenizer_dimension
          description: dimension of character embeddings and of the per-character
            bidirectional GRU. Note that inference time is quadratic in this parameter.
            Supported values are only 16, 24 and 64, with 64 needed for languages
            with complicated tokenization like Japanese, Chinese or Vietnamese or
            complicated segmentation.
          var_type: int
          optional: true
          default: 24
        - environment_var: tokenizer_segment_size
          description: length of character segment used to predict token and sentence
            breaks. Larger values like 200 are needed for languges with complicated
            segmentation
          var_type: int
          optional: true
          default: 50
        - environment_var: tokenizer_epochs
          description: the number of epochs to train the tokenizer for
          var_type: int
          optional: true
          default: 100
        - environment_var: tokenizer_batch_size
          description: batch size (number of segments) used during tokenizer training
          var_type: int
          optional: true
          default: 50
        - environment_var: tokenizer_learning_rate
          description: the learning rate used during tokenizer training
          var_type: float
          optional: true
          default: 0.005
        - environment_var: tokenizer_learning_rate_final
          description: if not zero, use exponential learning rate decay so that last
            epoch uses this learning rate
          var_type: float
          optional: true
          default: 0
        - environment_var: tokenizer_dropout
          description: dropout used during tokenizer training
          var_type: float
          optional: true
          default: 0.1
        - environment_var: tokenizer_early_stopping
          description: perform early stopping, choosing training iteration maximizing
            sentences F1 score plus tokens F1 score on heldout data
          var_type: bool
          optional: true
          default: 1
        - environment_var: tagger
          description: if tagger config should be read or not
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_use_lemma
          description: use the lemma field internally to perform disambiguation; the
            lemma may be not outputted
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_provide_lemma
          description: produce the disambiguated lemma on output
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_use_xpostag
          description: use the XPOS tags internally to perform disambiguation; it
            may not be outputted
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_provide_xpostag
          description: produce the disambiguated XPOS tag on output
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_use_feats
          description: use the Feats internally to perform disambiguation; it may
            not be outputted
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_provide_feats
          description: produce the disambiguated Feats field on output
          var_type: bool
          optional: true
          default: true
        - environment_var: tagger_dictionary_max_form_analyses
          description: the maximum number of (most frequent) form analyses from UD
            training data that are to be kept in the morphological dictionary
          var_type: int
          optional: true
          default: 0
        - environment_var: tagger_dictionary_file
          description: use a given custom morphological dictionary, where each line
            contains 5 tab-separated fields FORM, LEMMA, UPOSTAG, XPOSTAG and FEATS.
            Note that this dictionary data is appended to the dictionary created from
            the UD training data, not replacing it.
          var_type: str
          optional: true
          default: null
        - environment_var: tagger_guesser_suffix_rules
          description: number of rules generated for every suffix
          var_type: int
          optional: true
          default: 8
        - environment_var: tagger_guesser_prefixes_max
          description: maximum number of form-generating prefixes to use in the guesser
          var_type: int
          optional: true
          default: 4
        - environment_var: tagger_guesser_prefix_min_count
          description: minimum number of occurrences of form-generating prefix to
            consider using it in the guesser
          var_type: int
          optional: true
          default: 10
        - environment_var: tagger_guesser_enrich_dictionary
          description: number of rules generated for forms present in training data
            (assuming that the analyses from the training data may not be all)
          var_type: int
          optional: true
          default: 6
        - environment_var: tagger_iterations
          description: number of training iterations to perform
          var_type: int
          optional: true
          default: 20
        - environment_var: tagger_early_stopping
          description: perform early stopping, choosing training iteration maximizing
            tagging accuracy on the heldout data
          var_type: bool
          optional: true
          default: 0
        - environment_var: tagger_templates
          description: MorphoDiTa feature templates to use, either lemmatizer which
            focuses more on lemmas, or tagger which focuses more on UPOS/XPOS/FEATS
          var_type: str
          optional: true
          default: null
        - environment_var: parser
          description: if parser config should be read or not
          var_type: bool
          optional: true
          default: true
        - environment_var: parser_use_gold_tags
          description: if false and a tagger exists, the Lemmas/UPOS/XPOS/FEATS for
            both the training and heldout data are generated by the tagger, otherwise
            they are taken from the gold data
          var_type: bool
          optional: true
          default: false
        - environment_var: parser_embedding_upostag
          description: the dimension of the UPos embedding used in the parser
          var_type: int
          optional: true
          default: 20
        - environment_var: parser_embedding_feats
          description: the dimension of the Feats embedding used in the parser
          var_type: int
          optional: true
          default: 20
        - environment_var: parser_embedding_xpostag
          description: the dimension of the XPos embedding used in the parser
          var_type: int
          optional: true
          default: 0
        - environment_var: parser_embedding_form
          description: the dimension of the Form embedding used in the parser
          var_type: int
          optional: true
          default: 50
        - environment_var: parser_embedding_lemma
          description: the dimension of the Lemma embedding used in the parser
          var_type: int
          optional: true
          default: 0
        - environment_var: parser_embedding_deprel
          description: the dimension of the Deprel embedding used in the parser
          var_type: int
          optional: true
          default: 20
        - environment_var: parser_embedding_form_mincount
          description: for forms not present in the pre-trained embeddings, generate
            random embeddings if the form appears at least this number of times in
            the trainig data (forms not present in the pre-trained embeddings and
            appearing less number of times are considered OOV)
          var_type: int
          optional: true
          default: 2
        - environment_var: parser_embedding_lemma_mincount
          description: for lemmas not present in the pre-trained embeddings, generate
            random embeddings if the lemma appears at least this number of times in
            the trainig data (lemmas not present in the pre-trained embeddings and
            appearing less number of times are considered OOV)
          var_type: int
          optional: true
          default: 2
        - environment_var: parser_iterations
          description: number of training iterations to use
          var_type: int
          optional: true
          default: 10
        - environment_var: parser_hidden_layer
          description: the size of the hidden layer
          var_type: int
          optional: true
          default: 200
        - environment_var: parser_batch_size
          description: batch size used during neural-network training
          var_type: int
          optional: true
          default: 10
        - environment_var: parser_learning_rate
          description: the learning rate used during neural-network training
          var_type: float
          optional: true
          default: 0.02
        - environment_var: parser_learning_rate_final
          description: the final learning rate used during neural-network training
          var_type: float
          optional: true
          default: 0.001
        - environment_var: parser_l2
          description: the L2 regularization used during neural-network training
          var_type: float
          optional: true
          default: 0.5
        - environment_var: parser_early_stopping
          description: perform early stopping, choosing training iteration maximizing
            LAS on heldout data
          var_type: bool
          optional: true
          default: false
    services:
      veld_train:
        build: .
        command: /veld/code/train.sh
        volumes:
        - ./data/training/input/:/veld/input/
        - ./data/training/output/:/veld/output/
        - ./src/main/:/veld/code/
        environment:
          train_data_path: null
          model_path: null
          tokenizer: true
          tokenizer_tokenize_url: true
          tokenizer_allow_spaces: null
          tokenizer_dimension: 24
          tokenizer_segment_size: 50
          tokenizer_epochs: 100
          tokenizer_batch_size: 50
          tokenizer_learning_rate: 0.005
          tokenizer_learning_rate_final: 0
          tokenizer_dropout: 0.1
          tokenizer_early_stopping: 1
          tagger: true
          tagger_use_lemma: true
          tagger_provide_lemma: null
          tagger_use_xpostag: null
          tagger_provide_xpostag: null
          tagger_use_feats: null
          tagger_provide_feats: null
          tagger_dictionary_max_form_analyses: 0
          tagger_dictionary_file: null
          tagger_guesser_suffix_rules: 8
          tagger_guesser_prefixes_max: 4
          tagger_guesser_prefix_min_count: 10
          tagger_guesser_enrich_dictionary: 6
          tagger_iterations: 20
          tagger_early_stopping: 0
          tagger_templates: null
          parser: true
          parser_use_gold_tags: null
          parser_embedding_upostag: 20
          parser_embedding_feats: 20
          parser_embedding_xpostag: 0
          parser_embedding_form: 50
          parser_embedding_lemma: 0
          parser_embedding_deprel: 20
          parser_embedding_form_mincount: 2
          parser_embedding_lemma_mincount: 2
          parser_iterations: 10
          parser_hidden_layer: 200
          parser_batch_size: 10
          parser_learning_rate: 0.02
          parser_learning_rate_final: 0.001
          parser_l2: 0.5
          parser_early_stopping: null
veld_code__wikipedia_nlp_preprocessing___veld_download_and_extract.yaml:
  url: https://github.com/veldhub/veld_code__wikipedia_nlp_preprocessing/blob/main/veld_download_and_extract.yaml
  content:
    x-veld:
      code:
        description: downloading wikipedia archive and extracting each article to
          a json file.
        topic:
        - NLP
        - Machine Learning
        - ETL
        output:
        - volume: /veld/output/
          description: a folder containing json files, where each file contains the
            content of a wikipedia article
          file_type: json
          content:
          - NLP training data
          - raw text
        config:
        - environment_var: wikipedia_dump_url
          description: url to a wikipdedia dump download, from https://dumps.wikimedia.org/
          var_type: str
        - environment_var: out_data_description
          description: short human description for the data and its purpose, will
            be persisted in a data veld yaml
          var_type: str
          optional: true
    services:
      veld_download_and_extract:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        - ./data/wikipedia_json/:/veld/output/:z
        command: /veld/code/download_and_extract.sh
        environment:
          wikipedia_dump_url: null
          out_data_description: null
veld_code__wikipedia_nlp_preprocessing___veld_transform_wiki_json_to_txt.yaml:
  url: https://github.com/veldhub/veld_code__wikipedia_nlp_preprocessing/blob/main/veld_transform_wiki_json_to_txt.yaml
  content:
    x-veld:
      code:
        description: transforming wikipedia raw jsons to a single txt file.
        topic:
        - NLP
        - Machine Learning
        - ETL
        input:
        - volume: /veld/input/
          description: a folder containing json files, where each file contains the
            content of a wikipedia article
          file_type: json
          content:
          - NLP training data
          - raw text
        output:
        - volume: /veld/output/
          description: single txt file, containing only raw content of wikipedia pagaes,
            split into sentences or per article with a newline each, possibly being
            only a sampled subset for testing.
          environment_var: out_txt_file
          file_type: txt
          content:
          - NLP training data
          - word embeddings training data
          - raw text
        config:
        - environment_var: out_data_description
          description: short human description for the data and its purpose, will
            be persisted in a data veld yaml
          var_type: str
          optional: true
        - environment_var: cpu_count
          description: number of cpu cores to be used for parallel processing
          var_type: int
          optional: true
          default: maximum number of available cpu cores
        - environment_var: set_split_sentences
          description: Should the resulting txt be split by newlines at each sentence
            boundary? If not, then newlines will be set at the end of each article.
          var_type: bool
          optional: true
          default: false
        - environment_var: sample_size_percentage
          description: As percentage, can be used to transform only a sample of the
            data, for testing purpose most likely. The sample is randomly picked,
            and a random seed can also be set with `sample_random_seed`
          var_type: float
          optional: true
          default: 100
        - environment_var: sample_random_seed
          description: a random seed in case a random sample is drawn and its randomness
            should be fixed.
          var_type: str
          optional: true
          default: null
        - environment_var: buffer_segments
          description: The interval at which progress should be printed. E.g. 100
            means to print hundred times during processing.
          var_type: int
          optional: true
          default: 100
    services:
      veld_transform_wiki_json_to_txt:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        - ./data/wikipedia_json/:/veld/input/
        - ./data/wikipedia_txt/:/veld/output/
        command: python /veld/code/transform_wiki_json_to_txt.py
        environment:
          out_txt_file: null
          out_data_description: null
          cpu_count: null
          set_split_sentences: false
          sample_size_percentage: 100
          sample_random_seed: null
          buffer_segments: 100
veld_code__word2vec___veld_jupyter_notebook.yaml:
  url: https://github.com/veldhub/veld_code__word2vec/blob/main/veld_jupyter_notebook.yaml
  content:
    x-veld:
      code:
        description: a word2vec jupyter notebook, for quick experiments
        topic:
        - NLP
        - Machine Learning
        - word embeddings
        input:
        - volume: /veld/input/
          description: arbitrary storage for word2vec experiments
          file_type:
          - word2vec model
          - training data
          - NLP training data
          - raw text
          content:
          - NLP model
          - word embeddings model
          - model metadata
          - NLP training data
          - word embeddings training data
          - raw text
        output:
        - volume: /veld/output/
          description: arbitrary storage for word2vec experiments
    services:
      veld_jupyter_notebook:
        build: .
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/jupyter_notebook/:/veld/code/:z
        - ./data/input/:/veld/input/:z
        - ./data/output/:/veld/output/:z
veld_code__word2vec___veld_train.yaml:
  url: https://github.com/veldhub/veld_code__word2vec/blob/main/veld_train.yaml
  content:
    x-veld:
      code:
        description: word2vec training setup
        topic:
        - NLP
        - Machine Learning
        - word embeddings
        input:
        - volume: /veld/input/
          environment_var: in_train_data_file
          description: training data. Must be one single txt file, one sentence per
            line.
          file_type: txt
          content:
          - NLP training data
          - word embeddings training data
          - raw text
        output:
        - volume: /veld/output/
          environment_var: out_model_file
          description: self trained word embeddings word2vec model
          file_type: word2vec model
          content:
          - NLP model
          - word embeddings model
        config:
        - environment_var: train_data_description
          description: short human description for the kind of training data
          var_type: str
          optional: true
        - environment_var: model_description
          description: short human description for the overall model and its purpose
          var_type: str
          optional: true
        - environment_var: epochs
          description: 'word2vec hyperparameter: number of training epochs'
          var_type: int
          optional: true
          default: 50
        - environment_var: vector_size
          description: 'word2vec hyperparameter: number of dimensions of the word
            vectors'
          var_type: int
          default: 200
        - environment_var: window
          description: 'word2vec hyperparameter: number of surrounding context words
            to be used for training.'
          var_type: int
          default: 3
        - environment_var: min_count
          description: 'word2vec hyperparameter: minimal number of occurrence for
            each word to be used for training.'
          var_type: int
          default: 5
    services:
      veld_train:
        build: .
        command: python /veld/code/train.py
        volumes:
        - ./src/train/:/veld/code/:z
        - ./data/training_data/:/veld/input/:z
        - ./data/models/:/veld/output/:z
        environment:
          in_train_data_file: null
          out_model_file: null
          model_description: null
          epochs: 50
          vector_size: 200
          window: 3
          min_count: 5
veld_code__wordembeddings_evaluation___veld_analyse_evaluation.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_analyse_evaluation.yaml
  content:
    x-veld:
      code:
        description: data visualization of all evaluation data. In a jupyter notebook.
        topic:
        - NLP
        - word embeddings
        - data visualization
        input:
        - volume: /veld/
          environment_var: in_evaluation_summary_file
          description: summary of the custom evaluation logic on word embeddings
          file_type: yaml
          content: evaluation data
        output:
        - volume: /veld/output/
          environment_var: out_visualization_html_file
          description: data visualization of all evaluation data, expressed as interactive
            html
          file_type: html
          content: data visualization
        - volume: /veld/output/
          environment_var: out_visualization_png_file
          description: data visualization of all evaluation data, expressed as png
          file_type: png
          content: data visualization
    services:
      veld_analyse_evaluation:
        build:
          context: .
          dockerfile: ./build_analyse.dockerfile
        command: jupyter notebook --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
        ports:
        - 8888:8888
        volumes:
        - ./src/analyse/:/veld/code/:z
        environment:
          in_evaluation_summary_file: null
          out_visualization_html_file: null
          out_visualization_png_file: null
veld_code__wordembeddings_evaluation___veld_analyse_evaluation_non_interactive.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_analyse_evaluation_non_interactive.yaml
  content:
    x-veld:
      code:
        description: data visualization of all evaluation data. non-interactive version
          of the juypter code.
        topic:
        - NLP
        - word embeddings
        - data visualization
        input:
        - volume: /veld/input/
          environment_var: in_evaluation_summary_file
          description: summary of the custom evaluation logic on word embeddings
          file_type: yaml
          content: evaluation data
        output:
        - volume: /veld/output/
          environment_var: out_visualization_html_file
          description: data visualization of all evaluation data, expressed as interactive
            html
          file_type: html
          content: data visualization
        - volume: /veld/output/
          environment_var: out_visualization_png_file
          description: data visualization of all evaluation data, expressed as png
          file_type: png
          content: data visualization
    services:
      veld_analyse_evaluation:
        build:
          context: .
          dockerfile: ./build_analyse.dockerfile
        command: ./analyse.sh
        volumes:
        - ./src/analyse/:/veld/code/:z
        environment:
          in_evaluation_summary_file: null
          out_visualization_html_file: null
          out_visualization_png_file: null
veld_code__wordembeddings_evaluation___veld_eval_fasttext.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_eval_fasttext.yaml
  content:
    x-veld:
      code:
        description: custom evaluation logic on fasttext word embeddings.
        topic:
        - NLP
        - Machine learning
        - evaluation
        input:
        - volume: /veld/input/model/
          environment_var: in_model_file
          file_type: fasttext model
          content:
          - NLP model
          - word embeddings model
        - volume: /veld/input/model/
          environment_var: in_model_metadata_file
          file_type: yaml
          content: metadata
        - volume: /veld/input/eval_data/
          environment_var: in_eval_gold_data_file
          file_type: yaml
          content: NLP gold data
        output:
        - volume: /veld/output/summary/
          environment_var: out_eval_summary_file
          file_type: yaml
          description: ''
        - volume: /veld/output/log/
          environment_var: out_eval_log_file
          file_type: txt
          content: logs
    services:
      veld_eval_fasttext:
        build:
          context: .
          dockerfile: ./build_fasttext.dockerfile
        command: python eval_fasttext.py
        volumes:
        - ./src/:/veld/code/:z
        environment:
          in_model_file: null
          in_model_metadata_file: null
          in_2_eval_gold_data_file: null
          out_1_eval_summary_file: null
          out_2_eval_log_file: null
veld_code__wordembeddings_evaluation___veld_eval_glove.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_eval_glove.yaml
  content:
    x-veld:
      code:
        description: custom evaluation logic on GloVe word embeddings.
        topic:
        - NLP
        - Machine learning
        - evaluation
        input:
        - volume: /veld/input/model/
          environment_var: in_vector_file
          file_type: GloVe vector model
          content:
          - NLP model
          - word embeddings model
        - volume: /veld/input/model/
          environment_var: in_model_metadata_file
          file_type: yaml
          content: metadata
        - volume: /veld/input/eval_data/
          environment_var: in_eval_gold_data_file
          file_type: yaml
          content: NLP gold data
        output:
        - volume: /veld/output/summary/
          environment_var: out_eval_summary_file
          file_type: yaml
          description: ''
        - volume: /veld/output/log/
          environment_var: out_eval_log_file
          file_type: txt
          content: logs
        config:
        - environment_var: model_id
          description: id of the model
          var_type: str
    services:
      veld_eval_glove:
        build:
          context: .
          dockerfile: ./build_glove.dockerfile
        command: python3 eval_glove.py
        volumes:
        - ./src/:/veld/code/:z
        environment:
          in_1_vector_file: null
          model_id: null
          in_1_model_metadata_file: null
          in_2_eval_gold_data_file: null
          out_1_eval_summary_file: null
          out_2_eval_log_file: null
veld_code__wordembeddings_evaluation___veld_eval_word2vec.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_evaluation/blob/main/veld_eval_word2vec.yaml
  content:
    x-veld:
      code:
        description: custom evaluation logic on word2vec word embeddings.
        topic:
        - NLP
        - Machine learning
        - evaluation
        input:
        - volume: /veld/input/model/
          environment_var: in_model_file
          description: word2vec model file to be evaluated
          file_type: word2vec model
          content:
          - NLP model
          - word embeddings model
        - volume: /veld/input/model/
          environment_var: in_model_metadata_file
          description: word2vec model metadata
          file_type: yaml
          content: metadata
        - volume: /veld/input/eval_data/
          environment_var: in_eval_gold_data_file
          file_type: yaml
          content: NLP gold data
        output:
        - volume: /veld/output/summary/
          environment_var: out_eval_summary_file
          file_type: yaml
        - volume: /veld/output/log/
          environment_var: out_eval_log_file
          file_type: txt
          content: logs
    services:
      veld_eval_word2vec:
        build:
          context: .
          dockerfile: ./build_word2vec.dockerfile
        command: python eval_word2vec.py
        volumes:
        - ./src/:/veld/code/:z
        - ./data/models/:/veld/input/1/:z
        - ./data/evaluation_gold_data/:/veld/input/2/:z
        - ./data/evaluation_results/summary/:/veld/output/1/:z
        - ./data/evaluation_results/logs/:/veld/output/2/:z
        environment:
          in_1_model_file: null
          in_1_model_metadata_file: null
          in_2_eval_gold_data_file: null
          out_1_eval_summary_file: null
          out_2_eval_log_file: null
veld_code__wordembeddings_preprocessing___veld_preprocess_clean.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_clean.yaml
  content:
    x-veld:
      code:
        description: Removes lines that don't reach a threshold regarding the ratio
          of textual content to non-textual (numbers, special characters) content.
          Splits output into clean and dirty file.
        topic:
        - NLP
        - preprocessing
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_file
          file_type: txt
          content: raw text
        output:
        - volume: /veld/output/
          environment_var: out_file_clean
          description: clean lines, where each line's ratio is above the configured
            threshold
          file_type: txt
          content: raw text
        - volume: /veld/output/
          environment_var: out_file_dirty
          description: dirty lines, where each line's ratio is below the configured
            threshold
          file_type: txt
          content: raw text
        config:
        - environment_var: min_percentage_char
          description: threshold above which a line is considered clean. E.g. 80 means
            80% of character of a line must be textual
          var_type: int
        - environment_var: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          var_type: str
        - environment_var: cpu_count
          description: number of cpu cores allocated to this processing. Defaults
            to maximum number of available cores
          var_type: int
        - environment_var: buffer_segments
          description: percentage of segments where processing results are persisted
            in between. So that processing could continue should it have crashed
          var_type: int
          default: 100
        - environment_var: sleep_duration
          description: number of seceonds between each multiprocess invokation, since
            with big data, a memory race condition can occurr. To work-around this,
            a small waiting period in between can be set with this variable.
          var_type: int
          default: 10
    services:
      veld_preprocess_clean:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 /veld/code/preprocess_clean.py
        environment:
          in_file: null
          out_file_clean: null
          out_file_dirty: null
          out_data_veld_yaml: null
          min_percentage_char: null
          out_data_description: null
          cpu_count: null
          buffer_segments: 100
          sleep_duration: 10
veld_code__wordembeddings_preprocessing___veld_preprocess_lowercase.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_lowercase.yaml
  content:
    x-veld:
      code:
        description: makes entire text lowercase
        topic:
        - NLP
        - preprocessing
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_txt_file
          file_type: txt
          content: raw text
        output:
        - volume: /veld/output/
          environment_var: out_txt_file
          file_type: txt
          content: raw text
        config:
        - environment_var: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          var_type: str
    services:
      veld_preprocess_lowercase:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 /veld/code/preprocess_lowercase.py
        environment:
          in_txt_file: null
          out_txt_file: null
          out_data_description: null
veld_code__wordembeddings_preprocessing___veld_preprocess_remove_punctuation.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_remove_punctuation.yaml
  content:
    x-veld:
      code:
        description: removes punctuation from text with spaCy pretrained models
        topic:
        - NLP
        - preprocessing
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_txt_file
          file_type: txt
          content: raw text
        output:
        - volume: /veld/output/txt/
          environment_var: out_txt_file
          file_type: txt
          content: raw text
        - volume: /veld/output/tmp/
          file_type: txt
          content: raw text
        config:
        - environment_var: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          var_type: str
        - environment_var: cpu_count
          description: number of cpu cores allocated to this processing. Defaults
            to maximum number of available cores
          var_type: int
        - environment_var: buffer_segments
          description: percentage of segments where processing results are persisted
            in between. So that processing could continue should it have crashed
          var_type: int
          default: 100
        - environment_var: sleep_duration
          description: number of seceonds between each multiprocess invokation, since
            with big data, a memory race condition can occurr. To work-around this,
            a small waiting period in between can be set with this variable.
          var_type: int
          default: 10
    services:
      veld_preprocess_remove_punctuation:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 -u /veld/code/preprocess_remove_punctuation.py
        environment:
          in_txt_file: null
          out_txt_file: null
          cpu_count: null
          buffer_segments: 100
          out_data_description: null
          sleep_duration: 10
veld_code__wordembeddings_preprocessing___veld_preprocess_sample.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_sample.yaml
  content:
    x-veld:
      code:
        description: takes a random sample of lines from a txt file. Randomness can
          be set with a seed too
        topic:
        - NLP
        - preprocessing
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_txt_file
          file_type: txt
          content: raw text
        output:
        - volume: /veld/output/
          environment_var: out_txt_file
          file_type: txt
          content: raw text
        config:
        - environment_var: out_data_description
          description: automatic data description for generating a data veld yaml
            file
          var_type: str
        - environment_var: percentage_sample
          description: percentage of lines to be randomly sampled
          var_type: int
        - environment_var: sample_random_seed
          description: seed to make randomness stable and reproducible
          var_type: str
        - environment_var: buffer_segments
          description: percentage of segments where processing results are persisted
            in between. So that processing could continue should it have crashed
          var_type: int
          default: 100
    services:
      veld_preprocess_sample:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: python3 /veld/code/preprocess_sample.py
        environment:
          in_file: null
          out_file: null
          out_data_description: null
          percentage_sample: null
          sample_random_seed: null
          buffer_segments: 100
veld_code__wordembeddings_preprocessing___veld_preprocess_strip.yaml:
  url: https://github.com/veldhub/veld_code__wordembeddings_preprocessing/blob/main/veld_preprocess_strip.yaml
  content:
    x-veld:
      code:
        description: removes all lines before and after given line numbers
        topic:
        - NLP
        - preprocessing
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_file
          file_type: txt
          content: raw text
        output:
        - volume: /veld/output/
          environment_var: out_file
          file_type: txt
          content: raw text
        config:
        - environment_var: line_start
          description: line number before which lines will be stripped away. E.g.
            line_start=50 removes lines from 1-49
          var_type: int
        - environment_var: line_end
          description: line number after which lines will be stripped away. E.g. line_end=100
            removes lines from 101-end
          var_type: int
    services:
      veld_preprocess_strip:
        build: .
        volumes:
        - ./src/:/veld/code/:z
        command: /veld/code/preprocess_strip.sh
        environment:
          in_file: null
          out_file: null
          line_start: null
          line_end: null
veld_code__xmlanntools___veld_ann2standoff.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_ann2standoff.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the ann2standoff script. For more
          documentation, see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#ann2standoff'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/data/
          environment_var: in_conllu_file
          file_type:
          - conllu
          - tsv
        - volume: /veld/input/data/
          environment_var: in_txt_file
          file_type: txt
        - volume: /veld/input/config/
          environment_var: in_ann2standoff_ini_file
          file_type: ini
        output:
        - volume: /veld/output/
          environment_var: out_json_file
          file_type: json
        config:
        - environment_var: profile_name
          var_type: str
          default: DEFAULT
          optional: true
    services:
      veld_ann2standoff:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/ann2standoff/in/data/:/veld/input/data/
        - ./data/ann2standoff/in/config/:/veld/input/config/
        - ./data/ann2standoff/out/:/veld/output/
        command: ./veld_ann2standoff.sh
        environment:
          in_conllu_file: null
          in_txt_file: null
          in_ann2standoff_ini_file: null
          out_json_file: null
          profile_name: DEFAULT
veld_code__xmlanntools___veld_standoff2xml.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_standoff2xml.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the standoff2xml script. For more
          documentation, see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#standoff2xml'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_txt_file
          file_type: txt
        - volume: /veld/input/
          environment_var: in_json_file
          file_type: json
        - volume: /veld/input/
          environment_var: in_ann_json_file
          file_type: json
        output:
        - volume: /veld/output/
          environment_var: out_ann_xml_file
          file_type: xml
        config:
        - environment_var: token_annotation
          var_type: bool
          default: false
          optional: true
        - environment_var: warn_breaking
          var_type: str
          optional: true
        - environment_var: keep_between_sentences
          var_type: bool
          default: false
          optional: true
    services:
      veld_standoff2xml:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/standoff2xml/in/:/veld/input/
        - ./data/standoff2xml/out/:/veld/output/
        command: ./veld_standoff2xml.sh
        environment:
          in_txt_file: null
          in_json_file: null
          in_ann_json_file: null
          out_ann_xml_file: null
          token_annotation: false
          warn_breaking: null
          keep_between_sentences: false
veld_code__xmlanntools___veld_tag_ud.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_tag_ud.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the tag_ud script. For more documentation,
          see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#tag_ud'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_txt_file
          file_type: txt
        output:
        - volume: /veld/output/
          environment_var: out_conllu_file
          file_type:
          - tsv
          - conllu
        config:
        - environment_var: model
          var_type: str
        - environment_var: batch
          var_type: int
          default: 1000
          optional: true
        - environment_var: verbose
          var_type: bool
          default: false
          optional: true
    services:
      veld_tag_ud:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/tag_ud/in/:/veld/input/
        - ./data/tag_ud/out/:/veld/output/
        command: ./veld_tag_ud.sh
        environment:
          in_txt_file: null
          out_conllu_file: null
          model: null
          batch: 1000
          verbose: false
veld_code__xmlanntools___veld_xml2standoff.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_xml2standoff.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the xml2standoff script. For more
          documentation, see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#xml2standoff'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/
          environment_var: in_xml_file
          file_type: xml
        output:
        - volume: /veld/output/
          environment_var: out_txt_file
          file_type: txt
        - volume: /veld/output/
          environment_var: out_json_file
          file_type: json
        config:
        - environment_var: text_elements
          var_type: str
          optional: true
        - environment_var: exclude_elements
          var_type: str
          optional: true
        - environment_var: keep_linebreaks
          var_type: bool
          default: false
          optional: true
    services:
      veld_xml2standoff:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/xml2standoff/in/:/veld/input/
        - ./data/xml2standoff/out/:/veld/output/
        command: ./veld_xml2standoff.sh
        environment:
          in_xml_file: null
          out_txt_file: null
          out_json_file: null
          text_elements: null
          exclude_elements: null
          keep_linebreaks: false
veld_code__xmlanntools___veld_xml2vrt.yaml:
  url: https://github.com/veldhub/veld_code__xmlanntools/blob/main/veld_xml2vrt.yaml
  content:
    x-veld:
      code:
        description: 'A demo code veld, integrating the xml2vrt script. For more documentation,
          see: https://github.com/czcorpus/xmlanntools?tab=readme-ov-file#xml2vrt'
        topic:
        - NLP
        - ETL
        input:
        - volume: /veld/input/data/
          environment_var: in_ann_xml_file
          file_type: xml
        - volume: /veld/input/config/
          environment_var: in_ann2standoff_ini_file
          file_type: ini
        output:
        - volume: /veld/output/
          environment_var: out_conlluish_xml_file
          file_type: xml
        config:
        - environment_var: attributes
          var_type: str
          optional: true
        - environment_var: token_element
          var_type: str
          optional: true
        - environment_var: include_elements
          var_type: str
          optional: true
        - environment_var: exclude_elements
          var_type: str
          optional: true
        - environment_var: keep_token_tags
          var_type: bool
          default: false
          optional: true
        - environment_var: keep_empty
          var_type: bool
          default: false
          optional: true
        - environment_var: discard_freetext
          var_type: bool
          default: false
          optional: true
        - environment_var: no_glue
          var_type: bool
          default: false
          optional: true
        - environment_var: glue
          var_type: str
          optional: true
        - environment_var: fragment
          var_type: bool
          default: false
          optional: true
        - environment_var: no_flattening
          var_type: bool
          default: false
          optional: true
    services:
      veld_xml2vrt:
        build: .
        volumes:
        - ./:/veld/code/
        - ./data/xml2vrt/in/data/:/veld/input/data/
        - ./data/xml2vrt/in/config/:/veld/input/config/
        - ./data/xml2vrt/out/:/veld/output/
        command: ./veld_xml2vrt.sh
        environment:
          in_ann_xml_file: null
          in_ann2standoff_ini_file: null
          out_conlluish_xml_file: null
          attributes: null
          token_element: null
          include_elements: null
          exclude_elements: null
          keep_token_tags: false
          keep_empty: false
          discard_freetext: false
          no_glue: false
          glue: null
          fragment: false
          no_flattening: false
veld_code__xml_xslt_transformer___veld.yaml:
  url: https://github.com/veldhub/veld_code__xml_xslt_transformer/blob/main/veld.yaml
  content:
    x-veld:
      code:
        description: generic xml / xslt transformation setup.
        topic:
        - ETL
        - preprocessing
        input:
        - volume: /veld/input/xml/
          environment_var: in_xml_file
          description: the input xml file or folder containing xml. Note that if var
            `in_xml_file` is set, this script will only transform that file. If it's
            not set, it will go through the input folder recursively and create an
            equivalent output data structure.
          file_type: xml
          optional: true
        - volume: /veld/input/xsl/
          environment_var: in_xsl_file
          description: the input xsl file or folder containing xsl
          file_type: xslt
          optional: true
        output:
        - volume: /veld/output/
          environment_var: out_txt_file
          description: output file or folder for converted txt. Note that the var
            'out_txt_file' is only respected, when the input is a single xml file.
            If the input is a folder, the output will be an equivalent data structure
            and the var 'out_txt_file' is ignored.
          file_type:
          - xml
          - txt
    services:
      veld:
        build: .
        command: /veld/code/transform.sh
        volumes:
        - ./src/:/veld/code/
        environment:
          in_xsl_file: null
          in_xml_file: null
          out_txt_file: null
veld_chain__akp_ner_inference___veld_infer.yaml:
  url: https://github.com/veldhub/veld_chain__akp_ner_inference/blob/main/veld_infer.yaml
  content:
    x-veld:
      chain:
        description: This repo uses self-trained spaCy NER models on the linkedcat
          dataset to extract entities, which are stored in csv files.
        topic:
        - NLP
        - Machine learning
        - Named entity recognition
    services:
      veld_infer:
        extends:
          file: ./code/veld_code__akp_ner_inference/veld_infer.yaml
          service: veld_infer
        volumes:
        - ./data/veld_data__apis_spacy_ner_models/m1/model-best/:/veld/input/
        - ./data/veld_data__akp_ner_linkedcat/linkedcat2/:/veld/output/
        environment:
          solr_core_url: http://linkedcat-solr.acdh-cluster-2.arz.oeaw.ac.at/solr/linkedcat2
          out_csv_file: linkedcat2.csv
veld_chain__apis_ner_evaluate_old_models___veld_evaluate.yaml:
  url: https://github.com/veldhub/veld_chain__apis_ner_evaluate_old_models/blob/main/veld_evaluate.yaml
  content:
    x-veld:
      chain:
        description: hard-coded evaluation of several spaCy 2.2.4 models.
        topic:
        - NLP
        - Machine learning
        - Named entity recognition
    services:
      veld_evaluate:
        extends:
          file: ./code/veld_code__apis_ner_evaluate_old_models/veld_evaluate.yaml
          service: veld_evaluate
        volumes:
        - ./data/spacy-ner/:/veld/input/
        - ./data/spacy-ner/:/veld/output/
        environment:
          out_eval_result_file: reevaluations_all.md
veld_chain__apis_ner_transform_to_gold___veld.yaml:
  url: https://github.com/veldhub/veld_chain__apis_ner_transform_to_gold/blob/main/veld.yaml
  content:
    x-veld:
      chain:
        description: Conversion of apis ner model data to harmonized custom json format.
        topic:
        - ETL
        - data cleaning
    services:
      veld:
        extends:
          file: ./code/veld_code__apis_ner_transform_to_gold/veld.yaml
          service: veld
        volumes:
        - ./data/veld_data__apis_spacy_ner_legacy/:/veld/input/
        - ./data/veld_data__apis_oebl__ner_gold/data_uncleaned:/veld/output/uncleaned/
        - ./data/veld_data__apis_oebl__ner_gold/data_cleaned:/veld/output/cleaned/
        - ./data/veld_data__apis_oebl__ner_gold/data_cleaned_simplified:/veld/output/cleaned_simplified/
        - ./:/veld/output/log/
        environment:
          out_json_uncleaned_file: uncleaned.json
          out_json_cleaned_file: cleaned.json
          out_json_cleaned_simplified_file: cleaned_simplified.json
          out_log_file: extract_and_clean.log
veld_chain__demo_teitok-tools___veld_parseudpipe.yaml:
  url: https://github.com/veldhub/veld_chain__demo_teitok-tools/blob/main/veld_parseudpipe.yaml
  content:
    x-veld:
      chain:
        description: 'This chain veld exemplifies usage of the respective code veld.
          For more information on the underlying tool and its usage, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#parseudpipe'
        topic:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
    services:
      veld_parseudpipe:
        extends:
          file: ./code/veld_code__teitok-tools/veld_parseudpipe.yaml
          service: veld_parseudpipe
        volumes:
        - ./data/parseudpipe/in/:/veld/input/
        - ./data/parseudpipe/out/:/veld/output/
        environment:
          in_xml_file: DEU001_tokenized.xml
          out_xml_file: DEU001.xml
          model: german-hdt-ud-2.6-200830
          sent: p
veld_chain__demo_teitok-tools___veld_udpipe2teitok.yaml:
  url: https://github.com/veldhub/veld_chain__demo_teitok-tools/blob/main/veld_udpipe2teitok.yaml
  content:
    x-veld:
      chain:
        description: 'This chain veld exemplifies usage of the respective code veld.
          For more information on the underlying tool and its usage, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#udpipe2teitok'
        topic:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
    services:
      veld_udpipe2teitok:
        extends:
          file: ./code/veld_code__teitok-tools/veld_udpipe2teitok.yaml
          service: veld_udpipe2teitok
        volumes:
        - ./data/udpipe2teitok/in/:/veld/input/
        - ./data/udpipe2teitok/out/:/veld/output/
        environment:
          lang: de
          model: german-hdt-ud-2.6-200830
          mixed: true
veld_chain__demo_teitok-tools___veld_xmltokenize.yaml:
  url: https://github.com/veldhub/veld_chain__demo_teitok-tools/blob/main/veld_xmltokenize.yaml
  content:
    x-veld:
      chain:
        description: 'This chain veld exemplifies usage of the respective code veld.
          For more information on the underlying tool and its usage, see: https://github.com/ufal/teitok-tools?tab=readme-ov-file#xmltokenize'
        topic:
        - NLP
        - ETL
        - tokenization
        - universal dependencies
    services:
      veld_xmltokenize:
        extends:
          file: ./code/veld_code__teitok-tools/veld_xmltokenize.yaml
          service: veld_xmltokenize
        volumes:
        - ./data/xmltokenize/in/:/veld/input/
        - ./data/xmltokenize/out/:/veld/output/
        environment:
          in_xml_file: DEU001.xml
          out_xml_file: DEU001.xml
          textnode: body
          tok: xyz
          enumerate: true
veld_chain__demo_udipe_ts-vienna-2024___veld_infer.yaml:
  url: https://github.com/veldhub/veld_chain__demo_udipe_ts-vienna-2024/blob/main/veld_infer.yaml
  content:
    x-veld:
      chain:
        description: A demonstration of a VELD chain inferencing on a txt with a self-trained
          udpipe model
        topic:
        - NLP
        - universal dependencies
    services:
      veld_infer:
        extends:
          file: ./code/veld_code__udpipe/veld_infer.yaml
          service: veld_infer
        volumes:
        - ./data/veld_data__demo_inference_input_ts-vienna-2024/:/veld/input/txt/
        - ./data/veld_data__demo_updipe_models_ts-vienna-2024/:/veld/input/model/
        - ./data/veld_data__demo_inference_output_ts-vienna-2024/:/veld/output/
        environment:
          in_txt_file: rumpelstiltskin.txt
          in_model_file: en_ewt-ud.udpipe
veld_chain__demo_udipe_ts-vienna-2024___veld_train.yaml:
  url: https://github.com/veldhub/veld_chain__demo_udipe_ts-vienna-2024/blob/main/veld_train.yaml
  content:
    x-veld:
      chain:
        description: A demonstration of a VELD chain training a udpipe model from
          scratch
        topic:
        - NLP
        - universal dependencies
    services:
      veld_train:
        extends:
          file: ./code/veld_code__udpipe/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/veld_data__demo_train_data_ts-vienna-2024/:/veld/input/
        - ./data/veld_data__demo_updipe_models_ts-vienna-2024/:/veld/output/
        environment:
          train_data_path: en_ewt-ud.conllu
          model_path: en_ewt-ud.udpipe
          tokenizer_epochs: 2
          tagger_iterations: 2
          parser_iterations: 2
veld_chain__demo_wordembeddings_multiarch___veld_jupyter_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_jupyter_word2vec.yaml
  content:
    x-veld:
      chain:
        description: demo word2vec jupyter notebook
        topic:
        - NLP
        - Machine Learning
        - word embeddings
    services:
      veld_jupyter_notebook:
        extends:
          file: ./code/veld_code__word2vec/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/models/word2vec/:/veld/input/:z
veld_chain__demo_wordembeddings_multiarch___veld_preprocess.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_preprocess.yaml
  content:
    x-veld:
      chain:
        description: Download and preprocessing of the bible
        topic:
        - ETL
        - NLP
        - bible studies
    services:
      veld_downloader:
        extends:
          file: ./code/veld_code__downloader/veld.yaml
          service: veld_downloader
        volumes:
        - ./data/training_data/:/veld/output/
        environment:
          url: https://raw.githubusercontent.com/mxw/grmr/master/src/finaltests/bible.txt
          out_file: bible.txt
      veld_bible_preprocess:
        build: ./code/bible_preprocess/
        command: python /veld/code/bible_preprocess.py
        volumes:
        - ./code/bible_preprocess/bible_preprocess.py:/veld/code/bible_preprocess.py
        - ./data/training_data/:/veld/input/
        - ./data/training_data/:/veld/output/
        environment:
          in_file: bible.txt
          out_file: bible.txt
        depends_on:
          veld_downloader:
            condition: service_completed_successfully
veld_chain__demo_wordembeddings_multiarch___veld_train_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__demo_wordembeddings_multiarch/blob/main/veld_train_word2vec.yaml
  content:
    x-veld:
      chain:
        description: demo word2vec training on the bible
        topic:
        - NLP
        - Machine Learning
        - word embeddings
    services:
      veld_train:
        extends:
          file: ./code/veld_code__word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/:/veld/input/
        - ./data/models/word2vec/m1/:/veld/output/
        environment:
          in_train_data_file: bible.txt
          out_model_file: m1.bin
          model_description: trained on bible with simple hyperparams
          epochs: 20
          vector_size: 200
          window: 5
          min_count: 5
veld_chain__eltec_udpipe_inference___veld_analyse.yaml:
  url: https://github.com/veldhub/veld_chain__eltec_udpipe_inference/blob/main/veld_analyse.yaml
  content:
    x-veld:
      chain:
        description: chain to analyse the conllu data which was inferenced by udpipe
          on several ELTeC corpora.
        topic:
        - NLP
        - Machine learning
        - tokenization
        - lemmatization
        - part of speech
        - dependency parsing
        - universal dependencies
        - grammatical annotation
    services:
      veld_analyse:
        extends:
          file: ./code/veld_code__analyse_conllu/veld.yaml
          service: veld
        volumes:
        - ./data/data_tmp_conllu_inferenced/:/veld/input/
        - ./data/veld_data__eltec_conllu_stats/data/:/veld/output/
veld_chain__eltec_udpipe_inference___veld_infer.yaml:
  url: https://github.com/veldhub/veld_chain__eltec_udpipe_inference/blob/main/veld_infer.yaml
  content:
    x-veld:
      chain:
        description: udpipe inference setup, reading in preprocessed ELTeC data
        topic:
        - NLP
        - Machine learning
        - tokenization
        - lemmatization
        - part of speech
        - dependency parsing
        - universal dependencies
        - grammatical annotation
    x-vars:
    - &id002
      file: ./code/veld_code__udpipe/veld_infer.yaml
      service: veld_infer
    - &id001
      file: ./code/veld_code__downloader/veld.yaml
      service: veld_downloader
    - - ./data/data_tmp_txt_transformed/:/veld/input/txt/
      - ./data/data_tmp_conllu_inferenced/:/veld/output/
    services:
      veld_download_cze:
        extends: *id001
        volumes:
        - ./data/data_tmp_udpipe_models/cze/:/veld/output/
        environment:
          url: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/czech-pdt-ud-2.5-191206.udpipe
      veld_infer_cze:
        extends: *id002
        volumes:
        - ./data/data_tmp_txt_transformed/ELTeC-cze/level1/:/veld/input/txt/
        - ./data/data_tmp_udpipe_models/cze/:/veld/input/model/
        - ./data/data_tmp_conllu_inferenced/ELTeC-cze/level1/:/veld/output/
        environment:
          in_model_file: czech-pdt-ud-2.5-191206.udpipe
        depends_on:
          veld_download_cze:
            condition: service_completed_successfully
      veld_download_deu:
        extends: *id001
        volumes:
        - ./data/data_tmp_udpipe_models/deu/:/veld/output/
        environment:
          url: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/german-hdt-ud-2.5-191206.udpipe
      veld_infer_deu:
        extends: *id002
        volumes:
        - ./data/data_tmp_txt_transformed/ELTeC-deu/level1/:/veld/input/txt/
        - ./data/data_tmp_udpipe_models/deu/:/veld/input/model/
        - ./data/data_tmp_conllu_inferenced/ELTeC-deu/level1/:/veld/output/
        environment:
          in_model_file: german-hdt-ud-2.5-191206.udpipe
        depends_on:
          veld_download_deu:
            condition: service_completed_successfully
      veld_download_eng:
        extends: *id001
        volumes:
        - ./data/data_tmp_udpipe_models/eng/:/veld/output/
        environment:
          url: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/english-ewt-ud-2.5-191206.udpipe
      veld_infer_eng:
        extends: *id002
        volumes:
        - ./data/data_tmp_txt_transformed/ELTeC-eng/level1/:/veld/input/txt/
        - ./data/data_tmp_udpipe_models/eng/:/veld/input/model/
        - ./data/data_tmp_conllu_inferenced/ELTeC-eng/level1/:/veld/output/
        environment:
          in_model_file: english-ewt-ud-2.5-191206.udpipe
        depends_on:
          veld_download_eng:
            condition: service_completed_successfully
      veld_download_fra:
        extends: *id001
        volumes:
        - ./data/data_tmp_udpipe_models/fra/:/veld/output/
        environment:
          url: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/french-gsd-ud-2.5-191206.udpipe
      veld_infer_fra:
        extends: *id002
        volumes:
        - ./data/data_tmp_txt_transformed/ELTeC-fra/level1/:/veld/input/txt/
        - ./data/data_tmp_udpipe_models/fra/:/veld/input/model/
        - ./data/data_tmp_conllu_inferenced/ELTeC-fra/level1/:/veld/output/
        environment:
          in_model_file: french-gsd-ud-2.5-191206.udpipe
        depends_on:
          veld_download_fra:
            condition: service_completed_successfully
      veld_download_spa:
        extends: *id001
        volumes:
        - ./data/data_tmp_udpipe_models/spa/:/veld/output/
        environment:
          url: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/spanish-gsd-ud-2.5-191206.udpipe
      veld_infer_spa:
        extends: *id002
        volumes:
        - ./data/data_tmp_txt_transformed/ELTeC-spa/level1/:/veld/input/txt/
        - ./data/data_tmp_udpipe_models/spa/:/veld/input/model/
        - ./data/data_tmp_conllu_inferenced/ELTeC-spa/level1/:/veld/output/
        environment:
          in_model_file: spanish-gsd-ud-2.5-191206.udpipe
        depends_on:
          veld_download_spa:
            condition: service_completed_successfully
veld_chain__eltec_udpipe_inference___veld_preprocess.yaml:
  url: https://github.com/veldhub/veld_chain__eltec_udpipe_inference/blob/main/veld_preprocess.yaml
  content:
    x-veld:
      chain:
        description: xml / xslt transformation of ELTeC data
        topic:
        - NLP
        - Machine learning
        - tokenization
        - lemmatization
        - part of speech
        - dependency parsing
        - universal dependencies
        - grammatical annotation
    x-vars:
    - &id003
      file: ./code/veld_code__xml_xslt_transformer/veld.yaml
      service: veld
    - &id004
      in_xsl_file: transformation.xsl
    services:
      veld_preprocess_cze:
        extends: *id003
        volumes:
        - ./data/veld_data__eltec_original_selection/data/ELTeC-cze/level1/:/veld/input/xml/
        - ./data/xsl/:/veld/input/xsl/
        - ./data/data_tmp_txt_transformed/ELTeC-cze/level1/:/veld/output/
        environment: *id004
      veld_preprocess_deu:
        extends: *id003
        volumes:
        - ./data/veld_data__eltec_original_selection/data/ELTeC-deu/level1/:/veld/input/xml/
        - ./data/xsl/:/veld/input/xsl/
        - ./data/data_tmp_txt_transformed/ELTeC-deu/level1/:/veld/output/
        environment: *id004
      veld_preprocess_eng:
        extends: *id003
        volumes:
        - ./data/veld_data__eltec_original_selection/data/ELTeC-eng/level1/:/veld/input/xml/
        - ./data/xsl/:/veld/input/xsl/
        - ./data/data_tmp_txt_transformed/ELTeC-eng/level1/:/veld/output/
        environment: *id004
      veld_preprocess_fra:
        extends: *id003
        volumes:
        - ./data/veld_data__eltec_original_selection/data/ELTeC-fra/level1/:/veld/input/xml/
        - ./data/xsl/:/veld/input/xsl/
        - ./data/data_tmp_txt_transformed/ELTeC-fra/level1/:/veld/output/
        environment: *id004
      veld_preprocess_spa:
        extends: *id003
        volumes:
        - ./data/veld_data__eltec_original_selection/data/ELTeC-spa/level1/:/veld/input/xml/
        - ./data/xsl/:/veld/input/xsl/
        - ./data/data_tmp_txt_transformed/ELTeC-spa/level1/:/veld/output/
        environment: *id004
veld_chain__mara_load_and_publish_models___veld_publish_to_hf.yaml:
  url: https://github.com/veldhub/veld_chain__mara_load_and_publish_models/blob/main/veld_publish_to_hf.yaml
  content:
    x-veld:
      chain:
        description: publish SpaCy text classification models trained during the MARA
          project to huggingface
        topic:
        - NLP
    services:
      veld_publish_to_hf:
        build: ./code/mara-nlp-suite__spacy-build/
        command: python /veld/code/test.py
        volumes:
        - ./code/mara-nlp-suite__spacy-build/test.py:/veld/code/test.py
        - ./data/mara-nlp-suite-internal/data_internal/models/mo3/:/veld/input/
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_analyse_evaluation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_analyse_evaluation.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_analyse_evaluation:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_analyse_evaluation.yaml
          service: veld_analyse_evaluation
        volumes:
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/input/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/:z
        environment_var:
          in_evaluation_summary_file: summary.yaml
          out_visualization_html_file: summary_visualized.html
          out_visualization_png_file: summary_visualized.png
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_analyse_evaluation_non_interactive.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_analyse_evaluation_non_interactive.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_analyse_evaluation_non_interactive:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_analyse_evaluation_non_interactive.yaml
          service: veld_analyse_evaluation
        volumes:
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/input/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/:z
        environment:
          in_evaluation_summary_file: summary.yaml
          out_visualization_html_file: summary_visualized.html
          out_visualization_png_file: summary_visualized.png
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_eval_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_eval_fasttext.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_eval_fasttext:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_fasttext.yaml
          service: veld_eval_fasttext
        volumes:
        - ./data/veld_data__fasttext_models/m9/:/veld/input/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/fasttext/:/veld/output/2:z
        environment:
          in_1_model_file: m9.bin
          in_1_model_metadata_file: veld.yaml
          in_2_eval_gold_data_file: eval_data_lowercase.yaml
          out_1_eval_summary_file: summary.yaml
          out_2_eval_log_file: m9.txt
        depends_on:
          veld_train_fasttext:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_eval_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_eval_glove.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_eval_glove:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_glove.yaml
          service: veld_eval_glove
        volumes:
        - ./data/veld_data__glove_models/data/m3/:/veld/input/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/glove/:/veld/output/2/:z
        environment:
          in_1_vector_file: m3_vector.txt
          model_id: m3
          in_1_model_metadata_file: veld.yaml
          in_2_eval_gold_data_file: eval_data_lowercase.yaml
          out_1_eval_summary_file: summary.yaml
          out_2_eval_log_file: m3.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_eval_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_eval_word2vec.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_eval_word2vec:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_word2vec.yaml
          service: veld_eval_word2vec
        volumes:
        - ./data/veld_data__word2vec_models/m9/:/veld/input/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/1/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/word2vec/:/veld/output/2:z
        environment:
          in_1_model_file: m9.bin
          in_1_model_metadata_file: veld.yaml
          in_2_eval_gold_data_file: eval_data_lowercase.yaml
          out_1_eval_summary_file: summary.yaml
          out_2_eval_log_file: m9.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_jupyter_notebook_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_jupyter_notebook_fasttext.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_jupyter_notebook_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        ports:
        - 8889:8888
        volumes:
        - ./data/veld_data__amc_we_training_data/:/veld/storage/data/veld_data__amc_we_training_data/:z
        - ./data/veld_data__fasttext_models/:/veld/storag./data/veld_data__fasttext_models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_jupyter_notebook_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_jupyter_notebook_glove.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_jupyter_notebook_glove:
        extends:
          file: ./code/veld_code__glove/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        ports:
        - 8890:8888
        volumes:
        - ./data/veld_data__amc_we_training_data/:/veld/storage/data/veld_data__amc_we_training_data/:z
        - ./data/veld_data__glove_models/:/veld/storag./data/veld_data__glove_models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_jupyter_notebook_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_jupyter_notebook_word2vec.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_jupyter_notebook_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        ports:
        - 8891:8888
        volumes:
        - ./data/veld_data__amc_we_training_data/:/veld/storage/data/veld_data__amc_we_training_data/:z
        - ./data/veld_data__word2vec_models/:/veld/storag./data/veld_data__word2vec_models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_clean.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_clean.yaml
  content:
    x-veld:
      code: null
    services:
      veld_preprocess_clean:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_clean.yaml
          service: veld_preprocess_clean
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed/:/veld/input/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/:/veld/output/1/:z
        - ./tmp_clean/:/veld/output/2/clean/:z
        - ./tmp_dirty/:/veld/output/2/dirty/:z
        environment:
          in_file: data.txt
          out_file_clean: data.txt
          out_file_dirty: data_dirty.txt
          min_percentage_char: 80
          out_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
            sampled, lowercased, punctuation removed, cleaned from lines not having
            enough text'
          cpu_count: 15
          buffer_segments: 100
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_lowercase.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_lowercase.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_preprocess_lowercase:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled/:/veld/input/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased/:/veld/output/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
            sampled, lowercased.'
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_remove_punctuation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_remove_punctuation.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_preprocess_remove_punctuation:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased/:/veld/input/:z
        - ./tmp/:/veld/output/2/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed/:/veld/output/1/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: 'AMC data: stripped from non-alphanumeric lines, lowercased,
            punctuation removed.'
          cpu_count: 14
          buffer_segments: 1000
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_sample.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_sample.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_preprocess_sample:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_sample.yaml
          service: veld_preprocess_sample
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped/:/veld/input/:z
        - ./exp_bert_tmp/:/veld/output/:z
        environment:
          in_file: data.txt
          out_file: data.txt
          out_data_description: 10% of AMC
          percentage_sample: 0.01
          sample_random_seed: 42
          buffer_segments: 100
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_preprocess_strip.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_preprocess_strip.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_preprocess_strip:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_strip.yaml
          service: veld_preprocess_strip
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq/:/veld/input/:z
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped/:/veld/output/:z
        environment:
          in_file: data.txt
          out_file: data.txt
          line_start: 54993
          line_end: 521781020
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_train_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_train_fasttext.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_train_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_train.yaml
          service: veld_train
        volumes:
        - ./veld_data_amc_we_training_data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/:/veld/input/:z
        - ./veld_data_fasttext_models/m9/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m9.bin
          model_description: 100% AMC model
          vector_size: 300
          epochs: 10
          window_size: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_train_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_train_glove.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_train_glove:
        extends:
          file: ./code/veld_code__glove/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__sampled__lowercased__punctuation_removed__cleaned/:/veld/input/:z
        - ./data/veld_data__glove_models/data/m4/:/veld/output/:z
        environment:
          in_corpus_file: data.txt
          out_vocab_file: m4_vocab.txt
          out_cooccurrence_file: m4_cooccurrence.bin
          out_cooccurrence_shuf_file: m4_cooccurrence_shuf.bin
          out_vector_file: m4_vector
          model_id: m4
          model_description: 10% AMC model
          verbose: 2
          memory: 4.0
          vocab_min_count: 5
          vector_size: 200
          max_iter: 10
          window_size: 15
          binary: 2
          num_threads: 14
          x_max: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__amc___veld_train_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__amc/blob/main/veld_train_word2vec.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_train_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/veld_data__amc_we_training_data/data/203_vert_rftt_inhalt_nodup__uniq__stripped__lowercased__punctuation_removed__cleaned/:/veld/input/:z
        - ./data/veld_data__word2vec_models/m8/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m8.bin
          model_description: 100% AMC model
          epochs: 10
          vector_size: 300
          window: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_playground_jupyter_notebook_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_playground_jupyter_notebook_fasttext.yaml
  content:
    x-veld:
      chain:
        description: jupyter notebook for playing with fasttext models
        topic: NLP
    services:
      veld_jupyter_notebook_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/training_data/:/veld/storage/training_data/:z
        - ./data/models/fasttext/:/veld/storage/models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_playground_jupyter_notebook_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_playground_jupyter_notebook_glove.yaml
  content:
    x-veld:
      chain:
        description: jupyter notebook for playing with glove models
        topic: NLP
    services:
      veld_jupyter_notebook_glove:
        extends:
          file: ./code/veld_code__glove/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/training_data/:/veld/storage/training_data/:z
        - ./data/models/glove/:/veld/storage/models/:z
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_playground_jupyter_notebook_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_playground_jupyter_notebook_word2vec.yaml
  content:
    x-veld:
      chain:
        description: jupyter notebook for playing with word2vec models
        topic: NLP
    services:
      veld_jupyter_notebook_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_jupyter_notebook.yaml
          service: veld_jupyter_notebook
        volumes:
        - ./data/training_data/:/veld/storage/training_data/:z
        - ./data/models/word2vec/:/veld/storage/models/:z
? veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_01_preprocess_download_and_extract.yaml
: url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_01_preprocess_download_and_extract.yaml
  content:
    x-veld:
      chain:
        description: downloading wikipedia archive and extracting each article to
          a json file.
        topic:
        - NLP
        - Machine Learning
        - ETL
    services:
      veld_preprocess_download_and_extract:
        extends:
          file: ./code/veld_code__wikipedia_nlp_preprocessing/veld_download_and_extract.yaml
          service: veld_download_and_extract
        volumes:
        - ./data/training_data/extracted/:/veld/output/:z
        environment:
          wikipedia_dump_url: https://dumps.wikimedia.org/dewiki/latest/dewiki-latest-pages-articles.xml.bz2
? veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_02_preprocess_transform_wiki_json_to_txt.yaml
: url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_02_preprocess_transform_wiki_json_to_txt.yaml
  content:
    x-veld:
      chain:
        description: transforming wikipedia jsons to a single txt file.
        topic:
        - NLP
        - Machine Learning
        - ETL
    services:
      veld_preprocess_transform_wiki_json_to_txt_articles:
        extends:
          file: ./code/veld_code__wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data/training_data/extracted/data/:/veld/input/:z
        - ./data/training_data/extracted__txt_article_per_line/:/veld/output/:z
        environment:
          out_txt_file: data.txt
          out_data_description: 10% german wikipedia, transformed from json files
            into one txt file, each json file's content persisted with each each article
            in a single line.
          set_split_sentences: false
          sample_size_percentage: 10
          cpu_count: 14
          buffer_segments: 10
      veld_preprocess_transform_wiki_json_to_txt_sentences:
        extends:
          file: ./code/veld_code__wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data/training_data/extracted/data/:/veld/input/:z
        - ./data/training_data/extracted__txt_sentence_per_line/:/veld/output/:z
        environment:
          out_txt_file: data.txt
          out_data_description: 10% german wikipedia, transformed from json files
            into one txt file, each json file's content persisted with each sentence
            in a single line.
          set_split_sentences: true
          sample_size_percentage: 10
          cpu_count: 14
          buffer_segments: 10
        depends_on:
          veld_preprocess_transform_wiki_json_to_txt_articles:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_03_preprocess_lowercase.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_03_preprocess_lowercase.yaml
  content:
    x-veld:
      chain:
        description: preprocessing by making the entire text lowercase.
        topic: NLP
    services:
      veld_preprocess_lowercase_articles:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data/training_data/extracted__txt_article_per_line/:/veld/input/:z
        - ./data/training_data/extracted__txt_article_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased
      veld_preprocess_lowercase_sentences:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line/:/veld/input/:z
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased
        depends_on:
          veld_preprocess_lowercase_articles:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_04_preprocess_remove_punctuation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_04_preprocess_remove_punctuation.yaml
  content:
    x-veld:
      chain:
        description: preprocessing by removing punctuation of the entire text.
        topic: NLP
    services:
      veld_preprocess_remove_punctuation_articles:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data/training_data/extracted__txt_article_per_line__lowercased/:/veld/input/:z
        - ./data/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/output/txt/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased, punctuation removed
          cpu_count: 14
          buffer_segments: 100
      veld_preprocess_remove_punctuation_sentences:
        extends:
          file: ./code/veld_code__wordembeddings_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/input/:z
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/output/txt/:z
        environment:
          in_txt_file: data.txt
          out_txt_file: data.txt
          out_data_description: all data lowercased, punctuation removed
          cpu_count: 14
          buffer_segments: 100
        depends_on:
          veld_preprocess_remove_punctuation_articles:
            condition: service_completed_successfully
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_05_train_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_05_train_fasttext.yaml
  content:
    x-veld:
      chain:
        description: training a fasttext model on wikipediaa
        topic: NLP
    services:
      veld_train_fasttext:
        extends:
          file: ./code/veld_code__fasttext/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data/models/fasttext/m1/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m1.bin
          model_description: 10% wikipedia test model
          vector_size: 200
          epochs: 5
          window_size: 5
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_06_train_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_06_train_word2vec.yaml
  content:
    x-veld:
      chain:
        description: training a word2vec model on wikipediaa
        topic: NLP
    services:
      veld_train_word2vec:
        extends:
          file: ./code/veld_code__word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data/models/word2vec/m1/:/veld/output/:z
        environment:
          in_train_data_file: data.txt
          out_model_file: m1.bin
          model_description: 10% wikipedia test model
          epochs: 5
          vector_size: 200
          window: 5
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_07_train_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_07_train_glove.yaml
  content:
    x-veld:
      chain:
        description: training a glove model on wikipediaa
        topic: NLP
    services:
      veld_train_glove:
        extends:
          file: ./code/veld_code__glove/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data/models/glove/m1/:/veld/output/:z
        environment:
          in_corpus_file: data.txt
          out_vocab_file: m1_vocab.txt
          out_cooccurrence_file: m1_cooccurrence.bin
          out_cooccurrence_shuf_file: m1_cooccurrence_shuf.bin
          out_vector_file: m1_vector
          model_id: m1
          model_description: 10% wikipedia test model
          verbose: 2
          memory: 1.0
          vocab_min_count: 5
          vector_size: 200
          max_iter: 5
          window_size: 5
          binary: 2
          num_threads: 11
          x_max: 10
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_08_eval_fasttext.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_08_eval_fasttext.yaml
  content:
    x-veld:
      chain:
        description: evaluate fasttext model against evaluation gold data
        topic: NLP
    services:
      veld_eval_fasttext:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_fasttext.yaml
          service: veld_eval_fasttext
        volumes:
        - ./data/models/fasttext/m1/:/veld/input/model/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/eval_data/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/summary/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/fasttext/:/veld/output/log/:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_09_eval_word2vec.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_09_eval_word2vec.yaml
  content:
    x-veld:
      chain:
        description: evaluate word2vec model against evaluation gold data
        topic: NLP
    services:
      veld_eval_word2vec:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_word2vec.yaml
          service: veld_eval_word2vec
        volumes:
        - ./data/models/word2vec/m1/:/veld/input/model/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/eval_data/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/summary/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/word2vec/:/veld/output/log/:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_10_eval_glove.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_10_eval_glove.yaml
  content:
    x-veld:
      chain:
        description: evaluate glove model against evaluation gold data
        topic: NLP
    services:
      veld_eval_glove:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_eval_glove.yaml
          service: veld_eval_glove
        volumes:
        - ./data/models/glove/m1/:/veld/input/model/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_gold_data/lowercase/:/veld/input/eval_data/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/summary/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/logs/glove/:/veld/output/log/:z
        environment:
          in_vector_file: m1_vector.txt
          model_id: m1
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_11_analyse_evaluation.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_11_analyse_evaluation.yaml
  content:
    x-veld:
      chain:
        description: chain of analysing and evaluating models trained on wikipedia
        topic: NLP
    services:
      veld_analyse_evaluation:
        extends:
          file: ./code/veld_code__wordembeddings_evaluation/veld_analyse_evaluation.yaml
          service: veld_analyse_evaluation
        volumes:
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/input/:z
        - ./data/veld_data__wordembeddings_evaluation/evaluation_results/:/veld/output/:z
        environment:
          in_evaluation_summary_file: summary.yaml
          out_visualization_html_file: summary_visualized.html
          out_visualization_png_file: summary_visualized.png
veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia___veld_step_all_multi_chain.yaml:
  url: https://github.com/veldhub/veld_chain__train_infer_wordembeddings_multiple_architectures__wikipedia/blob/main/veld_step_all_multi_chain.yaml
  content:
    x-veld:
      chain:
        description: An entire multi chain, going through everything (fetching, preprocessing,
          training, evaluation in one service. This chain is composed of the other
          chains and is rather meant as a demonstration of the entire setup
        topic: NLP
    services:
      veld_preprocess_transform_wiki_json_to_txt_fasttext-word2vec:
        extends:
          file: ./veld_code_20_wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data_local/training_data/extracted/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_sentence_per_line/:/veld/output/:z
        environment:
          in_json_folder: data
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, transformed from json files into
            one txt file, each json file's content is split into sentences and persisted
            per line. Best for fastText and word2vec.
          sample_size_percentage: 10
          set_split_sentences: true
          cpu_count: 14
          sample_random_seed: 42
          info_interval: 100
      veld_preprocess_transform_wiki_json_to_txt_glove:
        extends:
          file: ./veld_code_20_wikipedia_nlp_preprocessing/veld_transform_wiki_json_to_txt.yaml
          service: veld_transform_wiki_json_to_txt
        volumes:
        - ./data_local/training_data/extracted/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_article_per_line/:/veld/output/:z
        environment:
          in_json_folder: data
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, transformed from json files into
            one txt file, each json file's content is persisted per line. Best for
            GloVe.
          sample_size_percentage: 10
          set_split_sentences: false
          cpu_count: 14
          sample_random_seed: 42
          info_interval: 100
        depends_on:
          veld_preprocess_transform_wiki_json_to_txt_fasttext-word2vec:
            condition: service_completed_successfully
      veld_preprocess_lowercase_fasttext-word2vec:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one sentence per line,
            lowercased,
        depends_on:
          veld_preprocess_transform_wiki_json_to_txt_glove:
            condition: service_completed_successfully
      veld_preprocess_lowercase_glove:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_lowercase.yaml
          service: veld_preprocess_lowercase
        volumes:
        - ./data_local/training_data/extracted__txt_article_per_line/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one article per line,
            lowercased
        depends_on:
          veld_preprocess_lowercase_fasttext-word2vec:
            condition: service_completed_successfully
      veld_preprocess_remove_punctuation_fasttext-word2vec:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one sentence per line,
            lowercased, removed punctuation
          cpu_count: 14
          info_interval: 100
        depends_on:
          veld_preprocess_lowercase_glove:
            condition: service_completed_successfully
      veld_preprocess_remove_punctuation_glove:
        extends:
          file: ./veld_code_19_we_preprocessing/veld_preprocess_remove_punctuation.yaml
          service: veld_preprocess_remove_punctuation
        volumes:
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased/:/veld/input/:z
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/output/:z
        environment:
          in_txt_file: de_wiki_sample.txt
          out_txt_file: de_wiki_sample.txt
          out_data_description: sample wikipedia, single txt, one article per line,
            lowercased, removed punctuation
          cpu_count: 14
          info_interval: 100
        depends_on:
          veld_preprocess_remove_punctuation_fasttext-word2vec:
            condition: service_completed_successfully
      veld_train_fasttext:
        extends:
          file: ./veld_code_12_fasttext/veld_train.yaml
          service: veld_train
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data_local/models/fasttext/m1/:/veld/output/:z
        environment:
          in_train_data_file: de_wiki_sample.txt
          model_id: m1
          model_description: fasttext test model
          vector_size: 200
          epochs: 10
        depends_on:
          veld_preprocess_remove_punctuation_glove:
            condition: service_completed_successfully
      veld_train_word2vec:
        extends:
          file: ./veld_code_13_word2vec/veld_train.yaml
          service: veld_train
        volumes:
        - ./data_local/training_data/extracted__txt_sentence_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data_local/models/word2vec/m1/:/veld/output/:z
        environment:
          in_train_data_file: de_wiki_sample.txt
          model_id: m1
          model_description: word2vec test model
          epochs: 10
          vector_size: 200
          window: 5
          min_count: 5
        depends_on:
          veld_train_fasttext:
            condition: service_completed_successfully
      veld_train_glove:
        extends:
          file: ./veld_code_17_glove/veld_train.yaml
          service: veld_train
        volumes:
        - ./data_local/training_data/extracted__txt_article_per_line__lowercased__removed_punctuation/:/veld/input/:z
        - ./data_local/models/glove/m1/:/veld/output/:z
        environment:
          in_corpus_file: de_wiki_sample.txt
          out_vocab_file: m1_vocab.txt
          out_cooccurrence_file: m1_cooccurrence.bin
          out_cooccurrence_shuf_file: m1_cooccurrence_shuf.bin
          out_vector_file: m1_vector
          model_id: m1
          model_description: glove test model
          verbose: 2
          memory: 4.0
          vocab_min_count: 5
          vector_size: 200
          max_iter: 10
          window_size: 15
          binary: 2
          num_threads: 14
          x_max: 10
        depends_on:
          veld_train_word2vec:
            condition: service_completed_successfully
      veld_eval_fasttext:
        extends:
          file: ./veld_code_14_we_evaluation/veld_eval_fasttext.yaml
          service: veld_eval_fasttext
        volumes:
        - ./data_local/models/fasttext/m1/:/veld/input/1/:z
        - ./veld_data_10_we_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./veld_data_10_we_evaluation/evaluation_results/:/veld/output/1/:z
        - ./veld_data_10_we_evaluation/evaluation_results/logs/fasttext/:/veld/output/2:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
        depends_on:
          veld_train_glove:
            condition: service_completed_successfully
      veld_eval_word2vec:
        extends:
          file: ./veld_code_14_we_evaluation/veld_eval_word2vec.yaml
          service: veld_eval_word2vec
        volumes:
        - ./data_local/models/word2vec/m1/:/veld/input/1/:z
        - ./veld_data_10_we_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./veld_data_10_we_evaluation/evaluation_results/:/veld/output/1/:z
        - ./veld_data_10_we_evaluation/evaluation_results/logs/word2vec/:/veld/output/2:z
        environment:
          in_model_file: m1.bin
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
        depends_on:
          veld_eval_fasttext:
            condition: service_completed_successfully
      veld_eval_glove:
        extends:
          file: ./veld_code_14_we_evaluation/veld_eval_glove.yaml
          service: veld_eval_glove
        volumes:
        - ./data_local/models/glove/m1/:/veld/input/1/:z
        - ./veld_data_10_we_evaluation/evaluation_gold_data/lowercase/:/veld/input/2/:z
        - ./veld_data_10_we_evaluation/evaluation_results/:/veld/output/1/:z
        - ./veld_data_10_we_evaluation/evaluation_results/logs/glove/:/veld/output/2/:z
        environment:
          in_vector_file: m1_vector.txt
          model_id: m1
          in_model_metadata_file: veld.yaml
          in_eval_gold_data_file: eval_data_lowercase.yaml
          out_eval_summary_file: summary.yaml
          out_eval_log_file: m1.txt
        depends_on:
          veld_eval_word2vec:
            condition: service_completed_successfully
veld_chain__train_spacy_apis_ner___veld_analysis.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_analysis.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_analysis:
        extends:
          file: ./code/analysis/compose.yaml
          service: veld_analysis
        volumes:
        - ./data/:/veld/input/
veld_chain__train_spacy_apis_ner___veld_convert.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_convert.yaml
  content:
    x-veld:
      chain:
        description: cleaning and converting json into spaCy docbin
        topic:
        - ETL
        - NLP
        - Machine learning
    services:
      veld_convert:
        extends:
          file: ./code/veld_code__spacy/veld_convert.yaml
          service: veld_convert
        volumes:
        - ./data/veld_data__apis_oebl__ner_gold/data_cleaned_simplified/:/veld/input/
        - ./data/docbin/:/veld/output/docbin/
        - ./:/veld/output/log/
        environment:
          in_json_file: cleaned_simplified.json
          out_log_file: veld_convert.log
          model_base: de_core_news_lg
veld_chain__train_spacy_apis_ner___veld_create_config.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_create_config.yaml
  content:
    x-veld:
      chain: null
    services:
      veld_create_config:
        extends:
          file: ./code/veld_code__spacy/veld_create_config.yaml
          service: veld_create_config
        volumes:
        - ./data/configs/:/veld/output/
        environment:
          out_config_file: config_1.cfg
          lang: de
          ner: true
          optimize_accuracy: true
          pretraining: true
veld_chain__train_spacy_apis_ner___veld_publish_to_hf.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_publish_to_hf.yaml
  content:
    x-veld:
      chain:
        description: pushing spacy model to huggingface.
        topic: NLP
    services:
      veld_publish_to_hf:
        extends:
          file: ./code/veld_code__spacy/veld_publish_to_hf.yaml
          service: veld_publish_to_hf
        volumes:
        - ./data/veld_data__apis_spacy_ner_models/m1/model-best/:/veld/input/
        environment:
          model_name: m1
          version: '1.0'
veld_chain__train_spacy_apis_ner___veld_train.yaml:
  url: https://github.com/veldhub/veld_chain__train_spacy_apis_ner/blob/main/veld_train.yaml
  content:
    x-veld:
      chain:
        description: A NER trainig setup, utilizing spaCy 3's config system.
        topic:
        - NLP
        - Machine learning
        - Named entity recognition
    services:
      veld_train:
        extends:
          file: ./code/veld_code__spacy/veld_train.yaml
          service: veld_train
        volumes:
        - ./data/docbin/:/veld/input/docbin/
        - ./data/configs/:/veld/input/config/
        - ./data/veld_data__apis_spacy_ner_models/m2/:/veld/output/
        environment:
          in_train_docbin_file: train.spacy
          in_dev_docbin_file: dev.spacy
          in_eval_docbin_file: eval.spacy
          in_spacy_config: config_2.cfg
          model_base: de_core_news_lg
          out_train_log_file: train.log
          out_eval_log_file: eval.log
